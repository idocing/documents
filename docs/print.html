<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title></title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/pagetoc.css">
        <link rel="stylesheet" href="theme/rust-syntax-bg-highlight.css">

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="ai/nn.html"><strong aria-hidden="true">1.</strong> ai</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ai/nn.html"><strong aria-hidden="true">1.1.</strong> nn</a></li></ol></li><li class="chapter-item expanded "><a href="algorithm/algorithm.html"><strong aria-hidden="true">2.</strong> algorithm</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="algorithm/algorithm.html"><strong aria-hidden="true">2.1.</strong> algorithm</a></li></ol></li><li class="chapter-item expanded "><a href="c/gcc.html"><strong aria-hidden="true">3.</strong> c</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="c/gcc.html"><strong aria-hidden="true">3.1.</strong> gcc</a></li><li class="chapter-item expanded "><a href="c/sleep.html"><strong aria-hidden="true">3.2.</strong> sleep</a></li></ol></li><li class="chapter-item expanded "><a href="cmake/sample.html"><strong aria-hidden="true">4.</strong> cmake</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="cmake/cmakefile.html"><strong aria-hidden="true">4.1.</strong> cmakefile</a></li><li class="chapter-item expanded "><a href="cmake/command.html"><strong aria-hidden="true">4.2.</strong> command</a></li><li class="chapter-item expanded "><a href="cmake/example.html"><strong aria-hidden="true">4.3.</strong> example</a></li><li class="chapter-item expanded "><a href="cmake/sample.html"><strong aria-hidden="true">4.4.</strong> sample</a></li></ol></li><li class="chapter-item expanded "><a href="crypto/openssl.html"><strong aria-hidden="true">5.</strong> crypto</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="crypto/openssl.html"><strong aria-hidden="true">5.1.</strong> openssl</a></li><li class="chapter-item expanded "><a href="crypto/rsa.html"><strong aria-hidden="true">5.2.</strong> rsa</a></li></ol></li><li class="chapter-item expanded "><a href="csharp/vscode.html"><strong aria-hidden="true">6.</strong> csharp</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="csharp/vscode.html"><strong aria-hidden="true">6.1.</strong> vscode</a></li></ol></li><li class="chapter-item expanded "><a href="cxx/export.html"><strong aria-hidden="true">7.</strong> cxx</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="cxx/export.html"><strong aria-hidden="true">7.1.</strong> export</a></li></ol></li><li class="chapter-item expanded "><a href="db/explain.html"><strong aria-hidden="true">8.</strong> db</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="db/explain.html"><strong aria-hidden="true">8.1.</strong> explain</a></li><li class="chapter-item expanded "><a href="db/mysql.html"><strong aria-hidden="true">8.2.</strong> mysql</a></li><li class="chapter-item expanded "><a href="db/pg_function.html"><strong aria-hidden="true">8.3.</strong> pg_function</a></li><li class="chapter-item expanded "><a href="db/pg_locks.html"><strong aria-hidden="true">8.4.</strong> pg_locks</a></li><li class="chapter-item expanded "><a href="db/pg_size.html"><strong aria-hidden="true">8.5.</strong> pg_size</a></li><li class="chapter-item expanded "><a href="db/postgres.html"><strong aria-hidden="true">8.6.</strong> postgres</a></li><li class="chapter-item expanded "><a href="db/recursive.html"><strong aria-hidden="true">8.7.</strong> recursive</a></li><li class="chapter-item expanded "><a href="db/uuid.html"><strong aria-hidden="true">8.8.</strong> uuid</a></li></ol></li><li class="chapter-item expanded "><a href="docker/copy&add.html"><strong aria-hidden="true">9.</strong> docker</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="docker/es/elk.html"><strong aria-hidden="true">9.1.</strong> es</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="docker/es/elk.html"><strong aria-hidden="true">9.1.1.</strong> elk</a></li><li class="chapter-item expanded "><a href="docker/es/elk_docker.html"><strong aria-hidden="true">9.1.2.</strong> elk_docker</a></li></ol></li><li class="chapter-item expanded "><a href="docker/copy&add.html"><strong aria-hidden="true">9.2.</strong> copy&add</a></li><li class="chapter-item expanded "><a href="docker/d-bus.html"><strong aria-hidden="true">9.3.</strong> d-bus</a></li><li class="chapter-item expanded "><a href="docker/debian.html"><strong aria-hidden="true">9.4.</strong> debian</a></li><li class="chapter-item expanded "><a href="docker/docker.html"><strong aria-hidden="true">9.5.</strong> docker</a></li><li class="chapter-item expanded "><a href="docker/golang.html"><strong aria-hidden="true">9.6.</strong> golang</a></li><li class="chapter-item expanded "><a href="docker/manifest.html"><strong aria-hidden="true">9.7.</strong> manifest</a></li><li class="chapter-item expanded "><a href="docker/mysql.html"><strong aria-hidden="true">9.8.</strong> mysql</a></li><li class="chapter-item expanded "><a href="docker/other.html"><strong aria-hidden="true">9.9.</strong> other</a></li><li class="chapter-item expanded "><a href="docker/qemu.html"><strong aria-hidden="true">9.10.</strong> qemu</a></li><li class="chapter-item expanded "><a href="docker/recover.html"><strong aria-hidden="true">9.11.</strong> recover</a></li><li class="chapter-item expanded "><a href="docker/redis.html"><strong aria-hidden="true">9.12.</strong> redis</a></li><li class="chapter-item expanded "><a href="docker/rootfs.html"><strong aria-hidden="true">9.13.</strong> rootfs</a></li><li class="chapter-item expanded "><a href="docker/run.html"><strong aria-hidden="true">9.14.</strong> run</a></li><li class="chapter-item expanded "><a href="docker/scratch.html"><strong aria-hidden="true">9.15.</strong> scratch</a></li><li class="chapter-item expanded "><a href="docker/vlmcsd.html"><strong aria-hidden="true">9.16.</strong> vlmcsd</a></li></ol></li><li class="chapter-item expanded "><a href="error/linux.html"><strong aria-hidden="true">10.</strong> error</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="error/linux.html"><strong aria-hidden="true">10.1.</strong> linux</a></li></ol></li><li class="chapter-item expanded "><a href="git/hooks.html"><strong aria-hidden="true">11.</strong> git</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="git/hooks.html"><strong aria-hidden="true">11.1.</strong> hooks</a></li><li class="chapter-item expanded "><a href="git/reset.html"><strong aria-hidden="true">11.2.</strong> reset</a></li><li class="chapter-item expanded "><a href="git/status.html"><strong aria-hidden="true">11.3.</strong> status</a></li></ol></li><li class="chapter-item expanded "><a href="go/install.html"><strong aria-hidden="true">12.</strong> go</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="go/install.html"><strong aria-hidden="true">12.1.</strong> install</a></li><li class="chapter-item expanded "><a href="go/json.html"><strong aria-hidden="true">12.2.</strong> json</a></li><li class="chapter-item expanded "><a href="go/micro.html"><strong aria-hidden="true">12.3.</strong> micro</a></li><li class="chapter-item expanded "><a href="go/mod.html"><strong aria-hidden="true">12.4.</strong> mod</a></li><li class="chapter-item expanded "><a href="go/pkg.html"><strong aria-hidden="true">12.5.</strong> pkg</a></li><li class="chapter-item expanded "><a href="go/printf.html"><strong aria-hidden="true">12.6.</strong> printf</a></li><li class="chapter-item expanded "><a href="go/type.html"><strong aria-hidden="true">12.7.</strong> type</a></li><li class="chapter-item expanded "><a href="go/vscode.html"><strong aria-hidden="true">12.8.</strong> vscode</a></li></ol></li><li class="chapter-item expanded "><a href="install/alpine.html"><strong aria-hidden="true">13.</strong> install</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="install/alpine.html"><strong aria-hidden="true">13.1.</strong> alpine</a></li><li class="chapter-item expanded "><a href="install/lang.html"><strong aria-hidden="true">13.2.</strong> lang</a></li><li class="chapter-item expanded "><a href="install/linux.html"><strong aria-hidden="true">13.3.</strong> linux</a></li><li class="chapter-item expanded "><a href="install/opencv.html"><strong aria-hidden="true">13.4.</strong> opencv</a></li><li class="chapter-item expanded "><a href="install/wxWidgets.html"><strong aria-hidden="true">13.5.</strong> wxWidgets</a></li></ol></li><li class="chapter-item expanded "><a href="java/jvm.html"><strong aria-hidden="true">14.</strong> java</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="java/maven/maven.html"><strong aria-hidden="true">14.1.</strong> maven</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="java/maven/maven.html"><strong aria-hidden="true">14.1.1.</strong> maven</a></li></ol></li><li class="chapter-item expanded "><a href="java/springboot/logback.html"><strong aria-hidden="true">14.2.</strong> springboot</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="java/springboot/logback.html"><strong aria-hidden="true">14.2.1.</strong> logback</a></li><li class="chapter-item expanded "><a href="java/springboot/logback-define.html"><strong aria-hidden="true">14.2.2.</strong> logback-define</a></li></ol></li><li class="chapter-item expanded "><a href="java/command.html"><strong aria-hidden="true">14.3.</strong> command</a></li><li class="chapter-item expanded "><a href="java/docker.html"><strong aria-hidden="true">14.4.</strong> docker</a></li></ol></li><li class="chapter-item expanded "><a href="linux/base.html"><strong aria-hidden="true">15.</strong> linux</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="linux/alpine/alpine.html"><strong aria-hidden="true">15.1.</strong> alpine</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="linux/alpine/alpine.html"><strong aria-hidden="true">15.1.1.</strong> alpine</a></li><li class="chapter-item expanded "><a href="linux/alpine/docker.html"><strong aria-hidden="true">15.1.2.</strong> docker</a></li></ol></li><li class="chapter-item expanded "><a href="linux/tools/tar.html"><strong aria-hidden="true">15.2.</strong> tools</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="linux/tools/tar.html"><strong aria-hidden="true">15.2.1.</strong> tar</a></li></ol></li><li class="chapter-item expanded "><a href="linux/base.html"><strong aria-hidden="true">15.3.</strong> base</a></li><li class="chapter-item expanded "><a href="linux/centos.html"><strong aria-hidden="true">15.4.</strong> centos</a></li><li class="chapter-item expanded "><a href="linux/curl.html"><strong aria-hidden="true">15.5.</strong> curl</a></li><li class="chapter-item expanded "><a href="linux/debian.html"><strong aria-hidden="true">15.6.</strong> debian</a></li><li class="chapter-item expanded "><a href="linux/lang.html"><strong aria-hidden="true">15.7.</strong> lang</a></li><li class="chapter-item expanded "><a href="linux/replace.html"><strong aria-hidden="true">15.8.</strong> replace</a></li><li class="chapter-item expanded "><a href="linux/source.html"><strong aria-hidden="true">15.9.</strong> source</a></li><li class="chapter-item expanded "><a href="linux/ssh.html"><strong aria-hidden="true">15.10.</strong> ssh</a></li><li class="chapter-item expanded "><a href="linux/sshd.html"><strong aria-hidden="true">15.11.</strong> sshd</a></li><li class="chapter-item expanded "><a href="linux/ubuntu.html"><strong aria-hidden="true">15.12.</strong> ubuntu</a></li><li class="chapter-item expanded "><a href="linux/user.html"><strong aria-hidden="true">15.13.</strong> user</a></li></ol></li><li class="chapter-item expanded "><a href="mac/brew.html"><strong aria-hidden="true">16.</strong> mac</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="mac/brew.html"><strong aria-hidden="true">16.1.</strong> brew</a></li><li class="chapter-item expanded "><a href="mac/brewcn.html"><strong aria-hidden="true">16.2.</strong> brewcn</a></li><li class="chapter-item expanded "><a href="mac/homebrew.html"><strong aria-hidden="true">16.3.</strong> homebrew</a></li><li class="chapter-item expanded "><a href="mac/launchpad.html"><strong aria-hidden="true">16.4.</strong> launchpad</a></li></ol></li><li class="chapter-item expanded "><a href="net/net.html"><strong aria-hidden="true">17.</strong> net</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="net/net.html"><strong aria-hidden="true">17.1.</strong> net</a></li></ol></li><li class="chapter-item expanded "><a href="other/elk/elk.html"><strong aria-hidden="true">18.</strong> other</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="other/elk/elk.html"><strong aria-hidden="true">18.1.</strong> elk</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="other/elk/elk.html"><strong aria-hidden="true">18.1.1.</strong> elk</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="python/conda.html"><strong aria-hidden="true">19.</strong> python</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="python/conda.html"><strong aria-hidden="true">19.1.</strong> conda</a></li><li class="chapter-item expanded "><a href="python/definition.html"><strong aria-hidden="true">19.2.</strong> definition</a></li><li class="chapter-item expanded "><a href="python/import.html"><strong aria-hidden="true">19.3.</strong> import</a></li><li class="chapter-item expanded "><a href="python/jupyter.html"><strong aria-hidden="true">19.4.</strong> jupyter</a></li><li class="chapter-item expanded "><a href="python/other.html"><strong aria-hidden="true">19.5.</strong> other</a></li><li class="chapter-item expanded "><a href="python/pip.html"><strong aria-hidden="true">19.6.</strong> pip</a></li></ol></li><li class="chapter-item expanded "><a href="react/env.html"><strong aria-hidden="true">20.</strong> react</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="react/env.html"><strong aria-hidden="true">20.1.</strong> env</a></li></ol></li><li class="chapter-item expanded "><a href="rust/build.html"><strong aria-hidden="true">21.</strong> rust</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="rust/build.html"><strong aria-hidden="true">21.1.</strong> build</a></li><li class="chapter-item expanded "><a href="rust/env.html"><strong aria-hidden="true">21.2.</strong> env</a></li><li class="chapter-item expanded "><a href="rust/link.html"><strong aria-hidden="true">21.3.</strong> link</a></li><li class="chapter-item expanded "><a href="rust/pointer.html"><strong aria-hidden="true">21.4.</strong> pointer</a></li><li class="chapter-item expanded "><a href="rust/rsproxy.html"><strong aria-hidden="true">21.5.</strong> rsproxy</a></li><li class="chapter-item expanded "><a href="rust/rustup.html"><strong aria-hidden="true">21.6.</strong> rustup</a></li><li class="chapter-item expanded "><a href="rust/triples.html"><strong aria-hidden="true">21.7.</strong> triples</a></li></ol></li><li class="chapter-item expanded "><a href="server/ca.html"><strong aria-hidden="true">22.</strong> server</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="server/ca.html"><strong aria-hidden="true">22.1.</strong> ca</a></li><li class="chapter-item expanded "><a href="server/caddy.html"><strong aria-hidden="true">22.2.</strong> caddy</a></li><li class="chapter-item expanded "><a href="server/nginx.html"><strong aria-hidden="true">22.3.</strong> nginx</a></li><li class="chapter-item expanded "><a href="server/pem.html"><strong aria-hidden="true">22.4.</strong> pem</a></li></ol></li><li class="chapter-item expanded "><a href="ssh/ssh.html"><strong aria-hidden="true">23.</strong> ssh</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ssh/ssh.html"><strong aria-hidden="true">23.1.</strong> ssh</a></li></ol></li><li class="chapter-item expanded "><a href="sys/proxy.html"><strong aria-hidden="true">24.</strong> sys</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="sys/proxy.html"><strong aria-hidden="true">24.1.</strong> proxy</a></li></ol></li><li class="chapter-item expanded "><a href="vi/vi.html"><strong aria-hidden="true">25.</strong> vi</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="vi/vi.html"><strong aria-hidden="true">25.1.</strong> vi</a></li></ol></li><li class="chapter-item expanded "><a href="vscode/edit.html"><strong aria-hidden="true">26.</strong> vscode</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="vscode/edit.html"><strong aria-hidden="true">26.1.</strong> edit</a></li><li class="chapter-item expanded "><a href="vscode/go.html"><strong aria-hidden="true">26.2.</strong> go</a></li><li class="chapter-item expanded "><a href="vscode/java.html"><strong aria-hidden="true">26.3.</strong> java</a></li><li class="chapter-item expanded "><a href="vscode/keymap.html"><strong aria-hidden="true">26.4.</strong> keymap</a></li><li class="chapter-item expanded "><a href="vscode/mvn.html"><strong aria-hidden="true">26.5.</strong> mvn</a></li><li class="chapter-item expanded "><a href="vscode/svn.html"><strong aria-hidden="true">26.6.</strong> svn</a></li></ol></li><li class="chapter-item expanded "><a href="vue/vue.html"><strong aria-hidden="true">27.</strong> vue</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="vue/vue.html"><strong aria-hidden="true">27.1.</strong> vue</a></li><li class="chapter-item expanded "><a href="vue/deploy.html"><strong aria-hidden="true">27.2.</strong> deploy</a></li><li class="chapter-item expanded "><a href="vue/svg.html"><strong aria-hidden="true">27.3.</strong> svg</a></li></ol></li><li class="chapter-item expanded "><a href="windows/install.html"><strong aria-hidden="true">28.</strong> windows</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="windows/install.html"><strong aria-hidden="true">28.1.</strong> install</a></li><li class="chapter-item expanded "><a href="windows/msi.html"><strong aria-hidden="true">28.2.</strong> msi</a></li></ol></li><li class="chapter-item expanded "><a href="index.html"><strong aria-hidden="true">29.</strong> Readme</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <h1 id="人工智能-神经网络原理"><a class="header" href="#人工智能-神经网络原理">人工智能-神经网络原理</a></h1>
<p>神经网络的灵感来自于人体大脑结构，人在思考问题的时候，神经冲动就会在神经突触所连接的无数神经元中传递。据说成人大脑中有1000亿个神经元，比宇宙中星球的数量还多。我们的神经网络就是模拟用很多的节点来处理信息，不过神经网络和大脑还是有区别的，因为大脑的神经冲动传导的过程中不仅仅只有”是”和”非”，还有强弱，缓急之分。</p>
<h2 id="神经网络的结构"><a class="header" href="#神经网络的结构">神经网络的结构</a></h2>
<p>我们来分析一下神经网络中的一个最简单例子。识别0~9这几个数字。</p>
<p><img src="ai/../static/img/nn/num.png" alt="" /></p>
<p>对于人类来说可以很轻易的认出下面的这些数字都是9，但是对于计算机来说，这确实很难。</p>
<p><img src="ai/../static/img/nn/numnine.png" alt="" /></p>
<p>那么我们如何通过神经网络识别出来呢?下面是一个神经网络示意图。</p>
<p><img src="ai/../static/img/nn/nn01.png" alt="" /></p>
<p>最左边的一列节点是输入，右边的一列节点是输出，把图像的每一个像素点对应到输入层的输入点，输入值为像素点的颜色，假设用0~1之间的数字表示这些颜色，越接近白色数值越接近0，越接近黑色越接近1。最右边代表输出值，每个节点代表一个结果值，输出点的结果越接近1说明这个点所代表的值概率越大。反之越接近0，概率越小。中间的两层叫做隐藏层，输入层，隐藏层和输出层连接组成神经网络。</p>
<p>我们现在要识别某张图片上的数字9，我们来做一个大胆的假设，如果第一个隐藏层可以识别出上半部分是个圆形，如果第二个隐藏层可以识别出下半部分是竖线，输出层将这个圆和竖线组合起来，就可以识别出这张图片是9。</p>
<p><img src="ai/../static/img/nn/nn02.png" alt="" /></p>
<p>如果这个假设可行的话，那么问题就从如何识别9变成了如何识别圆和竖线，那么你会想，识别圆也很难啊，同样的道理，圆可以切分成很多圆弧，这个问题最终可以演化到如何识别在某个指定区域是否有线段。</p>
<p><img src="ai/../static/img/nn/nn03.png" alt="" /></p>
<p>观察方框内的点，如果这个方框里面有直线的话，将这些点的输入值加起来一定是个大于0的数，如果没有线段的话，相加一定是等于或者接近0。</p>
<p><img src="ai/../static/img/nn/nn04.png" alt="" /></p>
<p>这些累积和构成了第二层也就是第一个隐藏层的值。</p>
<p><img src="ai/../static/img/nn/nn05.png" alt="" /></p>
<p>我们现在只关心方框内是否有线段，不关心方框外的点，这时候只需要将关心的点乘以1，不关心的点乘以1以下的数甚至乘以0。</p>
<p><img src="ai/../static/img/nn/nn06.png" alt="" /></p>
<p>我们把这个要乘的数值叫做权重weight，代表我们对这个输入值得关注程度。</p>
<p><img src="ai/../static/img/nn/nn07.png" alt="" /></p>
<p>现在我们能做到如何判断一张图片的某个区域是否有线段了，如果第二层的神经节点足够多的话，也就是说可以做无数次这种某个区域是否有线段的假设。这样我们就可以判断出图片上哪些地方有线段了。第一个隐藏层的任务完成。
但是有的时候图片会有噪点，也就是干扰，所以我们需要界定一个标准，只有高于一定的标准才允许激活，所以我们还需要一个偏置值。</p>
<p><img src="ai/../static/img/nn/nn08.png" alt="" /></p>
<p>下面来解决另一个问题，输入层的值是0~1的数，但是第二层是前一层的累加，有可能超过1，甚至可能是很大的数，这样不好，因为1可以代表概率的100%，0可以代表概率的0%，这是很方便的，如果数值的区间不可控，就很难代表概率了，所以我们用一个函数处理一下，可以将y处理成0~1之间的，y越大越接近1，y越小越接近0，所以就有了如下公式。</p>
<p><img src="ai/../static/img/nn/nn09.png" alt="" /></p>
<p>如果你熟悉线性代数的话，也许你会觉着用矩阵来表示看起来一目了然。</p>
<p><img src="ai/../static/img/nn/nn10.png" alt="" /></p>
<p>简写为</p>
<p><img src="ai/../static/img/nn/nn11.png" alt="" /></p>
<p>在接下来的网络层里上一层的输出就是下一层的输入，整个神经网络可以理解成一个方程，像素值是输入，图片的结果是几的概率是输出。只不过这个函数非常的复杂，有非常多个输入，10个输出，还有无数个权重和无数个偏置值。</p>
<h2 id="神经网络的训练"><a class="header" href="#神经网络的训练">神经网络的训练</a></h2>
<p>在训练的最初，会给所有的权重和偏置值赋予随机值，然后将计算值与真实值求误差，计算机会尽可能的减少这个误差。
减小误差的算法叫做梯度下降法，这里我们不做介绍，我们只要知道，计算机能够通过调整那些海量的权重和偏置值能够不断的减小误差。最终达到计算出来的值与真实值得偏差无限小。这时一个识别数字的人工智能就诞生了。
那么对于我们这个2个隐藏层，每层16个神经元的神经网络，它识别模式图片的精确度可以达到多少呢？可以很轻松的达到96%的正确率，最优秀的算法可以达到99%以上，而且增加神经元的个数继续提升。</p>
<p>现在我们回过来看之前的那个假设，如果第一个隐藏层可以识别出上半部分是个圆形，如果第二个隐藏层可以识别出下半部分是竖线，输出层将这个圆和竖线组合起来，就可以识别出这张图片是9。事实是这样么？完全不是。
我们将每个神经元所记录到的图像打印出来。得到的像素点非常混乱。</p>
<p><img src="ai/../static/img/nn/nn12.png" alt="" /></p>
<p>实际上神经网络并没有如我们想像的那样先识别线，再识别圆，最后组成数字9，而是用海量的权重和偏置值生生的将0~9这10个数字”记住”了。</p>
<p>如果神经网络的节点数真如人类大脑的神经元一样多，如果在算法或者其他技术上有些突破，未来说不定真的会有有情感的人工智能也说不定呢。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="人工智能-神经网络原理-1"><a class="header" href="#人工智能-神经网络原理-1">人工智能-神经网络原理</a></h1>
<p>神经网络的灵感来自于人体大脑结构，人在思考问题的时候，神经冲动就会在神经突触所连接的无数神经元中传递。据说成人大脑中有1000亿个神经元，比宇宙中星球的数量还多。我们的神经网络就是模拟用很多的节点来处理信息，不过神经网络和大脑还是有区别的，因为大脑的神经冲动传导的过程中不仅仅只有”是”和”非”，还有强弱，缓急之分。</p>
<h2 id="神经网络的结构-1"><a class="header" href="#神经网络的结构-1">神经网络的结构</a></h2>
<p>我们来分析一下神经网络中的一个最简单例子。识别0~9这几个数字。</p>
<p><img src="ai/../static/img/nn/num.png" alt="" /></p>
<p>对于人类来说可以很轻易的认出下面的这些数字都是9，但是对于计算机来说，这确实很难。</p>
<p><img src="ai/../static/img/nn/numnine.png" alt="" /></p>
<p>那么我们如何通过神经网络识别出来呢?下面是一个神经网络示意图。</p>
<p><img src="ai/../static/img/nn/nn01.png" alt="" /></p>
<p>最左边的一列节点是输入，右边的一列节点是输出，把图像的每一个像素点对应到输入层的输入点，输入值为像素点的颜色，假设用0~1之间的数字表示这些颜色，越接近白色数值越接近0，越接近黑色越接近1。最右边代表输出值，每个节点代表一个结果值，输出点的结果越接近1说明这个点所代表的值概率越大。反之越接近0，概率越小。中间的两层叫做隐藏层，输入层，隐藏层和输出层连接组成神经网络。</p>
<p>我们现在要识别某张图片上的数字9，我们来做一个大胆的假设，如果第一个隐藏层可以识别出上半部分是个圆形，如果第二个隐藏层可以识别出下半部分是竖线，输出层将这个圆和竖线组合起来，就可以识别出这张图片是9。</p>
<p><img src="ai/../static/img/nn/nn02.png" alt="" /></p>
<p>如果这个假设可行的话，那么问题就从如何识别9变成了如何识别圆和竖线，那么你会想，识别圆也很难啊，同样的道理，圆可以切分成很多圆弧，这个问题最终可以演化到如何识别在某个指定区域是否有线段。</p>
<p><img src="ai/../static/img/nn/nn03.png" alt="" /></p>
<p>观察方框内的点，如果这个方框里面有直线的话，将这些点的输入值加起来一定是个大于0的数，如果没有线段的话，相加一定是等于或者接近0。</p>
<p><img src="ai/../static/img/nn/nn04.png" alt="" /></p>
<p>这些累积和构成了第二层也就是第一个隐藏层的值。</p>
<p><img src="ai/../static/img/nn/nn05.png" alt="" /></p>
<p>我们现在只关心方框内是否有线段，不关心方框外的点，这时候只需要将关心的点乘以1，不关心的点乘以1以下的数甚至乘以0。</p>
<p><img src="ai/../static/img/nn/nn06.png" alt="" /></p>
<p>我们把这个要乘的数值叫做权重weight，代表我们对这个输入值得关注程度。</p>
<p><img src="ai/../static/img/nn/nn07.png" alt="" /></p>
<p>现在我们能做到如何判断一张图片的某个区域是否有线段了，如果第二层的神经节点足够多的话，也就是说可以做无数次这种某个区域是否有线段的假设。这样我们就可以判断出图片上哪些地方有线段了。第一个隐藏层的任务完成。
但是有的时候图片会有噪点，也就是干扰，所以我们需要界定一个标准，只有高于一定的标准才允许激活，所以我们还需要一个偏置值。</p>
<p><img src="ai/../static/img/nn/nn08.png" alt="" /></p>
<p>下面来解决另一个问题，输入层的值是0~1的数，但是第二层是前一层的累加，有可能超过1，甚至可能是很大的数，这样不好，因为1可以代表概率的100%，0可以代表概率的0%，这是很方便的，如果数值的区间不可控，就很难代表概率了，所以我们用一个函数处理一下，可以将y处理成0~1之间的，y越大越接近1，y越小越接近0，所以就有了如下公式。</p>
<p><img src="ai/../static/img/nn/nn09.png" alt="" /></p>
<p>如果你熟悉线性代数的话，也许你会觉着用矩阵来表示看起来一目了然。</p>
<p><img src="ai/../static/img/nn/nn10.png" alt="" /></p>
<p>简写为</p>
<p><img src="ai/../static/img/nn/nn11.png" alt="" /></p>
<p>在接下来的网络层里上一层的输出就是下一层的输入，整个神经网络可以理解成一个方程，像素值是输入，图片的结果是几的概率是输出。只不过这个函数非常的复杂，有非常多个输入，10个输出，还有无数个权重和无数个偏置值。</p>
<h2 id="神经网络的训练-1"><a class="header" href="#神经网络的训练-1">神经网络的训练</a></h2>
<p>在训练的最初，会给所有的权重和偏置值赋予随机值，然后将计算值与真实值求误差，计算机会尽可能的减少这个误差。
减小误差的算法叫做梯度下降法，这里我们不做介绍，我们只要知道，计算机能够通过调整那些海量的权重和偏置值能够不断的减小误差。最终达到计算出来的值与真实值得偏差无限小。这时一个识别数字的人工智能就诞生了。
那么对于我们这个2个隐藏层，每层16个神经元的神经网络，它识别模式图片的精确度可以达到多少呢？可以很轻松的达到96%的正确率，最优秀的算法可以达到99%以上，而且增加神经元的个数继续提升。</p>
<p>现在我们回过来看之前的那个假设，如果第一个隐藏层可以识别出上半部分是个圆形，如果第二个隐藏层可以识别出下半部分是竖线，输出层将这个圆和竖线组合起来，就可以识别出这张图片是9。事实是这样么？完全不是。
我们将每个神经元所记录到的图像打印出来。得到的像素点非常混乱。</p>
<p><img src="ai/../static/img/nn/nn12.png" alt="" /></p>
<p>实际上神经网络并没有如我们想像的那样先识别线，再识别圆，最后组成数字9，而是用海量的权重和偏置值生生的将0~9这10个数字”记住”了。</p>
<p>如果神经网络的节点数真如人类大脑的神经元一样多，如果在算法或者其他技术上有些突破，未来说不定真的会有有情感的人工智能也说不定呢。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="algorithm"><a class="header" href="#algorithm">algorithm</a></h1>
<h2 id="flat_to_nest"><a class="header" href="#flat_to_nest">flat_to_nest</a></h2>
<pre><code>const test_data = [
    { pid: 0, id: 1, name: &quot;aaa&quot; },
    { pid: 0, id: 2, name: &quot;bbb&quot; },
    { pid: 1, id: 3, name: &quot;ccc&quot; },
    { pid: 2, id: 4, name: &quot;ddd&quot; },
    { pid: 3, id: 5, name: &quot;eee&quot; },
]
export const flat_to_nest = function (data) {
    if (!data) {
        data = test_data
    }
    let res = []
    data.forEach(c =&gt; {
        c.children = []
        if (c.pid == 0) {
            res.push(a)
        } else {
            data.find(it =&gt; {
                return it.id === c.pid
            }).children.push(c)
        }
    })
    return res
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="algorithm-1"><a class="header" href="#algorithm-1">algorithm</a></h1>
<h2 id="flat_to_nest-1"><a class="header" href="#flat_to_nest-1">flat_to_nest</a></h2>
<pre><code>const test_data = [
    { pid: 0, id: 1, name: &quot;aaa&quot; },
    { pid: 0, id: 2, name: &quot;bbb&quot; },
    { pid: 1, id: 3, name: &quot;ccc&quot; },
    { pid: 2, id: 4, name: &quot;ddd&quot; },
    { pid: 3, id: 5, name: &quot;eee&quot; },
]
export const flat_to_nest = function (data) {
    if (!data) {
        data = test_data
    }
    let res = []
    data.forEach(c =&gt; {
        c.children = []
        if (c.pid == 0) {
            res.push(a)
        } else {
            data.find(it =&gt; {
                return it.id === c.pid
            }).children.push(c)
        }
    })
    return res
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gcc"><a class="header" href="#gcc">gcc</a></h1>
<h2 id="options"><a class="header" href="#options">options</a></h2>
<h3 id="-o-file-output-file"><a class="header" href="#-o-file-output-file">-o &lt;file&gt; output file</a></h3>
<h3 id="-g-contain-debug-info"><a class="header" href="#-g-contain-debug-info">-g contain debug info</a></h3>
<h3 id="-v-print-compile-info"><a class="header" href="#-v-print-compile-info">-v print compile info</a></h3>
<h3 id="-i-dir-add-include-dir"><a class="header" href="#-i-dir-add-include-dir">-I &lt;dir&gt; add include dir</a></h3>
<h3 id="-l-dir-add-library-dir"><a class="header" href="#-l-dir-add-library-dir">-L &lt;dir&gt; add library dir</a></h3>
<h3 id="-static-link-static-libaray"><a class="header" href="#-static-link-static-libaray">-static link static libaray</a></h3>
<h3 id="-shared-dynamic-build-link-dynamic-library"><a class="header" href="#-shared-dynamic-build-link-dynamic-library">-shared dynamic build, link dynamic library</a></h3>
<h3 id="-lxxx-link-xxx-libaray"><a class="header" href="#-lxxx-link-xxx-libaray">-lxxx link xxx libaray</a></h3>
<h3 id="-e-preprocess-only-do-not-compile-assemble-or-link"><a class="header" href="#-e-preprocess-only-do-not-compile-assemble-or-link">-E preprocess only, do not compile, assemble or link</a></h3>
<pre><code>gcc -E *.c -o out.i
</code></pre>
<h3 id="-s-compile-only-do-not-assemble-or-link"><a class="header" href="#-s-compile-only-do-not-assemble-or-link">-S compile only, do not assemble or link</a></h3>
<pre><code>gcc -S *.i -o out.s
</code></pre>
<h3 id="-c-assemble-only-do-not-link"><a class="header" href="#-c-assemble-only-do-not-link">-c assemble only, do not link</a></h3>
<pre><code>gcc -c *.s -o out.o
</code></pre>
<h3 id="link"><a class="header" href="#link">link</a></h3>
<pre><code>gcc *.o -o x
</code></pre>
<h2 id="other-options"><a class="header" href="#other-options">other options</a></h2>
<h3 id="-wloptions-pass-comma-separated-options-on-to-the-linker"><a class="header" href="#-wloptions-pass-comma-separated-options-on-to-the-linker">-Wl,&lt;options&gt; pass comma-separated &lt;options&gt; on to the linker</a></h3>
<ul>
<li>static link</li>
</ul>
<pre><code>-Wl,-Bstatic
</code></pre>
<ul>
<li>dynamic link</li>
</ul>
<pre><code>-Wl,-Bdynamic
</code></pre>
<ul>
<li>import library (output import library xxx.lib)</li>
</ul>
<pre><code>-Wl,--out-implib,xxx.lib
</code></pre>
<blockquote>
<p>example</p>
</blockquote>
<pre><code>-Wl,-Bstatic -lpgm -lxerces-c -Wl,-Bdynamic -libverbs -lcurl -Wl,--as-needed -Wl,--out-implib,xxx.lib
</code></pre>
<h2 id="static-libaray"><a class="header" href="#static-libaray">static libaray</a></h2>
<h3 id="single-object"><a class="header" href="#single-object">single object</a></h3>
<pre><code>gcc -c -o x.o x.c
ar -rc libx.a x.o
</code></pre>
<h3 id="multiple-object"><a class="header" href="#multiple-object">multiple object</a></h3>
<pre><code>gcc -c -o x1.o x1.c
gcc -c -o x2.o x2.c
ar -rc libx.a x1.o x2.o
</code></pre>
<h2 id="shared-libaray"><a class="header" href="#shared-libaray">shared libaray</a></h2>
<h3 id="single-source"><a class="header" href="#single-source">single source</a></h3>
<pre><code>gcc -shared -fPIC -o libx.so x.c
</code></pre>
<h3 id="single-object-1"><a class="header" href="#single-object-1">single object</a></h3>
<pre><code>gcc -shared -fPIC -o libx.so x.o
</code></pre>
<h3 id="multiple-source"><a class="header" href="#multiple-source">multiple source</a></h3>
<pre><code>gcc -shared -fPIC -o libx.so x1.c x2.c
</code></pre>
<h3 id="multiple-object-1"><a class="header" href="#multiple-object-1">multiple object</a></h3>
<pre><code>gcc -shared -fPIC -o libx.so x1.o x2.o
</code></pre>
<h2 id="use-shared-library--static-use-static-mode"><a class="header" href="#use-shared-library--static-use-static-mode">use shared library (-static use static mode)</a></h2>
<pre><code>gcc -c -o xxx.o xxx.c
ar -rc libxxx.a xxx.o
gcc -o test -L. -lxxx test.c [-static]
</code></pre>
<blockquote>
<p>or</p>
</blockquote>
<pre><code>gcc -o test test.c libxxx.a
</code></pre>
<h2 id="use-shared-library-windows-use-libxxxdll"><a class="header" href="#use-shared-library-windows-use-libxxxdll">use shared library (windows use libxxx.dll)</a></h2>
<pre><code>gcc -shared -fPIC -o libxxx.so xxx.c
gcc -o test -L. -lxxx test.c
</code></pre>
<blockquote>
<p>or</p>
</blockquote>
<pre><code>gcc -o test test.c libxxx.so
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gcc-1"><a class="header" href="#gcc-1">gcc</a></h1>
<h2 id="options-1"><a class="header" href="#options-1">options</a></h2>
<h3 id="-o-file-output-file-1"><a class="header" href="#-o-file-output-file-1">-o &lt;file&gt; output file</a></h3>
<h3 id="-g-contain-debug-info-1"><a class="header" href="#-g-contain-debug-info-1">-g contain debug info</a></h3>
<h3 id="-v-print-compile-info-1"><a class="header" href="#-v-print-compile-info-1">-v print compile info</a></h3>
<h3 id="-i-dir-add-include-dir-1"><a class="header" href="#-i-dir-add-include-dir-1">-I &lt;dir&gt; add include dir</a></h3>
<h3 id="-l-dir-add-library-dir-1"><a class="header" href="#-l-dir-add-library-dir-1">-L &lt;dir&gt; add library dir</a></h3>
<h3 id="-static-link-static-libaray-1"><a class="header" href="#-static-link-static-libaray-1">-static link static libaray</a></h3>
<h3 id="-shared-dynamic-build-link-dynamic-library-1"><a class="header" href="#-shared-dynamic-build-link-dynamic-library-1">-shared dynamic build, link dynamic library</a></h3>
<h3 id="-lxxx-link-xxx-libaray-1"><a class="header" href="#-lxxx-link-xxx-libaray-1">-lxxx link xxx libaray</a></h3>
<h3 id="-e-preprocess-only-do-not-compile-assemble-or-link-1"><a class="header" href="#-e-preprocess-only-do-not-compile-assemble-or-link-1">-E preprocess only, do not compile, assemble or link</a></h3>
<pre><code>gcc -E *.c -o out.i
</code></pre>
<h3 id="-s-compile-only-do-not-assemble-or-link-1"><a class="header" href="#-s-compile-only-do-not-assemble-or-link-1">-S compile only, do not assemble or link</a></h3>
<pre><code>gcc -S *.i -o out.s
</code></pre>
<h3 id="-c-assemble-only-do-not-link-1"><a class="header" href="#-c-assemble-only-do-not-link-1">-c assemble only, do not link</a></h3>
<pre><code>gcc -c *.s -o out.o
</code></pre>
<h3 id="link-1"><a class="header" href="#link-1">link</a></h3>
<pre><code>gcc *.o -o x
</code></pre>
<h2 id="other-options-1"><a class="header" href="#other-options-1">other options</a></h2>
<h3 id="-wloptions-pass-comma-separated-options-on-to-the-linker-1"><a class="header" href="#-wloptions-pass-comma-separated-options-on-to-the-linker-1">-Wl,&lt;options&gt; pass comma-separated &lt;options&gt; on to the linker</a></h3>
<ul>
<li>static link</li>
</ul>
<pre><code>-Wl,-Bstatic
</code></pre>
<ul>
<li>dynamic link</li>
</ul>
<pre><code>-Wl,-Bdynamic
</code></pre>
<ul>
<li>import library (output import library xxx.lib)</li>
</ul>
<pre><code>-Wl,--out-implib,xxx.lib
</code></pre>
<blockquote>
<p>example</p>
</blockquote>
<pre><code>-Wl,-Bstatic -lpgm -lxerces-c -Wl,-Bdynamic -libverbs -lcurl -Wl,--as-needed -Wl,--out-implib,xxx.lib
</code></pre>
<h2 id="static-libaray-1"><a class="header" href="#static-libaray-1">static libaray</a></h2>
<h3 id="single-object-2"><a class="header" href="#single-object-2">single object</a></h3>
<pre><code>gcc -c -o x.o x.c
ar -rc libx.a x.o
</code></pre>
<h3 id="multiple-object-2"><a class="header" href="#multiple-object-2">multiple object</a></h3>
<pre><code>gcc -c -o x1.o x1.c
gcc -c -o x2.o x2.c
ar -rc libx.a x1.o x2.o
</code></pre>
<h2 id="shared-libaray-1"><a class="header" href="#shared-libaray-1">shared libaray</a></h2>
<h3 id="single-source-1"><a class="header" href="#single-source-1">single source</a></h3>
<pre><code>gcc -shared -fPIC -o libx.so x.c
</code></pre>
<h3 id="single-object-3"><a class="header" href="#single-object-3">single object</a></h3>
<pre><code>gcc -shared -fPIC -o libx.so x.o
</code></pre>
<h3 id="multiple-source-1"><a class="header" href="#multiple-source-1">multiple source</a></h3>
<pre><code>gcc -shared -fPIC -o libx.so x1.c x2.c
</code></pre>
<h3 id="multiple-object-3"><a class="header" href="#multiple-object-3">multiple object</a></h3>
<pre><code>gcc -shared -fPIC -o libx.so x1.o x2.o
</code></pre>
<h2 id="use-shared-library--static-use-static-mode-1"><a class="header" href="#use-shared-library--static-use-static-mode-1">use shared library (-static use static mode)</a></h2>
<pre><code>gcc -c -o xxx.o xxx.c
ar -rc libxxx.a xxx.o
gcc -o test -L. -lxxx test.c [-static]
</code></pre>
<blockquote>
<p>or</p>
</blockquote>
<pre><code>gcc -o test test.c libxxx.a
</code></pre>
<h2 id="use-shared-library-windows-use-libxxxdll-1"><a class="header" href="#use-shared-library-windows-use-libxxxdll-1">use shared library (windows use libxxx.dll)</a></h2>
<pre><code>gcc -shared -fPIC -o libxxx.so xxx.c
gcc -o test -L. -lxxx test.c
</code></pre>
<blockquote>
<p>or</p>
</blockquote>
<pre><code>gcc -o test test.c libxxx.so
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sleep"><a class="header" href="#sleep">sleep</a></h1>
<h2 id="usleep"><a class="header" href="#usleep">usleep</a></h2>
<pre><code class="language-c">#include &lt;unistd.h&gt;

void task() {
    usleep(1000000); //sleep 1s
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sample"><a class="header" href="#sample">sample</a></h1>
<h2 id="project-name"><a class="header" href="#project-name">project name</a></h2>
<pre><code>project(project_name)
</code></pre>
<h2 id="version-required"><a class="header" href="#version-required">version required</a></h2>
<pre><code>cmake_minimum_required(VERSION 3.0)
</code></pre>
<h2 id="set-source-dir"><a class="header" href="#set-source-dir">set source dir</a></h2>
<pre><code>aux_source_directory(&lt;dir&gt; &lt;variable&gt;)
aux_source_directory(. DIR_SRCS)
</code></pre>
<h2 id="add-subdirectory"><a class="header" href="#add-subdirectory">add subdirectory</a></h2>
<pre><code>add_subdirectory(&lt;dir&gt;)
</code></pre>
<h2 id="add-static-library"><a class="header" href="#add-static-library">add static library</a></h2>
<pre><code>add_library(lib_name STATIC source_list)
</code></pre>
<h2 id="add-shared-library"><a class="header" href="#add-shared-library">add shared library</a></h2>
<pre><code>add_library(lib_name SHARED source_list)
</code></pre>
<h2 id="add-executable"><a class="header" href="#add-executable">add executable</a></h2>
<pre><code>add_executable(exe_name source_list)
</code></pre>
<h2 id="link-library"><a class="header" href="#link-library">link library</a></h2>
<pre><code>target_link_libraries(exe_name lib_name)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cmakelists"><a class="header" href="#cmakelists">CMakeLists</a></h1>
<h2 id="writing-cmakelists-files"><a class="header" href="#writing-cmakelists-files">Writing CMakeLists Files</a></h2>
<p>This chapter will cover the basics of writing effective CMakeLists files for your software. It will cover the basic commands and issues you will need to handle most projects. While CMake can handle extremely complex projects, for most projects you will find this chapter’s contents will tell you all you need to know. CMake is driven by the CMakeLists.txt files written for a software project. The CMakeLists files determine everything from which options to present to users, to which source files to compile. In addition to discussing how to write a CMakeLists file, this chapter will also cover how to make them robust and maintainable.</p>
<h2 id="editing-cmakelists-files"><a class="header" href="#editing-cmakelists-files">Editing CMakeLists Files</a></h2>
<p>CMakeLists files can be edited in almost any text editor. Some editors, such as Notepad++, come with CMake syntax highlighting and indentation support built-in. For editors such as Emacs or Vim, CMake includes indentation and syntax highlighting modes. These can be found in the Auxiliary directory of the source distribution, or downloaded from the CMake Download page.</p>
<p>Within any of the supported generators (Makefiles, Visual Studio, etc.), if you edit a CMakeLists file and rebuild, there are rules that will automatically invoke CMake to update the generated files (e.g. Makefiles or project files) as required. This helps to assure that your generated files are always in sync with your CMakeLists files.</p>
<h2 id="cmake-language"><a class="header" href="#cmake-language">CMake Language</a></h2>
<p>he CMake language is composed of comments, commands, and variables.</p>
<h2 id="comments"><a class="header" href="#comments">Comments</a></h2>
<p>Comments start with # and run to the end of the line. See the <code>cmake-language</code> manual for more details.</p>
<h2 id="variables"><a class="header" href="#variables">Variables</a></h2>
<p>CMakeLists files use variables much like any programming language. CMake variable names are case sensitive and may only contain alphanumeric characters and underscores.</p>
<p>A number of useful variables are automatically defined by CMake and are discussed in the cmake-variables manual. These variables begin with CMAKE_. Avoid this naming convention (and, ideally, establish your own) for variables specific to your project.</p>
<p>All CMake variables are stored internally as strings although they may sometimes be interpreted as other types.</p>
<p>Use the set command to set variable values. In its simplest form, the first argument to set is the name of the variable and the rest of the arguments are the values. Multiple value arguments are packed into a semicolon-separated list and stored in the variable as a string. For example:</p>
<pre><code>set(Foo &quot;&quot;)      # 1 quoted arg -&gt; value is &quot;&quot;
set(Foo a)       # 1 unquoted arg -&gt; value is &quot;a&quot;
set(Foo &quot;a b c&quot;) # 1 quoted arg -&gt; value is &quot;a b c&quot;
set(Foo a b c)   # 3 unquoted args -&gt; value is &quot;a;b;c&quot;
</code></pre>
<p>Variables may be referenced in command arguments using syntax ${VAR} where VAR is the variable name. If the named variable is not defined, the reference is replaced with an empty string; otherwise it is replaced by the value of the variable. Replacement is performed prior to the expansion of unquoted arguments, so variable values containing semicolons are split into zero-or-more arguments in place of the original unquoted argument. For example:</p>
<pre><code>set(Foo a b c)    # 3 unquoted args -&gt; value is &quot;a;b;c&quot;
command(${Foo})   # unquoted arg replaced by a;b;c
                  # and expands to three arguments
command(&quot;${Foo}&quot;) # quoted arg value is &quot;a;b;c&quot;
set(Foo &quot;&quot;)       # 1 quoted arg -&gt; value is empty string
command(${Foo})   # unquoted arg replaced by empty string
                  # and expands to zero arguments
command(&quot;${Foo}&quot;) # quoted arg value is empty string
</code></pre>
<p>System environment variables and Windows registry values can be accessed directly in CMake. To access system environment variables, use the syntax $ENV{VAR}. CMake can also reference registry entries in many commands using a syntax of the form [HKEY_CURRENT_USER\Software\path1\path2;key], where the paths are built from the registry tree and key.</p>
<h2 id="variable-scope"><a class="header" href="#variable-scope">Variable Scope</a></h2>
<p>Variables in CMake have a scope that is a little different from most languages. When you set a variable, it is visible to the current CMakeLists file or function and any subdirectory’s CMakeLists files, any functions or macros that are invoked, and any files that are included using the include command. When a new subdirectory is processed (or a function called), a new variable scope is created and initialized with the current value of all variables in the calling scope. Any new variables created in the child scope, or changes made to existing variables, will not impact the parent scope. Consider the following example:</p>
<pre><code>function(foo)
  message(${test}) # test is 1 here
  set(test 2)
  message(${test}) # test is 2 here, but only in this scope
endfunction()

set(test 1)
foo()
message(${test}) # test will still be 1 here
</code></pre>
<p>In some cases, you might want a function or subdirectory to set a variable in its parent’s scope. There is a way for CMake to return a value from a function, and it can be done by using the PARENT_SCOPE option with the <code>set</code> command. We can modify the prior example so that the function foo changes the value of test in its parent’s scope as follows:</p>
<pre><code>function(foo)
  message(${test}) # test is 1 here
  set(test 2 PARENT_SCOPE)
  message(${test}) # test still 1 in this scope
endfunction()

set(test 1)
foo()
message(${test}) # test will now be 2 here
</code></pre>
<p>Variables in CMake are defined in the order of the execution of set commands.</p>
<p>Consider the following example:</p>
<pre><code># FOO is undefined

set(FOO 1)
# FOO is now set to 1

set(FOO 0)
# FOO is now set to 0
</code></pre>
<p>To understand the scope of variables, consider this example:</p>
<pre><code>set(foo 1)

# process the dir1 subdirectory
add_subdirectory(dir1)

# include and process the commands in file1.cmake
include(file1.cmake)

set(bar 2)
# process the dir2 subdirectory
add_subdirectory(dir2)

# include and process the commands in file2.cmake
include(file2.cmake)
</code></pre>
<p>In this example, because the variable foo is defined at the beginning, it will be defined while processing both dir1 and dir2. In contrast, bar will only be defined when processing dir2. Likewise, foo will be defined when processing both file1.cmake and file2.cmake, whereas bar will only be defined while processing file2.cmake.</p>
<h2 id="commands"><a class="header" href="#commands">Commands</a></h2>
<p>A command consists of the command name, opening parenthesis, whitespace separated arguments, and a closing parenthesis. Each command is evaluated in the order that it appears in the CMakeLists file. See the <code>cmake-commands</code> manual for a full list of CMake commands.</p>
<p>CMake is no longer case sensitive to command names, so where you see command, you could use COMMAND or Command instead. It is considered best practice to use lowercase commands. All whitespace (spaces, line feeds, tabs) is ignored except to separate arguments. Therefore, commands may span multiple lines as long as the command name and the opening parenthesis are on the same line.</p>
<p>CMake command arguments are space separated and case sensitive. Command arguments may be either quoted or unquoted. A quoted argument starts and ends in a double quote (“) and always represents exactly one argument. Any double quotes contained inside the value must be escaped with a backslash. Consider using bracket arguments for arguments that require escaping, see the <code>cmake-language</code> manual. An unquoted argument starts in any character other than a double quote (later double quotes are literal) and is automatically expanded into zero-or-more arguments by separating on semicolons within the value. For example:</p>
<pre><code>command(&quot;&quot;)          # 1 quoted argument
command(&quot;a b c&quot;)     # 1 quoted argument
command(&quot;a;b;c&quot;)     # 1 quoted argument
command(&quot;a&quot; &quot;b&quot; &quot;c&quot;) # 3 quoted arguments
command(a b c)       # 3 unquoted arguments
command(a;b;c)       # 1 unquoted argument expands to 3
</code></pre>
<h2 id="basic-commands"><a class="header" href="#basic-commands">Basic Commands</a></h2>
<p>As we saw earlier, the set and unset commands explicitly set or unset variables. The string, list, and separate_arguments commands offer basic manipulation of strings and lists.</p>
<p>The add_executable and add_library commands are the main commands for defining the executables and libraries to build, and which source files comprise them. For Visual Studio projects, the source files will show up in the IDE as usual, but any header files the project uses will not be. To have the header files show up, simply add them to the list of source files for the executable or library; this can be done for all generators. Any generators that do not use the header files directly (such as Makefile based generators) will simply ignore them.</p>
<h2 id="flow-control"><a class="header" href="#flow-control">Flow Control</a></h2>
<p>The CMake language provides three flow control constructs to help organize your CMakeLists files and keep them maintainable.</p>
<p>Conditional statements (e.g. if)</p>
<p>Looping constructs (e.g. foreach and while)</p>
<p>Procedure definitions (e.g. macro and function)</p>
<h2 id="conditional-statements"><a class="header" href="#conditional-statements">Conditional Statements</a></h2>
<p>First we will consider the if command. In many ways, the if command in CMake is just like the if command in any other language. It evaluates its expression and uses it to execute the code in its body or optionally the code in the else clause. For example:</p>
<pre><code>if(FOO)
  # do something here
else()
  # do something else
endif()
</code></pre>
<p>CMake also supports elseif to help sequentially test for multiple conditions. For example:</p>
<pre><code>if(MSVC80)
  # do something here
elseif(MSVC90)
  # do something else
elseif(APPLE)
  # do something else
endif()
</code></pre>
<p>The if command documents the many conditions it can test.</p>
<h2 id="looping-constructs"><a class="header" href="#looping-constructs">Looping Constructs</a></h2>
<p>The foreach and while commands allow you to handle repetitive tasks that occur in sequence. The break command breaks out of a foreach or while loop before it would normally end.</p>
<p>The foreach command enables you to execute a group of CMake commands repeatedly on the members of a list. Consider the following example adapted from VTK</p>
<pre><code>foreach(tfile
        TestAnisotropicDiffusion2D
        TestButterworthLowPass
        TestButterworthHighPass
        TestCityBlockDistance
        TestConvolve
        )
  add_test(${tfile}-image ${VTK_EXECUTABLE}
    ${VTK_SOURCE_DIR}/Tests/rtImageTest.tcl
    ${VTK_SOURCE_DIR}/Tests/${tfile}.tcl
    -D ${VTK_DATA_ROOT}
    -V Baseline/Imaging/${tfile}.png
    -A ${VTK_SOURCE_DIR}/Wrapping/Tcl
    )
endforeach()
</code></pre>
<p>The first argument of the foreach command is the name of the variable that will take on a different value with each iteration of the loop; the remaining arguments are the list of values over which to loop. In this example, the body of the foreach loop is just one CMake command, add_test. In the body of the foreach, each time the loop variable (tfile in this example) is referenced will be replaced with the current value from the list. In the first iteration, occurrences of ${tfile} will be replaced with TestAnisotropicDiffusion2D. In the next iteration, ${tfile} will be replaced with TestButterworthLowPass. The foreach loop will continue to loop until all of the arguments have been processed.</p>
<p>It is worth mentioning that foreach loops can be nested, and that the loop variable is replaced prior to any other variable expansion. This means that in the body of a foreach loop, you can construct variable names using the loop variable. In the code below, the loop variable tfile is expanded, and then concatenated with _TEST_RESULT. The new variable name is then expanded and tested to see if it matches FAILED.</p>
<pre><code>if(${${tfile}_TEST_RESULT} MATCHES FAILED)
  message(&quot;Test ${tfile} failed.&quot;)
endif()
</code></pre>
<p>The while command provides looping based on a test condition. The format for the test expression in the while command is the same as it is for the if command, as described earlier. Consider the following example, which is used by CTest. Note that CTest updates the value of CTEST_ELAPSED_TIME internally.</p>
<pre><code>#####################################################
# run paraview and ctest test dashboards for 6 hours
#
while(${CTEST_ELAPSED_TIME} LESS 36000)
  set(START_TIME ${CTEST_ELAPSED_TIME})
  ctest_run_script(&quot;dash1_ParaView_vs71continuous.cmake&quot;)
  ctest_run_script(&quot;dash1_cmake_vs71continuous.cmake&quot;)
endwhile()
</code></pre>
<h2 id="procedure-definitions"><a class="header" href="#procedure-definitions">Procedure Definitions</a></h2>
<p>The macro and function commands support repetitive tasks that may be scattered throughout your CMakeLists files. Once a macro or function is defined, it can be used by any CMakeLists files processed after its definition.</p>
<p>A function in CMake is very much like a function in C or C++. You can pass arguments into it, and they become variables within the function. Likewise, some standard variables such as ARGC, ARGV, ARGN, and ARGV0, ARGV1, etc. are defined. Function calls have a dynamic scope. Within a function you are in a new variable scope; this is like how you drop into a subdirectory using the add_subdirectory command and are in a new variable scope. All the variables that were defined when the function was called remain defined, but any changes to variables or new variables only exist within the function. When the function returns, those variables will go away. Put more simply: when you invoke a function, a new variable scope is pushed; when it returns, that variable scope is popped.</p>
<p>The function command defines a new function. The first argument is the name of the function to define; all additional arguments are formal parameters to the function.</p>
<pre><code>function(DetermineTime _time)
  # pass the result up to whatever invoked this
  set(${_time} &quot;1:23:45&quot; PARENT_SCOPE)
endfunction()

# now use the function we just defined
DetermineTime(current_time)

if(DEFINED current_time)
  message(STATUS &quot;The time is now: ${current_time}&quot;)
endif()
</code></pre>
<p>Note that in this example, _time is used to pass the name of the return variable. The set command is invoked with the value of _time, which will be current_time. Finally, the set command uses the PARENT_SCOPE option to set the variable in the caller’s scope instead of the local scope.</p>
<p>Macros are defined and called in the same manner as functions. The main differences are that a macro does not push and pop a new variable scope, and that the arguments to a macro are not treated as variables but as strings replaced prior to execution. This is very much like the differences between a macro and a function in C or C++. The first argument is the name of the macro to create; all additional arguments are formal parameters to the macro.</p>
<pre><code># define a simple macro
macro(assert TEST COMMENT)
  if(NOT ${TEST})
    message(&quot;Assertion failed: ${COMMENT}&quot;)
  endif()
endmacro()

# use the macro
find_library(FOO_LIB foo /usr/local/lib)
assert(${FOO_LIB} &quot;Unable to find library foo&quot;)
</code></pre>
<p>The simple example above creates a macro called assert. The macro is defined into two arguments; the first is a value to test and the second is a comment to print out if the test fails. The body of the macro is a simple if command with a message command inside of it. The macro body ends when the endmacro command is found. The macro can be invoked simply by using its name as if it were a command. In the above example, if FOO_LIB was not found then a message would be displayed indicating the error condition.</p>
<p>The macro command also supports defining macros that take variable argument lists. This can be useful if you want to define a macro that has optional arguments or multiple signatures. Variable arguments can be referenced using ARGC and ARGV0, ARGV1, etc., instead of the formal parameters. ARGV0 represents the first argument to the macro; ARGV1 represents the next, and so forth. You can also use a mixture of formal arguments and variable arguments, as shown in the example below.</p>
<pre><code># define a macro that takes at least two arguments
# (the formal arguments) plus an optional third argument
macro(assert TEST COMMENT)
  if(NOT ${TEST})
    message(&quot;Assertion failed: ${COMMENT}&quot;)

    # if called with three arguments then also write the
    # message to a file specified as the third argument
    if(${ARGC} MATCHES 3)
      file(APPEND ${ARGV2} &quot;Assertion failed: ${COMMENT}&quot;)
    endif()

  endif()
endmacro()

# use the macro
find_library(FOO_LIB foo /usr/local/lib)
assert(${FOO_LIB} &quot;Unable to find library foo&quot;)
</code></pre>
<p>In this example, the two required arguments are TEST and COMMENT. These required arguments can be referenced by name, as they are in this example, or by referencing ARGV0 and ARGV1. If you want to process the arguments as a list, use the ARGV and ARGN variables. ARGV (as opposed to ARGV0, ARGV1, etc) is a list of all the arguments to the macro, while ARGN is a list of all the arguments after the formal arguments. Inside your macro, you can use the foreach command to iterate over ARGV or ARGN as desired.</p>
<p>The return command returns from a function, directory or file. Note that a macro, unlike a function, is expanded in place and therefore cannot handle return.</p>
<h2 id="regular-expressions"><a class="header" href="#regular-expressions">Regular Expressions</a></h2>
<p>A few CMake commands, such as if and string, make use of regular expressions or can take a regular expression as an argument. In its simplest form, a regular expression is a sequence of characters used to search for exact character matches. However, many times the exact sequence to be found is unknown, or only a match at the beginning or end of a string is desired. Since there are several different conventions for specifying regular expressions, CMake’s standard is described in the string command documentation. The description is based on the open source regular expression class from Texas Instruments, which is used by CMake for parsing regular expressions.</p>
<h2 id="advanced-commands"><a class="header" href="#advanced-commands">Advanced Commands</a></h2>
<p>There are a few commands that can be very useful, but are not typically used in writing CMakeLists files. This section will discuss a few of these commands and when they are useful.</p>
<p>First, consider the add_dependencies command which creates a dependency between two targets. CMake automatically creates dependencies between targets when it can determine them. For example, CMake will automatically create a dependency for an executable target that depends on a library target. The add_dependencies command is typically used to specify inter-target dependencies between targets where at least one of the targets is a custom target (see Add Custom Command section).</p>
<p>The include_regular_expression command also relates to dependencies. This command controls the regular expression that is used for tracing source code dependencies. By default, CMake will trace all the dependencies for a source file including system files such as stdio.h. If you specify a regular expression with the include_regular_expression command, that regular expression will be used to limit which include files are processed. For example; if your software project’s include files all started with the prefix foo (e.g. fooMain.c fooStruct.h, etc), you could specify a regular expression of ^foo.*$ to limit the dependency checking to just the files of your project.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="command"><a class="header" href="#command">command</a></h1>
<h2 id="synopsis"><a class="header" href="#synopsis">Synopsis</a></h2>
<pre><code>Generate a Project Buildsystem
 cmake [&lt;options&gt;] -B &lt;path-to-build&gt; [-S &lt;path-to-source&gt;]
 cmake [&lt;options&gt;] &lt;path-to-source | path-to-existing-build&gt;

Build a Project
 cmake --build &lt;dir&gt; [&lt;options&gt;] [-- &lt;build-tool-options&gt;]

Install a Project
 cmake --install &lt;dir&gt; [&lt;options&gt;]

Open a Project
 cmake --open &lt;dir&gt;

Run a Script
 cmake [-D &lt;var&gt;=&lt;value&gt;]... -P &lt;cmake-script-file&gt;

Run a Command-Line Tool
 cmake -E &lt;command&gt; [&lt;options&gt;]

Run the Find-Package Tool
 cmake --find-package [&lt;options&gt;]

Run a Workflow Preset
 cmake --workflow [&lt;options&gt;]

View Help
 cmake --help[-&lt;topic&gt;]
</code></pre>
<h2 id="description"><a class="header" href="#description">Description</a></h2>
<p>The cmake executable is the command-line interface of the cross-platform buildsystem generator CMake. The above Synopsis lists various actions the tool can perform as described in sections below.</p>
<p>To build a software project with CMake, Generate a Project Buildsystem. Optionally use cmake to Build a Project, Install a Project or just run the corresponding build tool (e.g. make) directly. cmake can also be used to View Help.</p>
<p>The other actions are meant for use by software developers writing scripts in the CMake language to support their builds.</p>
<p>For graphical user interfaces that may be used in place of cmake, see ccmake and cmake-gui. For command-line interfaces to the CMake testing and packaging facilities, see ctest and cpack.</p>
<p>For more information on CMake at large, see also the links at the end of this manual.</p>
<h2 id="introduction-to-cmake-buildsystems"><a class="header" href="#introduction-to-cmake-buildsystems">Introduction to CMake Buildsystems</a></h2>
<p>A buildsystem describes how to build a project's executables and libraries from its source code using a build tool to automate the process. For example, a buildsystem may be a Makefile for use with a command-line make tool or a project file for an Integrated Development Environment (IDE). In order to avoid maintaining multiple such buildsystems, a project may specify its buildsystem abstractly using files written in the CMake language. From these files CMake generates a preferred buildsystem locally for each user through a backend called a generator.</p>
<p>To generate a buildsystem with CMake, the following must be selected:</p>
<h2 id="source-tree"><a class="header" href="#source-tree">Source Tree</a></h2>
<p>The top-level directory containing source files provided by the project. The project specifies its buildsystem using files as described in the cmake-language(7) manual, starting with a top-level file named CMakeLists.txt. These files specify build targets and their dependencies as described in the cmake-buildsystem(7) manual.</p>
<h2 id="build-tree"><a class="header" href="#build-tree">Build Tree</a></h2>
<p>The top-level directory in which buildsystem files and build output artifacts (e.g. executables and libraries) are to be stored. CMake will write a CMakeCache.txt file to identify the directory as a build tree and store persistent information such as buildsystem configuration options.</p>
<p>To maintain a pristine source tree, perform an out-of-source build by using a separate dedicated build tree. An in-source build in which the build tree is placed in the same directory as the source tree is also supported, but discouraged.</p>
<h2 id="generator"><a class="header" href="#generator">Generator</a></h2>
<p>This chooses the kind of buildsystem to generate. See the cmake-generators(7) manual for documentation of all generators. Run cmake --help to see a list of generators available locally. Optionally use the -G option below to specify a generator, or simply accept the default CMake chooses for the current platform.</p>
<p>When using one of the Command-Line Build Tool Generators CMake expects that the environment needed by the compiler toolchain is already configured in the shell. When using one of the IDE Build Tool Generators, no particular environment is needed.</p>
<h2 id="generate-a-project-buildsystem"><a class="header" href="#generate-a-project-buildsystem">Generate a Project Buildsystem</a></h2>
<p>Run CMake with one of the following command signatures to specify the source and build trees and generate a buildsystem:</p>
<pre><code>cmake [&lt;options&gt;] -B &lt;path-to-build&gt; [-S &lt;path-to-source&gt;]
</code></pre>
<h3 id="new-in-version-3xx"><a class="header" href="#new-in-version-3xx">New in version 3.xx.</a></h3>
<p>Uses <path-to-build> as the build tree and <code>&lt;path-to-source&gt;</code> as the source tree. The specified paths may be absolute or relative to the current working directory. The source tree must contain a CMakeLists.txt file. The build tree will be created automatically if it does not already exist. For example:</p>
<pre><code>cmake -S src -B build
cmake [&lt;options&gt;] &lt;path-to-source&gt;
</code></pre>
<p>Uses the current working directory as the build tree, and <code>&lt;path-to-source&gt;</code> as the source tree. The specified path may be absolute or relative to the current working directory. The source tree must contain a CMakeLists.txt file and must not contain a CMakeCache.txt file because the latter identifies an existing build tree. For example:</p>
<pre><code>mkdir build ; cd build
cmake ../src
cmake [&lt;options&gt;] &lt;path-to-existing-build&gt;
</code></pre>
<p>Uses <code>&lt;path-to-existing-build&gt;</code> as the build tree, and loads the path to the source tree from its CMakeCache.txt file, which must have already been generated by a previous run of CMake. The specified path may be absolute or relative to the current working directory. For example:</p>
<pre><code>cd build
cmake .
</code></pre>
<p>In all cases the <code>&lt;options&gt;</code> may be zero or more of the Options below.</p>
<p>The above styles for specifying the source and build trees may be mixed. Paths specified with -S or -B are always classified as source or build trees, respectively. Paths specified with plain arguments are classified based on their content and the types of paths given earlier. If only one type of path is given, the current working directory (cwd) is used for the other. For example:</p>
<div class="table-wrapper"><table><thead><tr><th>Command Line</th><th>Source Dir</th><th>Build Dir</th></tr></thead><tbody>
<tr><td>cmake -B build</td><td>cwd</td><td>build</td></tr>
<tr><td>cmake -B build src</td><td>src</td><td>build</td></tr>
<tr><td>cmake -B build -S src</td><td>src</td><td>build</td></tr>
<tr><td>cmake src</td><td>src</td><td>cwd</td></tr>
<tr><td>cmake build (existing)</td><td>loaded</td><td>build</td></tr>
<tr><td>cmake -S src</td><td>src</td><td>cwd</td></tr>
<tr><td>cmake -S src build</td><td>src</td><td>build</td></tr>
<tr><td>cmake -S src -B build</td><td>src</td><td>build</td></tr>
</tbody></table>
</div>
<p>Changed in version 3.xx: CMake warns when multiple source paths are specified. This has never been officially documented or supported, but older versions accidentally accepted multiple source paths and used the last path specified. Avoid passing multiple source path arguments.</p>
<p>After generating a buildsystem one may use the corresponding native build tool to build the project. For example, after using the Unix Makefiles generator one may run make directly:</p>
<p>make
make install
Alternatively, one may use cmake to Build a Project by automatically choosing and invoking the appropriate native build tool.</p>
<h2 id="options-2"><a class="header" href="#options-2">Options</a></h2>
<pre><code>-S &lt;path-to-source&gt;
Path to root directory of the CMake project to build.

-B &lt;path-to-build&gt;
Path to directory which CMake will use as the root of build directory.

If the directory doesn't already exist CMake will make it.

-C &lt;initial-cache&gt;
Pre-load a script to populate the cache.

When CMake is first run in an empty build tree, it creates a CMakeCache.txt file and populates it with customizable settings for the project. This option may be used to specify a file from which to load cache entries before the first pass through the project's CMake listfiles. The loaded entries take priority over the project's default values. The given file should be a CMake script containing set() commands that use the CACHE option, not a cache-format file.

References to CMAKE_SOURCE_DIR and CMAKE_BINARY_DIR within the script evaluate to the top-level source and build tree.

-D &lt;var&gt;:&lt;type&gt;=&lt;value&gt;, -D &lt;var&gt;=&lt;value&gt;
Create or update a CMake CACHE entry.

When CMake is first run in an empty build tree, it creates a CMakeCache.txt file and populates it with customizable settings for the project. This option may be used to specify a setting that takes priority over the project's default value. The option may be repeated for as many CACHE entries as desired.

If the :&lt;type&gt; portion is given it must be one of the types specified by the set() command documentation for its CACHE signature. If the :&lt;type&gt; portion is omitted the entry will be created with no type if it does not exist with a type already. If a command in the project sets the type to PATH or FILEPATH then the &lt;value&gt; will be converted to an absolute path.

This option may also be given as a single argument: -D&lt;var&gt;:&lt;type&gt;=&lt;value&gt; or -D&lt;var&gt;=&lt;value&gt;.

It's important to note that the order of -C and -D arguments is significant. They will be carried out in the order they are listed, with the last argument taking precedence over the previous ones. For example, if you specify -DCMAKE_BUILD_TYPE=Debug, followed by a -C argument with a file that calls:

set(CMAKE_BUILD_TYPE &quot;Release&quot; CACHE STRING &quot;&quot; FORCE)
then the -C argument will take precedence, and CMAKE_BUILD_TYPE will be set to Release. However, if the -D argument comes after the -C argument, it will be set to Debug.

If a set(... CACHE ...) call in the -C file does not use FORCE, and a -D argument sets the same variable, the -D argument will take precedence regardless of order because of the nature of non-FORCE set(... CACHE ...) calls.

-U &lt;globbing_expr&gt;
Remove matching entries from CMake CACHE.

This option may be used to remove one or more variables from the CMakeCache.txt file, globbing expressions using * and ? are supported. The option may be repeated for as many CACHE entries as desired.

Use with care, you can make your CMakeCache.txt non-working.

-G &lt;generator-name&gt;
Specify a build system generator.

CMake may support multiple native build systems on certain platforms. A generator is responsible for generating a particular build system. Possible generator names are specified in the cmake-generators(7) manual.

If not specified, CMake checks the CMAKE_GENERATOR environment variable and otherwise falls back to a builtin default selection.

-T &lt;toolset-spec&gt;
Toolset specification for the generator, if supported.

Some CMake generators support a toolset specification to tell the native build system how to choose a compiler. See the CMAKE_GENERATOR_TOOLSET variable for details.

-A &lt;platform-name&gt;
Specify platform name if supported by generator.

Some CMake generators support a platform name to be given to the native build system to choose a compiler or SDK. See the CMAKE_GENERATOR_PLATFORM variable for details.

--toolchain &lt;path-to-file&gt;
New in version 3.21.

Specify the cross compiling toolchain file, equivalent to setting CMAKE_TOOLCHAIN_FILE variable. Relative paths are interpreted as relative to the build directory, and if not found, relative to the source directory.

--install-prefix &lt;directory&gt;
New in version 3.21.

Specify the installation directory, used by the CMAKE_INSTALL_PREFIX variable. Must be an absolute path.

-Wno-dev
Suppress developer warnings.

Suppress warnings that are meant for the author of the CMakeLists.txt files. By default this will also turn off deprecation warnings.

-Wdev
Enable developer warnings.

Enable warnings that are meant for the author of the CMakeLists.txt files. By default this will also turn on deprecation warnings.

-Wdeprecated
Enable deprecated functionality warnings.

Enable warnings for usage of deprecated functionality, that are meant for the author of the CMakeLists.txt files.

-Wno-deprecated
Suppress deprecated functionality warnings.

Suppress warnings for usage of deprecated functionality, that are meant for the author of the CMakeLists.txt files.

-Werror=&lt;what&gt;
Treat CMake warnings as errors. &lt;what&gt; must be one of the following:

dev
Make developer warnings errors.

Make warnings that are meant for the author of the CMakeLists.txt files errors. By default this will also turn on deprecated warnings as errors.

deprecated
Make deprecated macro and function warnings errors.

Make warnings for usage of deprecated macros and functions, that are meant for the author of the CMakeLists.txt files, errors.

-Wno-error=&lt;what&gt;
Do not treat CMake warnings as errors. &lt;what&gt; must be one of the following:

dev
Make warnings that are meant for the author of the CMakeLists.txt files not errors. By default this will also turn off deprecated warnings as errors.

deprecated
Make warnings for usage of deprecated macros and functions, that are meant for the author of the CMakeLists.txt files, not errors.

--fresh
New in version 3.24.

Perform a fresh configuration of the build tree. This removes any existing CMakeCache.txt file and associated CMakeFiles/ directory, and recreates them from scratch.

Changed in version 3.30: For dependencies previously populated by FetchContent with the NEW setting for policy CMP0168, their stamp and script files from any previous run will be removed. The download, update, and patch steps will therefore be forced to re-execute.

-L[A][H]
List non-advanced cached variables.

List CACHE variables will run CMake and list all the variables from the CMake CACHE that are not marked as INTERNAL or ADVANCED. This will effectively display current CMake settings, which can then be changed with -D option. Changing some of the variables may result in more variables being created. If A is specified, then it will display also advanced variables. If H is specified, it will also display help for each variable.

-N
View mode only.

Only load the cache. Do not actually run configure and generate steps.

--graphviz=&lt;file&gt;
Generate graphviz of dependencies, see CMakeGraphVizOptions for more.

Generate a graphviz input file that will contain all the library and executable dependencies in the project. See the documentation for CMakeGraphVizOptions for more details.

--system-information [file]
Dump information about this system.

Dump a wide range of information about the current system. If run from the top of a binary tree for a CMake project it will dump additional information such as the cache, log files etc.

--log-level=&lt;level&gt;
Set the log &lt;level&gt;.

The message() command will only output messages of the specified log level or higher. The valid log levels are ERROR, WARNING, NOTICE, STATUS (default), VERBOSE, DEBUG, or TRACE.

To make a log level persist between CMake runs, set CMAKE_MESSAGE_LOG_LEVEL as a cache variable instead. If both the command line option and the variable are given, the command line option takes precedence.

For backward compatibility reasons, --loglevel is also accepted as a synonym for this option.

New in version 3.25: See the cmake_language() command for a way to query the current message logging level.

--log-context
Enable the message() command outputting context attached to each message.

This option turns on showing context for the current CMake run only. To make showing the context persistent for all subsequent CMake runs, set CMAKE_MESSAGE_CONTEXT_SHOW as a cache variable instead. When this command line option is given, CMAKE_MESSAGE_CONTEXT_SHOW is ignored.

--debug-trycompile
Do not delete the files and directories created for try_compile() / try_run() calls. This is useful in debugging failed checks.

Note that some uses of try_compile() may use the same build tree, which will limit the usefulness of this option if a project executes more than one try_compile(). For example, such uses may change results as artifacts from a previous try-compile may cause a different test to either pass or fail incorrectly. This option is best used only when debugging.

(With respect to the preceding, the try_run() command is effectively a try_compile(). Any combination of the two is subject to the potential issues described.)

New in version 3.25: When this option is enabled, every try-compile check prints a log message reporting the directory in which the check is performed.

--debug-output
Put cmake in a debug mode.

Print extra information during the cmake run like stack traces with message(SEND_ERROR) calls.

--debug-find
New in version 3.17.

Put cmake find commands in a debug mode.

Print extra find call information during the cmake run to standard error. Output is designed for human consumption and not for parsing. See also the CMAKE_FIND_DEBUG_MODE variable for debugging a more local part of the project.

--debug-find-pkg=&lt;pkg&gt;[,...]
New in version 3.23.

Put cmake find commands in a debug mode when running under calls to find_package(&lt;pkg&gt;), where &lt;pkg&gt; is an entry in the given comma-separated list of case-sensitive package names.

Like --debug-find, but limiting scope to the specified packages.

--debug-find-var=&lt;var&gt;[,...]
New in version 3.23.

Put cmake find commands in a debug mode when called with &lt;var&gt; as the result variable, where &lt;var&gt; is an entry in the given comma-separated list.

Like --debug-find, but limiting scope to the specified variable names.

--trace
Put cmake in trace mode.

Print a trace of all calls made and from where.

--trace-expand
Put cmake in trace mode.

Like --trace, but with variables expanded.

--trace-format=&lt;format&gt;
New in version 3.17.

Put cmake in trace mode and sets the trace output format.

&lt;format&gt; can be one of the following values.

human
Prints each trace line in a human-readable format. This is the default format.

json-v1
Prints each line as a separate JSON document. Each document is separated by a newline ( \n ). It is guaranteed that no newline characters will be present inside a JSON document.

JSON trace format
{
  &quot;file&quot;: &quot;/full/path/to/the/CMake/file.txt&quot;,
  &quot;line&quot;: 0,
  &quot;cmd&quot;: &quot;add_executable&quot;,
  &quot;args&quot;: [&quot;foo&quot;, &quot;bar&quot;],
  &quot;time&quot;: 1579512535.9687231,
  &quot;frame&quot;: 2,
  &quot;global_frame&quot;: 4
}
The members are:

file
The full path to the CMake source file where the function was called.

line
The line in file where the function call begins.

line_end
If the function call spans multiple lines, this field will be set to the line where the function call ends. If the function calls spans a single line, this field will be unset. This field was added in minor version 2 of the json-v1 format.

defer
Optional member that is present when the function call was deferred by cmake_language(DEFER). If present, its value is a string containing the deferred call &lt;id&gt;.

cmd
The name of the function that was called.

args
A string list of all function parameters.

time
Timestamp (seconds since epoch) of the function call.

frame
Stack frame depth of the function that was called, within the context of the CMakeLists.txt being processed currently.

global_frame
Stack frame depth of the function that was called, tracked globally across all CMakeLists.txt files involved in the trace. This field was added in minor version 2 of the json-v1 format.

Additionally, the first JSON document outputted contains the version key for the current major and minor version of the

JSON version format
{
  &quot;version&quot;: {
    &quot;major&quot;: 1,
    &quot;minor&quot;: 2
  }
}
The members are:

version
Indicates the version of the JSON format. The version has a major and minor components following semantic version conventions.

--trace-source=&lt;file&gt;
Put cmake in trace mode, but output only lines of a specified file.

Multiple options are allowed.

--trace-redirect=&lt;file&gt;
Put cmake in trace mode and redirect trace output to a file instead of stderr.

--warn-uninitialized
Warn about uninitialized values.

Print a warning when an uninitialized variable is used.

--warn-unused-vars
Does nothing. In CMake versions 3.2 and below this enabled warnings about unused variables. In CMake versions 3.3 through 3.18 the option was broken. In CMake 3.19 and above the option has been removed.

--no-warn-unused-cli
Don't warn about command line options.

Don't find variables that are declared on the command line, but not used.

--check-system-vars
Find problems with variable usage in system files.

Normally, unused and uninitialized variables are searched for only in CMAKE_SOURCE_DIR and CMAKE_BINARY_DIR. This flag tells CMake to warn about other files as well.

--compile-no-warning-as-error
New in version 3.24.

Ignore target property COMPILE_WARNING_AS_ERROR and variable CMAKE_COMPILE_WARNING_AS_ERROR, preventing warnings from being treated as errors on compile.

--profiling-output=&lt;path&gt;
New in version 3.18.

Used in conjunction with --profiling-format to output to a given path.

--profiling-format=&lt;file&gt;
Enable the output of profiling data of CMake script in the given format.

This can aid performance analysis of CMake scripts executed. Third party applications should be used to process the output into human readable format.

Currently supported values are: google-trace Outputs in Google Trace Format, which can be parsed by the about:tracing tab of Google Chrome or using a plugin for a tool like Trace Compass.

--preset &lt;preset&gt;, --preset=&lt;preset&gt;
Reads a preset from CMakePresets.json and CMakeUserPresets.json files, which must be located in the same directory as the top level CMakeLists.txt file. The preset may specify the generator, the build directory, a list of variables, and other arguments to pass to CMake. At least one of CMakePresets.json or CMakeUserPresets.json must be present. The CMake GUI also recognizes and supports CMakePresets.json and CMakeUserPresets.json files. For full details on these files, see cmake-presets(7).

The presets are read before all other command line options, although the -S option can be used to specify the source directory containing the CMakePresets.json and CMakeUserPresets.json files. If -S is not given, the current directory is assumed to be the top level source directory and must contain the presets files. The options specified by the chosen preset (variables, generator, etc.) can all be overridden by manually specifying them on the command line. For example, if the preset sets a variable called MYVAR to 1, but the user sets it to 2 with a -D argument, the value 2 is preferred.

--list-presets[=&lt;type&gt;]
Lists the available presets of the specified &lt;type&gt;. Valid values for &lt;type&gt; are configure, build, test, package, or all. If &lt;type&gt; is omitted, configure is assumed. The current working directory must contain CMake preset files unless the -S option is used to specify a different top level source directory.

--debugger
Enables interactive debugging of the CMake language. CMake exposes a debugging interface on the pipe named by --debugger-pipe that conforms to the Debug Adapter Protocol specification with the following modifications.

The initialize response includes an additional field named cmakeVersion which specifies the version of CMake being debugged.

Debugger initialize response
{
  &quot;cmakeVersion&quot;: {
    &quot;major&quot;: 3,
    &quot;minor&quot;: 27,
    &quot;patch&quot;: 0,
    &quot;full&quot;: &quot;3.27.0&quot;
  }
}
The members are:

major
An integer specifying the major version number.

minor
An integer specifying the minor version number.

patch
An integer specifying the patch version number.

full
A string specifying the full CMake version.

--debugger-pipe &lt;pipe name&gt;, --debugger-pipe=&lt;pipe name&gt;
Name of the pipe (on Windows) or domain socket (on Unix) to use for debugger communication.

--debugger-dap-log &lt;log path&gt;, --debugger-dap-log=&lt;log path&gt;
Logs all debugger communication to the specified file.

Build a Project
CMake provides a command-line signature to build an already-generated project binary tree:

cmake --build &lt;dir&gt;             [&lt;options&gt;] [-- &lt;build-tool-options&gt;]
cmake --build --preset &lt;preset&gt; [&lt;options&gt;] [-- &lt;build-tool-options&gt;]
This abstracts a native build tool's command-line interface with the following options:

--build &lt;dir&gt;
Project binary directory to be built. This is required (unless a preset is specified) and must be first.

--preset &lt;preset&gt;, --preset=&lt;preset&gt;
Use a build preset to specify build options. The project binary directory is inferred from the configurePreset key. The current working directory must contain CMake preset files. See preset for more details.

--list-presets
Lists the available build presets. The current working directory must contain CMake preset files.

-j [&lt;jobs&gt;], --parallel [&lt;jobs&gt;]
New in version 3.12.

The maximum number of concurrent processes to use when building. If &lt;jobs&gt; is omitted the native build tool's default number is used.

The CMAKE_BUILD_PARALLEL_LEVEL environment variable, if set, specifies a default parallel level when this option is not given.

Some native build tools always build in parallel. The use of &lt;jobs&gt; value of 1 can be used to limit to a single job.

-t &lt;tgt&gt;..., --target &lt;tgt&gt;...
Build &lt;tgt&gt; instead of the default target. Multiple targets may be given, separated by spaces.

--config &lt;cfg&gt;
For multi-configuration tools, choose configuration &lt;cfg&gt;.

--clean-first
Build target clean first, then build. (To clean only, use --target clean.)

--resolve-package-references=&lt;value&gt;
New in version 3.23.

Resolve remote package references from external package managers (e.g. NuGet) before build. When &lt;value&gt; is set to on (default), packages will be restored before building a target. When &lt;value&gt; is set to only, the packages will be restored, but no build will be performed. When &lt;value&gt; is set to off, no packages will be restored.

If the target does not define any package references, this option does nothing.

This setting can be specified in a build preset (using resolvePackageReferences). The preset setting will be ignored, if this command line option is specified.

If no command line parameter or preset option are provided, an environment- specific cache variable will be evaluated to decide, if package restoration should be performed.

When using the Visual Studio generator, package references are defined using the VS_PACKAGE_REFERENCES property. Package references are restored using NuGet. It can be disabled by setting the CMAKE_VS_NUGET_PACKAGE_RESTORE variable to OFF.

--use-stderr
Ignored. Behavior is default in CMake &gt;= 3.0.

-v, --verbose
Enable verbose output - if supported - including the build commands to be executed.

This option can be omitted if VERBOSE environment variable or CMAKE_VERBOSE_MAKEFILE cached variable is set.

--
Pass remaining options to the native tool.

Run cmake --build with no options for quick help.
</code></pre>
<h2 id="install-a-project"><a class="header" href="#install-a-project">Install a Project</a></h2>
<pre><code>CMake provides a command-line signature to install an already-generated project binary tree:

cmake --install &lt;dir&gt; [&lt;options&gt;]
This may be used after building a project to run installation without using the generated build system or the native build tool. The options are:

--install &lt;dir&gt;
Project binary directory to install. This is required and must be first.

--config &lt;cfg&gt;
For multi-configuration generators, choose configuration &lt;cfg&gt;.

--component &lt;comp&gt;
Component-based install. Only install component &lt;comp&gt;.

--default-directory-permissions &lt;permissions&gt;
Default directory install permissions. Permissions in format &lt;u=rwx,g=rx,o=rx&gt;.

--prefix &lt;prefix&gt;
Override the installation prefix, CMAKE_INSTALL_PREFIX.

--strip
Strip before installing.

-v, --verbose
Enable verbose output.

This option can be omitted if VERBOSE environment variable is set.

Run cmake --install with no options for quick help.
</code></pre>
<h2 id="open-a-project"><a class="header" href="#open-a-project">Open a Project</a></h2>
<pre><code>cmake --open &lt;dir&gt;
Open the generated project in the associated application. This is only supported by some generators.
</code></pre>
<h2 id="run-a-script"><a class="header" href="#run-a-script">Run a Script</a></h2>
<pre><code>cmake [-D &lt;var&gt;=&lt;value&gt;]... -P &lt;cmake-script-file&gt; [-- &lt;unparsed-options&gt;...]
-D &lt;var&gt;=&lt;value&gt;
Define a variable for script mode.

-P &lt;cmake-script-file&gt;
Process the given cmake file as a script written in the CMake language. No configure or generate step is performed and the cache is not modified. If variables are defined using -D, this must be done before the -P argument.

Any options after -- are not parsed by CMake, but they are still included in the set of CMAKE_ARGV&lt;n&gt; variables passed to the script (including the -- itself).
</code></pre>
<h2 id="run-a-command-line-tool"><a class="header" href="#run-a-command-line-tool">Run a Command-Line Tool</a></h2>
<pre><code>CMake provides builtin command-line tools through the signature

cmake -E &lt;command&gt; [&lt;options&gt;]
-E [help]
Run cmake -E or cmake -E help for a summary of commands.

Available commands are:

capabilities
New in version 3.7.

Report cmake capabilities in JSON format. The output is a JSON object with the following keys:

version
A JSON object with version information. Keys are:

string
The full version string as displayed by cmake --version.

major
The major version number in integer form.

minor
The minor version number in integer form.

patch
The patch level in integer form.

suffix
The cmake version suffix string.

isDirty
A bool that is set if the cmake build is from a dirty tree.

generators
A list available generators. Each generator is a JSON object with the following keys:

name
A string containing the name of the generator.

toolsetSupport
true if the generator supports toolsets and false otherwise.

platformSupport
true if the generator supports platforms and false otherwise.

supportedPlatforms
New in version 3.21.

Optional member that may be present when the generator supports platform specification via CMAKE_GENERATOR_PLATFORM (-A ...). The value is a list of platforms known to be supported.

extraGenerators
A list of strings with all the Extra Generators compatible with the generator.

fileApi
Optional member that is present when the cmake-file-api(7) is available. The value is a JSON object with one member:

requests
A JSON array containing zero or more supported file-api requests. Each request is a JSON object with members:

kind
Specifies one of the supported Object Kinds.

version
A JSON array whose elements are each a JSON object containing major and minor members specifying non-negative integer version components.

serverMode
true if cmake supports server-mode and false otherwise. Always false since CMake 3.20.

tls
New in version 3.25.

true if TLS support is enabled and false otherwise.

debugger
New in version 3.27.

true if the --debugger mode is supported and false otherwise.

cat [--] &lt;files&gt;...
New in version 3.18.

Concatenate files and print on the standard output.

--
New in version 3.24.

Added support for the double dash argument --. This basic implementation of cat does not support any options, so using a option starting with - will result in an error. Use -- to indicate the end of options, in case a file starts with -.

New in version 3.29: cat can now print the standard input by passing the - argument.

chdir &lt;dir&gt; &lt;cmd&gt; [&lt;arg&gt;...]
Change the current working directory and run a command.

compare_files [--ignore-eol] &lt;file1&gt; &lt;file2&gt;
Check if &lt;file1&gt; is same as &lt;file2&gt;. If files are the same, then returns 0, if not it returns 1. In case of invalid arguments, it returns 2.

--ignore-eol
New in version 3.14.

The option implies line-wise comparison and ignores LF/CRLF differences.

copy &lt;file&gt;... &lt;destination&gt;, copy -t &lt;destination&gt; &lt;file&gt;...
Copy files to &lt;destination&gt; (either file or directory). If multiple files are specified, or if -t is specified, the &lt;destination&gt; must be directory and it must exist. If -t is not specified, the last argument is assumed to be the &lt;destination&gt;. Wildcards are not supported. copy does follow symlinks. That means it does not copy symlinks, but the files or directories it point to.

New in version 3.5: Support for multiple input files.

New in version 3.26: Support for -t argument.

copy_directory &lt;dir&gt;... &lt;destination&gt;
Copy content of &lt;dir&gt;... directories to &lt;destination&gt; directory. If &lt;destination&gt; directory does not exist it will be created. copy_directory does follow symlinks.

New in version 3.5: Support for multiple input directories.

New in version 3.15: The command now fails when the source directory does not exist. Previously it succeeded by creating an empty destination directory.

copy_directory_if_different &lt;dir&gt;... &lt;destination&gt;
New in version 3.26.

Copy changed content of &lt;dir&gt;... directories to &lt;destination&gt; directory. If &lt;destination&gt; directory does not exist it will be created.

copy_directory_if_different does follow symlinks. The command fails when the source directory does not exist.

copy_if_different &lt;file&gt;... &lt;destination&gt;
Copy files to &lt;destination&gt; (either file or directory) if they have changed. If multiple files are specified, the &lt;destination&gt; must be directory and it must exist. copy_if_different does follow symlinks.

New in version 3.5: Support for multiple input files.

create_symlink &lt;old&gt; &lt;new&gt;
Create a symbolic link &lt;new&gt; naming &lt;old&gt;.

New in version 3.13: Support for creating symlinks on Windows.

Note Path to where &lt;new&gt; symbolic link will be created has to exist beforehand.
create_hardlink &lt;old&gt; &lt;new&gt;
New in version 3.19.

Create a hard link &lt;new&gt; naming &lt;old&gt;.

Note Path to where &lt;new&gt; hard link will be created has to exist beforehand. &lt;old&gt; has to exist beforehand.
echo [&lt;string&gt;...]
Displays arguments as text.

echo_append [&lt;string&gt;...]
Displays arguments as text but no new line.

env [&lt;options&gt;] [--] &lt;command&gt; [&lt;arg&gt;...]
New in version 3.1.

Run command in a modified environment. Options are:

NAME=VALUE
Replaces the current value of NAME with VALUE.

--unset=NAME
Unsets the current value of NAME.

--modify ENVIRONMENT_MODIFICATION
New in version 3.25.

Apply a single ENVIRONMENT_MODIFICATION operation to the modified environment.

The NAME=VALUE and --unset=NAME options are equivalent to --modify NAME=set:VALUE and --modify NAME=unset:, respectively. Note that --modify NAME=reset: resets NAME to the value it had when cmake launched (or unsets it), not to the most recent NAME=VALUE option.

--
New in version 3.24.

Added support for the double dash argument --. Use -- to stop interpreting options/environment variables and treat the next argument as the command, even if it start with - or contains a =.

environment
Display the current environment variables.

false
New in version 3.16.

Do nothing, with an exit code of 1.

make_directory &lt;dir&gt;...
Create &lt;dir&gt; directories. If necessary, create parent directories too. If a directory already exists it will be silently ignored.

New in version 3.5: Support for multiple input directories.

md5sum &lt;file&gt;...
Create MD5 checksum of files in md5sum compatible format:

351abe79cd3800b38cdfb25d45015a15  file1.txt
052f86c15bbde68af55c7f7b340ab639  file2.txt
sha1sum &lt;file&gt;...
New in version 3.10.

Create SHA1 checksum of files in sha1sum compatible format:

4bb7932a29e6f73c97bb9272f2bdc393122f86e0  file1.txt
1df4c8f318665f9a5f2ed38f55adadb7ef9f559c  file2.txt
sha224sum &lt;file&gt;...
New in version 3.10.

Create SHA224 checksum of files in sha224sum compatible format:

b9b9346bc8437bbda630b0b7ddfc5ea9ca157546dbbf4c613192f930  file1.txt
6dfbe55f4d2edc5fe5c9197bca51ceaaf824e48eba0cc453088aee24  file2.txt
sha256sum &lt;file&gt;...
New in version 3.10.

Create SHA256 checksum of files in sha256sum compatible format:

76713b23615d31680afeb0e9efe94d47d3d4229191198bb46d7485f9cb191acc  file1.txt
15b682ead6c12dedb1baf91231e1e89cfc7974b3787c1e2e01b986bffadae0ea  file2.txt
sha384sum &lt;file&gt;...
New in version 3.10.

Create SHA384 checksum of files in sha384sum compatible format:

acc049fedc091a22f5f2ce39a43b9057fd93c910e9afd76a6411a28a8f2b8a12c73d7129e292f94fc0329c309df49434  file1.txt
668ddeb108710d271ee21c0f3acbd6a7517e2b78f9181c6a2ff3b8943af92b0195dcb7cce48aa3e17893173c0a39e23d  file2.txt
sha512sum &lt;file&gt;...
New in version 3.10.

Create SHA512 checksum of files in sha512sum compatible format:

2a78d7a6c5328cfb1467c63beac8ff21794213901eaadafd48e7800289afbc08e5fb3e86aa31116c945ee3d7bf2a6194489ec6101051083d1108defc8e1dba89  file1.txt
7a0b54896fe5e70cca6dd643ad6f672614b189bf26f8153061c4d219474b05dad08c4e729af9f4b009f1a1a280cb625454bf587c690f4617c27e3aebdf3b7a2d  file2.txt
remove [-f] &lt;file&gt;...
Deprecated since version 3.17.

Remove the file(s). The planned behavior was that if any of the listed files already do not exist, the command returns a non-zero exit code, but no message is logged. The -f option changes the behavior to return a zero exit code (i.e. success) in such situations instead. remove does not follow symlinks. That means it remove only symlinks and not files it point to.

The implementation was buggy and always returned 0. It cannot be fixed without breaking backwards compatibility. Use rm instead.

remove_directory &lt;dir&gt;...
Deprecated since version 3.17.

Remove &lt;dir&gt; directories and their contents. If a directory does not exist it will be silently ignored. Use rm instead.

New in version 3.15: Support for multiple directories.

New in version 3.16: If &lt;dir&gt; is a symlink to a directory, just the symlink will be removed.

rename &lt;oldname&gt; &lt;newname&gt;
Rename a file or directory (on one volume). If file with the &lt;newname&gt; name already exists, then it will be silently replaced.

rm [-rRf] [--] &lt;file|dir&gt;...
New in version 3.17.

Remove the files &lt;file&gt; or directories &lt;dir&gt;. Use -r or -R to remove directories and their contents recursively. If any of the listed files/directories do not exist, the command returns a non-zero exit code, but no message is logged. The -f option changes the behavior to return a zero exit code (i.e. success) in such situations instead. Use -- to stop interpreting options and treat all remaining arguments as paths, even if they start with -.

sleep &lt;number&gt;
New in version 3.0.

Sleep for &lt;number&gt; seconds. &lt;number&gt; may be a floating point number. A practical minimum is about 0.1 seconds due to overhead in starting/stopping CMake executable. This can be useful in a CMake script to insert a delay:

# Sleep for about 0.5 seconds
execute_process(COMMAND ${CMAKE_COMMAND} -E sleep 0.5)
tar [cxt][vf][zjJ] file.tar [&lt;options&gt;] [--] [&lt;pathname&gt;...]
Create or extract a tar or zip archive. Options are:

c
Create a new archive containing the specified files. If used, the &lt;pathname&gt;... argument is mandatory.

x
Extract to disk from the archive.

New in version 3.15: The &lt;pathname&gt;... argument could be used to extract only selected files or directories. When extracting selected files or directories, you must provide their exact names including the path, as printed by list (-t).

t
List archive contents.

New in version 3.15: The &lt;pathname&gt;... argument could be used to list only selected files or directories.

v
Produce verbose output.

z
Compress the resulting archive with gzip.

j
Compress the resulting archive with bzip2.

J
New in version 3.1.

Compress the resulting archive with XZ.

--zstd
New in version 3.15.

Compress the resulting archive with Zstandard.

--files-from=&lt;file&gt;
New in version 3.1.

Read file names from the given file, one per line. Blank lines are ignored. Lines may not start in - except for --add-file=&lt;name&gt; to add files whose names start in -.

--format=&lt;format&gt;
New in version 3.3.

Specify the format of the archive to be created. Supported formats are: 7zip, gnutar, pax, paxr (restricted pax, default), and zip.

--mtime=&lt;date&gt;
New in version 3.1.

Specify modification time recorded in tarball entries.

--touch
New in version 3.24.

Use current local timestamp instead of extracting file timestamps from the archive.

--
New in version 3.1.

Stop interpreting options and treat all remaining arguments as file names, even if they start with -.

New in version 3.1: LZMA (7zip) support.

New in version 3.15: The command now continues adding files to an archive even if some of the files are not readable. This behavior is more consistent with the classic tar tool. The command now also parses all flags, and if an invalid flag was provided, a warning is issued.

time &lt;command&gt; [&lt;args&gt;...]
Run &lt;command&gt; and display elapsed time (including overhead of CMake frontend).

New in version 3.5: The command now properly passes arguments with spaces or special characters through to the child process. This may break scripts that worked around the bug with their own extra quoting or escaping.

touch &lt;file&gt;...
Creates &lt;file&gt; if file do not exist. If &lt;file&gt; exists, it is changing &lt;file&gt; access and modification times.

touch_nocreate &lt;file&gt;...
Touch a file if it exists but do not create it. If a file does not exist it will be silently ignored.

true
New in version 3.16.

Do nothing, with an exit code of 0.
</code></pre>
<h2 id="windows-specific-command-line-tools"><a class="header" href="#windows-specific-command-line-tools">Windows-specific Command-Line Tools</a></h2>
<pre><code>The following cmake -E commands are available only on Windows:

delete_regv &lt;key&gt;
Delete Windows registry value.

env_vs8_wince &lt;sdkname&gt;
New in version 3.2.

Displays a batch file which sets the environment for the provided Windows CE SDK installed in VS2005.

env_vs9_wince &lt;sdkname&gt;
New in version 3.2.

Displays a batch file which sets the environment for the provided Windows CE SDK installed in VS2008.

write_regv &lt;key&gt; &lt;value&gt;
Write Windows registry value.
</code></pre>
<h2 id="run-the-find-package-tool"><a class="header" href="#run-the-find-package-tool">Run the Find-Package Tool</a></h2>
<pre><code>CMake provides a pkg-config like helper for Makefile-based projects:

cmake --find-package [&lt;options&gt;]
It searches a package using find_package() and prints the resulting flags to stdout. This can be used instead of pkg-config to find installed libraries in plain Makefile-based projects or in autoconf-based projects (via share/aclocal/cmake.m4).

Note This mode is not well-supported due to some technical limitations. It is kept for compatibility but should not be used in new projects.
</code></pre>
<h2 id="run-a-workflow-preset"><a class="header" href="#run-a-workflow-preset">Run a Workflow Preset</a></h2>
<pre><code>New in version 3.25.

CMake Presets provides a way to execute multiple build steps in order:

cmake --workflow [&lt;options&gt;]
The options are:

--workflow
Select a Workflow Preset using one of the following options.

--preset &lt;preset&gt;, --preset=&lt;preset&gt;
Use a workflow preset to specify a workflow. The project binary directory is inferred from the initial configure preset. The current working directory must contain CMake preset files. See preset for more details.

--list-presets
Lists the available workflow presets. The current working directory must contain CMake preset files.

--fresh
Perform a fresh configuration of the build tree, which has the same effect as cmake --fresh.
</code></pre>
<h2 id="view-help"><a class="header" href="#view-help">View Help</a></h2>
<pre><code>To print selected pages from the CMake documentation, use

cmake --help[-&lt;topic&gt;]
with one of the following options:

-version [&lt;file&gt;], --version [&lt;file&gt;], /V [&lt;file&gt;]
Show program name/version banner and exit. The output is printed to a named &lt;file&gt; if given.

-h, -H, --help, -help, -usage, /?
Print usage information and exit.

Usage describes the basic command line interface and its options.

--help &lt;keyword&gt; [&lt;file&gt;]
Print help for one CMake keyword.

&lt;keyword&gt; can be a property, variable, command, policy, generator or module.

The relevant manual entry for &lt;keyword&gt; is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

Changed in version 3.28: Prior to CMake 3.28, this option supported command names only.

--help-full [&lt;file&gt;]
Print all help manuals and exit.

All manuals are printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-manual &lt;man&gt; [&lt;file&gt;]
Print one help manual and exit.

The specified manual is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-manual-list [&lt;file&gt;]
List help manuals available and exit.

The list contains all manuals for which help may be obtained by using the --help-manual option followed by a manual name. The output is printed to a named &lt;file&gt; if given.

--help-command &lt;cmd&gt; [&lt;file&gt;]
Print help for one command and exit.

The cmake-commands(7) manual entry for &lt;cmd&gt; is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-command-list [&lt;file&gt;]
List commands with help available and exit.

The list contains all commands for which help may be obtained by using the --help-command option followed by a command name. The output is printed to a named &lt;file&gt; if given.

--help-commands [&lt;file&gt;]
Print cmake-commands manual and exit.

The cmake-commands(7) manual is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-module &lt;mod&gt; [&lt;file&gt;]
Print help for one module and exit.

The cmake-modules(7) manual entry for &lt;mod&gt; is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-module-list [&lt;file&gt;]
List modules with help available and exit.

The list contains all modules for which help may be obtained by using the --help-module option followed by a module name. The output is printed to a named &lt;file&gt; if given.

--help-modules [&lt;file&gt;]
Print cmake-modules manual and exit.

The cmake-modules(7) manual is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-policy &lt;cmp&gt; [&lt;file&gt;]
Print help for one policy and exit.

The cmake-policies(7) manual entry for &lt;cmp&gt; is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-policy-list [&lt;file&gt;]
List policies with help available and exit.

The list contains all policies for which help may be obtained by using the --help-policy option followed by a policy name. The output is printed to a named &lt;file&gt; if given.

--help-policies [&lt;file&gt;]
Print cmake-policies manual and exit.

The cmake-policies(7) manual is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-property &lt;prop&gt; [&lt;file&gt;]
Print help for one property and exit.

The cmake-properties(7) manual entries for &lt;prop&gt; are printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-property-list [&lt;file&gt;]
List properties with help available and exit.

The list contains all properties for which help may be obtained by using the --help-property option followed by a property name. The output is printed to a named &lt;file&gt; if given.

--help-properties [&lt;file&gt;]
Print cmake-properties manual and exit.

The cmake-properties(7) manual is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-variable &lt;var&gt; [&lt;file&gt;]
Print help for one variable and exit.

The cmake-variables(7) manual entry for &lt;var&gt; is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

--help-variable-list [&lt;file&gt;]
List variables with help available and exit.

The list contains all variables for which help may be obtained by using the --help-variable option followed by a variable name. The output is printed to a named &lt;file&gt; if given.

--help-variables [&lt;file&gt;]
Print cmake-variables manual and exit.

The cmake-variables(7) manual is printed in a human-readable text format. The output is printed to a named &lt;file&gt; if given.

To view the presets available for a project, use

cmake &lt;source-dir&gt; --list-presets
</code></pre>
<h2 id="return-value-exit-code"><a class="header" href="#return-value-exit-code">Return Value (Exit Code)</a></h2>
<pre><code>Upon regular termination, the cmake executable returns the exit code 0.

If termination is caused by the command message(FATAL_ERROR), or another error condition, then a non-zero exit code is returned.
</code></pre>
<h2 id="see-also"><a class="header" href="#see-also">See Also</a></h2>
<pre><code>The following resources are available to get help using CMake:

Home Page
https://cmake.org

The primary starting point for learning about CMake.

Online Documentation and Community Resources
https://cmake.org/documentation

Links to available documentation and community resources may be found on this web page.

Discourse Forum
https://discourse.cmake.org

The Discourse Forum hosts discussion and questions about CMake.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cmake"><a class="header" href="#cmake">cmake</a></h1>
<h2 id="notes"><a class="header" href="#notes">notes</a></h2>
<pre><code># notes
</code></pre>
<h2 id="command-1"><a class="header" href="#command-1">command</a></h2>
<pre><code>command(arg1 arg2 ...)
</code></pre>
<h2 id="var"><a class="header" href="#var">var</a></h2>
<pre><code>set(FOO abc)
command(${FOO}) //command(abc)
command(&quot;${FOO}&quot;) //command(&quot;abc&quot;)
</code></pre>
<h2 id="flow-control-1"><a class="header" href="#flow-control-1">flow control</a></h2>
<pre><code>if()...else()/elseif()...endif()
while()...endwhile()
foreach()...endforeach()
</code></pre>
<h2 id="command-list"><a class="header" href="#command-list">command list</a></h2>
<pre><code>include_directories(&quot;dir1&quot; &quot;dir2&quot; ...) //-Idir1 -Idir2
link_directories(&quot;dir1&quot; &quot;dir2&quot;)
aux_source_directory(&quot;source-dir&quot; variable)
add_executable()
add_library()
add_custom_target()
add_dependencies(target1 t2 t3)
add_definitions(&quot;-Wall -ansi&quot;)
target_link_libraries(target-name lib1 lib2 ...)
link_libraries(lib1 lib2 ...)
set_target_properties(...)
message(...)
install(files &quot;f1&quot; &quot;f2&quot; destination)
set(variable value)
list(append|insert|length|get|remove_item|remove_at|sort ...)
string(toupper|tolower|length|substring|replace|regex ...)
separate_arguments(variable)
file(write|read|append|glob|glob_recurse|remove|make_directory ...)
find_file()
find_path()
find_library()
find_program()
find_package()
exec_program(bin [work_dir] args &lt;..&gt; [output_variable var] [return_value var])
option(option_var &quot;description&quot; [initial value])
</code></pre>
<h2 id="variable"><a class="header" href="#variable">variable</a></h2>
<h3 id="project-path"><a class="header" href="#project-path">project path</a></h3>
<pre><code>CMAKE_SOURCE_DIR
PROJECT_SOURCE_DIR
&lt;projectname&gt;_SOURCE_DIR
</code></pre>
<h3 id="root-path"><a class="header" href="#root-path">root path</a></h3>
<pre><code>CMAKE_BINARY_DIR
PROJECT_BINARY_DIR
&lt;projectname&gt;_BINARY_DIR
</code></pre>
<h3 id="current-path"><a class="header" href="#current-path">current path</a></h3>
<pre><code>CMAKE_CURRENT_SOURCE_DIR
CMAKE_CURRENT_BINARY_DIR
CMAKE_CURRENT_LIST_FILE
</code></pre>
<h3 id="cmakeliststxt-path"><a class="header" href="#cmakeliststxt-path">CMakeLists.txt path</a></h3>
<pre><code>CMAKE_BUILD_TYPE
</code></pre>
<h2 id="debug-or-release"><a class="header" href="#debug-or-release">debug or release</a></h2>
<pre><code>set(CMAKE_BUILD_TYPE Debug)
cmake DCMAKE_BUILD_TYPE=Release
</code></pre>
<h2 id="build-args"><a class="header" href="#build-args">build args</a></h2>
<pre><code>CMAKE_C_FLAGS
CMAKE_CXX_FLAGS
CMAKE_INCLUDE_PATH
CMAKE_LIBRARY_PATH
CMAKE_MODULE_PATH
CMAKE_INSTALL_PREFIX
BUILD_SHARED_LIBS
</code></pre>
<h2 id="example-1"><a class="header" href="#example-1">example 1</a></h2>
<pre><code>cmake_minimum_required(VERSION 3.0)
project(c_demo)

include_directories(header)
set(SRC src/main.cpp)
aux_source_directory(src SRC)
add_executable(c_demo ${SRC})
</code></pre>
<h1 id="cmake-1"><a class="header" href="#cmake-1">cmake</a></h1>
<h2 id="include_directories"><a class="header" href="#include_directories">INCLUDE_DIRECTORIES</a></h2>
<pre><code>include_directories(&quot;/xxx/include&quot;)
export CPLUS_INCLUDE_PATH=CPLUS_INCLUDE_PATH:/xxx/include
</code></pre>
<h2 id="link_directories"><a class="header" href="#link_directories">LINK_DIRECTORIES</a></h2>
<pre><code>link_directories(directory1 directory2 ...)
</code></pre>
<pre><code>LINK_DIRECTORIES(&quot;/xxx/lib&quot;)
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/xxx/lib
</code></pre>
<h2 id="link_libraries"><a class="header" href="#link_libraries">LINK_LIBRARIES</a></h2>
<pre><code>LINK_LIBRARIES(&quot;/xxx/lib/libeng.so&quot;)
</code></pre>
<p>or</p>
<pre><code>LINK_LIBRARIES(&quot;/xxx/lib/libeng.so&quot;　&quot;/xxx/lib/libmx.so&quot;)
</code></pre>
<h2 id="target_link_libraries"><a class="header" href="#target_link_libraries">TARGET_LINK_LIBRARIES</a></h2>
<pre><code>TARGET_LINK_LIBRARIES(targetlibrary1 &lt;debug | optimized&gt; library2 ..)
</code></pre>
<pre><code>TARGET_LINK_LIBRARIES(myProject hello)
TARGET_LINK_LIBRARIES(myProject libhello.a)
TARGET_LINK_LIBRARIES(myProject libhello.so)
</code></pre>
<p>or</p>
<pre><code>TARGET_LINK_LIBRARIES(myProject libeng.so)
TARGET_LINK_LIBRARIES(myProject eng)
TARGET_LINK_LIBRARIES(myProject -leng)
</code></pre>
<h2 id="example"><a class="header" href="#example">example</a></h2>
<pre><code>cmake_minimum_required(VERSION 3.0 FATAL_ERROR)
 
include_directories(&quot;/xxx/include&quot;)
 
#directly link to the libraries.
link_libraries(&quot;/xxx/lib/libeng.so&quot;)
link_libraries(&quot;/xxx/lib/libmx.so&quot;)
 
#equals to below
link_libraries(&quot;/xxx/lib/libeng.so&quot; &quot;/xxx/lib/libmx.so&quot;)
 
add_executable(myProject main.cpp) 
</code></pre>
<pre><code>cmake_minimum_required(VERSION 3.0 FATAL_ERROR)
 
include_directories(&quot;/xxx/include&quot;)

link_directories(&quot;/xxx/lib&quot;)
 
add_executable(myProject main.cpp)
 
target_link_libraries(myProject eng mx)
 
#equals to below
#target_link_libraries(myProject -leng -lmx)
#target_link_libraries(myProject libeng.so libmx.so)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sample-1"><a class="header" href="#sample-1">sample</a></h1>
<h2 id="project-name-1"><a class="header" href="#project-name-1">project name</a></h2>
<pre><code>project(project_name)
</code></pre>
<h2 id="version-required-1"><a class="header" href="#version-required-1">version required</a></h2>
<pre><code>cmake_minimum_required(VERSION 3.0)
</code></pre>
<h2 id="set-source-dir-1"><a class="header" href="#set-source-dir-1">set source dir</a></h2>
<pre><code>aux_source_directory(&lt;dir&gt; &lt;variable&gt;)
aux_source_directory(. DIR_SRCS)
</code></pre>
<h2 id="add-subdirectory-1"><a class="header" href="#add-subdirectory-1">add subdirectory</a></h2>
<pre><code>add_subdirectory(&lt;dir&gt;)
</code></pre>
<h2 id="add-static-library-1"><a class="header" href="#add-static-library-1">add static library</a></h2>
<pre><code>add_library(lib_name STATIC source_list)
</code></pre>
<h2 id="add-shared-library-1"><a class="header" href="#add-shared-library-1">add shared library</a></h2>
<pre><code>add_library(lib_name SHARED source_list)
</code></pre>
<h2 id="add-executable-1"><a class="header" href="#add-executable-1">add executable</a></h2>
<pre><code>add_executable(exe_name source_list)
</code></pre>
<h2 id="link-library-1"><a class="header" href="#link-library-1">link library</a></h2>
<pre><code>target_link_libraries(exe_name lib_name)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="openssl"><a class="header" href="#openssl">openssl</a></h1>
<h2 id="1-生成私钥"><a class="header" href="#1-生成私钥">1. 生成私钥</a></h2>
<pre><code>openssl genrsa -out private.pem 2048
</code></pre>
<h2 id="2-基于私钥生成公钥"><a class="header" href="#2-基于私钥生成公钥">2. 基于私钥生成公钥</a></h2>
<pre><code>openssl rsa -in private.pem -pubout -out public.pem
</code></pre>
<h2 id="3-查看-asn1-格式的私钥"><a class="header" href="#3-查看-asn1-格式的私钥">3. 查看 ASN.1 格式的私钥</a></h2>
<pre><code>openssl asn1parse -i -in private.pem
</code></pre>
<h2 id="4-查看-asn1-格式的公钥"><a class="header" href="#4-查看-asn1-格式的公钥">4. 查看 ASN.1 格式的公钥</a></h2>
<pre><code>openssl asn1parse -i -in public.pem
openssl asn1parse -i -in public.pem -strparse 16
</code></pre>
<h2 id="5-对文件-hellotxt-加密"><a class="header" href="#5-对文件-hellotxt-加密">5. 对文件 hello.txt 加密</a></h2>
<pre><code>openssl rsautl -encrypt -in hello.txt -inkey public.pem -pubin -out hello.en
</code></pre>
<h2 id="6-对文件-helloen-解密"><a class="header" href="#6-对文件-helloen-解密">6. 对文件 hello.en 解密</a></h2>
<pre><code>openssl rsautl -decrypt -in hello.en -inkey private.pem -out hello.de
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="openssl-1"><a class="header" href="#openssl-1">openssl</a></h1>
<h2 id="1-生成私钥-1"><a class="header" href="#1-生成私钥-1">1. 生成私钥</a></h2>
<pre><code>openssl genrsa -out private.pem 2048
</code></pre>
<h2 id="2-基于私钥生成公钥-1"><a class="header" href="#2-基于私钥生成公钥-1">2. 基于私钥生成公钥</a></h2>
<pre><code>openssl rsa -in private.pem -pubout -out public.pem
</code></pre>
<h2 id="3-查看-asn1-格式的私钥-1"><a class="header" href="#3-查看-asn1-格式的私钥-1">3. 查看 ASN.1 格式的私钥</a></h2>
<pre><code>openssl asn1parse -i -in private.pem
</code></pre>
<h2 id="4-查看-asn1-格式的公钥-1"><a class="header" href="#4-查看-asn1-格式的公钥-1">4. 查看 ASN.1 格式的公钥</a></h2>
<pre><code>openssl asn1parse -i -in public.pem
openssl asn1parse -i -in public.pem -strparse 16
</code></pre>
<h2 id="5-对文件-hellotxt-加密-1"><a class="header" href="#5-对文件-hellotxt-加密-1">5. 对文件 hello.txt 加密</a></h2>
<pre><code>openssl rsautl -encrypt -in hello.txt -inkey public.pem -pubin -out hello.en
</code></pre>
<h2 id="6-对文件-helloen-解密-1"><a class="header" href="#6-对文件-helloen-解密-1">6. 对文件 hello.en 解密</a></h2>
<pre><code>openssl rsautl -decrypt -in hello.en -inkey private.pem -out hello.de
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="openssl-rsa"><a class="header" href="#openssl-rsa">openssl rsa</a></h1>
<h2 id="generate-private-key"><a class="header" href="#generate-private-key">generate private key</a></h2>
<pre><code>openssl genrsa -out private.pem 2048
</code></pre>
<h2 id="generate-public-key"><a class="header" href="#generate-public-key">generate public key</a></h2>
<pre><code>openssl rsa -in private.pem -pubout -out public.pem
</code></pre>
<h2 id="parse-pkcs-not-necessary"><a class="header" href="#parse-pkcs-not-necessary">parse PKCS (not necessary)</a></h2>
<pre><code>openssl pkcs8 -topk8 -inform PEM -in private.pem -outform PEM –nocrypt
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vscode-csharp"><a class="header" href="#vscode-csharp">vscode csharp</a></h1>
<h2 id="vscode-extension"><a class="header" href="#vscode-extension">vscode extension</a></h2>
<h3 id="net-runtime-install-tool"><a class="header" href="#net-runtime-install-tool">.NET Runtime Install Tool</a></h3>
<pre><code>&quot;dotnetAcquisitionExtension.existingDotnetPath&quot;: [
    {
        &quot;extensionId&quot;: &quot;ms-dotnettools.csharp&quot;,
        &quot;path&quot;: &quot;/path/dotnet/dotnet&quot;,
    }
],
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vscode-csharp-1"><a class="header" href="#vscode-csharp-1">vscode csharp</a></h1>
<h2 id="vscode-extension-1"><a class="header" href="#vscode-extension-1">vscode extension</a></h2>
<h3 id="net-runtime-install-tool-1"><a class="header" href="#net-runtime-install-tool-1">.NET Runtime Install Tool</a></h3>
<pre><code>&quot;dotnetAcquisitionExtension.existingDotnetPath&quot;: [
    {
        &quot;extensionId&quot;: &quot;ms-dotnettools.csharp&quot;,
        &quot;path&quot;: &quot;/path/dotnet/dotnet&quot;,
    }
],
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="export"><a class="header" href="#export">export</a></h1>
<h2 id="export-class"><a class="header" href="#export-class">export class</a></h2>
<pre><code>class __declspec(dllexport) XXX {
    public:
        XXX();
        
        ~XXX();

        void xxx();
};
</code></pre>
<h2 id="export-function"><a class="header" href="#export-function">export function</a></h2>
<pre><code>extern &quot;C&quot; __declspec(dllexport) void xxx();
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="export-1"><a class="header" href="#export-1">export</a></h1>
<h2 id="export-class-1"><a class="header" href="#export-class-1">export class</a></h2>
<pre><code>class __declspec(dllexport) XXX {
    public:
        XXX();
        
        ~XXX();

        void xxx();
};
</code></pre>
<h2 id="export-function-1"><a class="header" href="#export-function-1">export function</a></h2>
<pre><code>extern &quot;C&quot; __declspec(dllexport) void xxx();
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="explain"><a class="header" href="#explain">explain</a></h1>
<h2 id="example-1"><a class="header" href="#example-1">example</a></h2>
<pre><code>explain select distinct course_id from course where course_term = 'xxx';
 
NOTICE:  QUERY PLAN:
 
Unique  (cost=12223.09..12339.76 rows=4667 width=4)
 
               -&gt; Sort (cost=12223.09..12223.09 rows=46666 width=4)
 
               -&gt;  Seq Scan on course  (cost=0.00..8279.99 rows=46666 width=4)
1.从下往上读，从右往左
2.explain报告查询的操作，开启的消耗，查询总的消耗，访问的行数 访问的平均宽度
3.开启时间消耗是输出开始前的时间例如排序的时间
4.消耗包括磁盘检索页，cpu时间 
5.注意，每一步的cost包括上一步的
6.重要的是，explain 不是真正的执行一次查询 只是得到查询执行的计划和估计的花费
</code></pre>
<h2 id="options-3"><a class="header" href="#options-3">options</a></h2>
<div class="table-wrapper"><table><thead><tr><th>执行计划运算类型</th><th>操作说明</th><th>是否有启动时间</th></tr></thead><tbody>
<tr><td>SeqScan</td><td>扫描表</td><td>无启动时间</td></tr>
<tr><td>IndexScan</td><td>索引扫描</td><td></td></tr>
<tr><td>Bitmap</td><td>IndexScan索引扫描</td><td>有启动时间</td></tr>
<tr><td>Bitmap</td><td>HeapScan索引扫描</td><td>有启动时间</td></tr>
<tr><td>Subquery</td><td>Scan子查询</td><td>无启动时间</td></tr>
<tr><td>TidScan</td><td>ctid=…条件</td><td>无启动时间</td></tr>
<tr><td>FunctionScan</td><td>函数扫描</td><td>无启动时间</td></tr>
<tr><td>NestedLoop</td><td>循环结合</td><td>无启动时间</td></tr>
<tr><td>MergeJoin</td><td>合并结合</td><td>有启动时间</td></tr>
<tr><td>HashJoin</td><td>哈希结合</td><td>有启动时间</td></tr>
<tr><td>Sort</td><td>排序，ORDERBY操作</td><td>有启动时间</td></tr>
<tr><td>Hash</td><td>哈希运算</td><td>有启动时间</td></tr>
<tr><td>Result</td><td>函数扫描，和具体的表无关</td><td>无启动时间</td></tr>
<tr><td>Unique</td><td>DISTINCT，UNION操作</td><td>有启动时间</td></tr>
<tr><td>Limit</td><td>LIMIT，OFFSET操作</td><td>有启动时间</td></tr>
<tr><td>Aggregate</td><td>count,sum,avg,stddev集约函数</td><td>有启动时间</td></tr>
<tr><td>Group</td><td>GROUPBY分组操作</td><td>有启动时间</td></tr>
<tr><td>Append</td><td>UNION操作</td><td>无启动时间</td></tr>
<tr><td>Materialize</td><td>子查询</td><td>有启动时间</td></tr>
<tr><td>SetOp</td><td>INTERCECT，EXCEPT</td><td>有启动时间</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="explain-1"><a class="header" href="#explain-1">explain</a></h1>
<h2 id="example-2"><a class="header" href="#example-2">example</a></h2>
<pre><code>explain select distinct course_id from course where course_term = 'xxx';
 
NOTICE:  QUERY PLAN:
 
Unique  (cost=12223.09..12339.76 rows=4667 width=4)
 
               -&gt; Sort (cost=12223.09..12223.09 rows=46666 width=4)
 
               -&gt;  Seq Scan on course  (cost=0.00..8279.99 rows=46666 width=4)
1.从下往上读，从右往左
2.explain报告查询的操作，开启的消耗，查询总的消耗，访问的行数 访问的平均宽度
3.开启时间消耗是输出开始前的时间例如排序的时间
4.消耗包括磁盘检索页，cpu时间 
5.注意，每一步的cost包括上一步的
6.重要的是，explain 不是真正的执行一次查询 只是得到查询执行的计划和估计的花费
</code></pre>
<h2 id="options-4"><a class="header" href="#options-4">options</a></h2>
<div class="table-wrapper"><table><thead><tr><th>执行计划运算类型</th><th>操作说明</th><th>是否有启动时间</th></tr></thead><tbody>
<tr><td>SeqScan</td><td>扫描表</td><td>无启动时间</td></tr>
<tr><td>IndexScan</td><td>索引扫描</td><td></td></tr>
<tr><td>Bitmap</td><td>IndexScan索引扫描</td><td>有启动时间</td></tr>
<tr><td>Bitmap</td><td>HeapScan索引扫描</td><td>有启动时间</td></tr>
<tr><td>Subquery</td><td>Scan子查询</td><td>无启动时间</td></tr>
<tr><td>TidScan</td><td>ctid=…条件</td><td>无启动时间</td></tr>
<tr><td>FunctionScan</td><td>函数扫描</td><td>无启动时间</td></tr>
<tr><td>NestedLoop</td><td>循环结合</td><td>无启动时间</td></tr>
<tr><td>MergeJoin</td><td>合并结合</td><td>有启动时间</td></tr>
<tr><td>HashJoin</td><td>哈希结合</td><td>有启动时间</td></tr>
<tr><td>Sort</td><td>排序，ORDERBY操作</td><td>有启动时间</td></tr>
<tr><td>Hash</td><td>哈希运算</td><td>有启动时间</td></tr>
<tr><td>Result</td><td>函数扫描，和具体的表无关</td><td>无启动时间</td></tr>
<tr><td>Unique</td><td>DISTINCT，UNION操作</td><td>有启动时间</td></tr>
<tr><td>Limit</td><td>LIMIT，OFFSET操作</td><td>有启动时间</td></tr>
<tr><td>Aggregate</td><td>count,sum,avg,stddev集约函数</td><td>有启动时间</td></tr>
<tr><td>Group</td><td>GROUPBY分组操作</td><td>有启动时间</td></tr>
<tr><td>Append</td><td>UNION操作</td><td>无启动时间</td></tr>
<tr><td>Materialize</td><td>子查询</td><td>有启动时间</td></tr>
<tr><td>SetOp</td><td>INTERCECT，EXCEPT</td><td>有启动时间</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="常用io操作"><a class="header" href="#常用io操作">常用IO操作</a></h1>
<ul>
<li>export one database</li>
</ul>
<pre><code>mysqldump -u dbuser -p dbname &gt; dbname.sql
</code></pre>
<ul>
<li>export one table</li>
</ul>
<pre><code>mysqldump -u dbuser -p dbname tbname &gt; dbname_tb.sql
</code></pre>
<ul>
<li>export one database or table structure</li>
</ul>
<pre><code>mysqldump -u dbuser -p -d --add-drop-table dbname &gt; dbname.db
mysqldump -u dbuser -p -d --add-drop-table dbname tbname &gt; dbname_tb.db
-d no data
--add-drop-table  add drop table before create table
</code></pre>
<ul>
<li>export query</li>
</ul>
<pre><code>mysql -u dbuser -p --default-character-set=gbk -e &quot;select * from tbname&quot; dbname &gt; tbname.db
</code></pre>
<ul>
<li>import data</li>
</ul>
<pre><code>mysql -u dbuser -p --default-character-set=gbk
mysql&gt;show databases;
mysql&gt;use dbname;
mysql&gt;source dbname.sql;
</code></pre>
<ul>
<li>import one database or table</li>
</ul>
<pre><code>mysql -u dbuser -p --default-character-set=gbk dbname &lt; dbname.db
mysql -u dbuser -p --default-character-set=gbk dbname tbname &lt; dbname_tb.db
</code></pre>
<ul>
<li>show database</li>
</ul>
<pre><code>mysql -u dbuser -p --default-character-set=gbk
mysql&gt;show databases;
mysql&gt;create database dbname default character set utf8 collate utf8_general_ci;
mysql&gt;use dbname;
mysql&gt;show tables;
mysql&gt;show columns from tbname;
</code></pre>
<h1 id="重置密码"><a class="header" href="#重置密码">重置密码</a></h1>
<ul>
<li>view version</li>
</ul>
<pre><code>mysql --version
</code></pre>
<ul>
<li>edit /etc/my.cnf</li>
</ul>
<pre><code># [mysqld] add content
skip-grant-tables
</code></pre>
<ul>
<li>restart mysql</li>
</ul>
<pre><code>service mysqld restart
</code></pre>
<ul>
<li>edit password for root</li>
</ul>
<pre><code>mysql
mysql&gt;update mysql.user set password = password('toor') where user = 'root';
mysql&gt;flush privileges;
mysql&gt;exit
</code></pre>
<ul>
<li>edit /etc/my.cnf</li>
</ul>
<pre><code># [mysqld] remove content
skip-grant-tables
</code></pre>
<ul>
<li>restart mysql</li>
</ul>
<pre><code>service mysqld restart
</code></pre>
<ul>
<li>login mysql</li>
</ul>
<pre><code>mysql -uroot -p
</code></pre>
<h1 id="允许远程连接"><a class="header" href="#允许远程连接">允许远程连接</a></h1>
<pre><code>mysql -root -p
mysql&gt;use mysql;
mysql&gt;select host, user from user;
mysql&gt;update user set host = '%' where user = 'root';
mysql&gt;flush privileges;
</code></pre>
<h1 id="删除空用户名的记录"><a class="header" href="#删除空用户名的记录">删除空用户名的记录</a></h1>
<ul>
<li>stop mysql</li>
</ul>
<pre><code>service mysqld stop
</code></pre>
<ul>
<li>skip grant</li>
</ul>
<pre><code>mysqld_safe --skip-grant-table
</code></pre>
<ul>
<li>open a new terminal</li>
</ul>
<pre><code>mysql -u root mysql
mysql&gt;delete from user where user = '';
mysql&gt;flush privileges;
mysql&gt;\q 
</code></pre>
<h1 id="查询语句执行顺序"><a class="header" href="#查询语句执行顺序">查询语句执行顺序</a></h1>
<p><img src="db/../static/img/db/dborder.jpg" alt="" /></p>
<pre><code>(01) from
(02) on
(03) join
(04) where
(05) group by
(06) avg, sum....
(07) having
(08) select
(09) distinct
(10) order by
(11) limit
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pg-function"><a class="header" href="#pg-function">pg function</a></h1>
<h2 id="do-for-loop"><a class="header" href="#do-for-loop">do for loop</a></h2>
<pre><code>DO 
$$
DECLARE 
r RECORD;
BEGIN
    FOR r IN (SELECT * FROM xxx) LOOP
    RAISE NOTICE 'row:%', r;
    END LOOP;
END;
$$;
</code></pre>
<h2 id="function"><a class="header" href="#function">function</a></h2>
<pre><code>CREATE OR REPLACE FUNCTION test()
RETURNS void
AS
$$
DECLARE
r RECORD;
BEGIN 
    FOR r IN (SELECT * FROM xxx) LOOP
    RAISE NOTICE 'row:%', r;
    END LOOP;
END;
$$
LANGUAGE plpgsql;
SELECT test() AS output;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pg-locks"><a class="header" href="#pg-locks">PG LOCKS</a></h1>
<h2 id="table-lock"><a class="header" href="#table-lock">TABLE LOCK</a></h2>
<ul>
<li>ACCESS SHARE</li>
<li>ROW SHARE</li>
<li>ROW EXCLUSIVE</li>
<li>SHARE UPDATE EXCLUSIVE</li>
<li>SHARE</li>
<li>SHARE ROW EXCLUSIVE</li>
<li>EXCLUSIVE</li>
<li>ACCESS EXCLUSIVE</li>
</ul>
<p><img src="db/../static/img/db/pg_lock/table_lock.png" alt="" /></p>
<h3 id="access-share"><a class="header" href="#access-share">ACCESS SHARE</a></h3>
<ul>
<li>1、SELECT 产生的锁</li>
<li>2、与ACCESS EXCLUSIVE冲突</li>
</ul>
<h3 id="row-share"><a class="header" href="#row-share">ROW SHARE</a></h3>
<ul>
<li>1、SELECT FOR UPDATE 、SELECT FOR SHARE 产生的锁</li>
<li>2、与EXCLUSIVE 、ACCESS EXCLUSIVE冲突</li>
</ul>
<h3 id="row-exclusive"><a class="header" href="#row-exclusive">ROW EXCLUSIVE</a></h3>
<ul>
<li>1、UPDATE、DELETE、与INSERT 产生的锁</li>
<li>2、与SHARE、SHARE ROW EXCLUSIVE、EXCLUSIVE、ACCESS EXCLUSIVE冲突</li>
</ul>
<h3 id="share-update-exclusive"><a class="header" href="#share-update-exclusive">SHARE UPDATE EXCLUSIVE</a></h3>
<ul>
<li>1、VACUUM (WITHOUT FULL)、ANALYZE、CREATE INDEX CONCURRENTLY、CREATE STATISTICS、COMMENT ON、 ALTER TABLE VALIDATE 、 OTHER ALTER TABLE VARIANTS 产生的锁</li>
<li>2、与SHARE UPDATE EXCLUSIVE、SHARE、SHARE ROW EXCLUSIVE、EXCLUSIVE、ACCESS EXCLUSIVE冲突</li>
</ul>
<h3 id="share"><a class="header" href="#share">SHARE</a></h3>
<ul>
<li>1、CREATE INDEX 产生的锁</li>
<li>2、与ROW EXCLUSIVE、SHARE UPDATE EXCLUSIVE、SHARE ROW EXCLUSIVE、EXCLUSIVE、ACCESS EXCLUSIVE冲突</li>
</ul>
<h3 id="share-row-exclusive"><a class="header" href="#share-row-exclusive">SHARE ROW EXCLUSIVE</a></h3>
<ul>
<li>1、CREATE COLLATION、CREATE TRIGGER、AND MANY FORMS OF ALTER TABLE 产生的锁</li>
<li>2、与ROW EXCLUSIVE、SHARE UPDATE EXCLUSIVE、SHARE、SHARE ROW EXCLUSIVE、EXCLUSIVE、AND ACCESS EXCLUSIVE 冲突</li>
</ul>
<h3 id="exclusive"><a class="header" href="#exclusive">EXCLUSIVE</a></h3>
<ul>
<li>1、刷新物化视图REFRESH MATERIALIZED VIEW CONCURRENTLY 产生的锁</li>
<li>2、与ROW SHARE、ROW EXCLUSIVE、SHARE UPDATE EXCLUSIVE、SHARE、SHARE ROW EXCLUSIVE、EXCLUSIVE、ACCESS EXCLUSIVE冲突</li>
</ul>
<h3 id="access-exclusive"><a class="header" href="#access-exclusive">ACCESS EXCLUSIVE</a></h3>
<ul>
<li>1、DROP TABLE、TRUNCATE、REINDEX、CLUSTER、VACUUM FULL、REFRESH MATERIALIZED VIEW (WITHOUT CONCURRENTLY) 产生的锁</li>
<li>2、与ACCESS SHARE、ROW SHARE、ROW EXCLUSIVE、SHARE UPDATE EXCLUSIVE、SHARE、SHARE ROW EXCLUSIVE、EXCLUSIVE、ACCESS EXCLUSIVE冲突</li>
</ul>
<h2 id="row-lock"><a class="header" href="#row-lock">ROW LOCK</a></h2>
<ul>
<li>FOR KEY SHARE</li>
<li>FOR SHARE</li>
<li>FOR NO KEY UPDATE</li>
<li>FOR UPDATE</li>
</ul>
<p><img src="db/../static/img/db/pg_lock/row_lock.png" alt="" /></p>
<h3 id="for-update"><a class="header" href="#for-update">FOR UPDATE</a></h3>
<p>对于所有的 FOR UPDATE 操作，对于被检索的数据行进行 FOR UPDATE 行锁锁定，阻止其他事务对持有 FOR UPDATE 行锁记录进行更新。在 RR 和 SERIALIZABLE 隔离级别下，如果一个被 FOR UPDATE 锁定的行在当前事务开始后被修改，该事务会抛出异常报错。对于 UPDATE、DELETE 操作同样需要获取 FOR UPDATE 行模式锁。</p>
<h3 id="for-no-key-update"><a class="header" href="#for-no-key-update">FOR NO KEY UPDATE</a></h3>
<p>与 FOR UPDATE 行模式锁类似，但是其锁范围相对较弱。对于不需要获取 FOR UPDATE 行锁资源的所有 UPDATE、DELETE 操作都会持有该行模式锁。在 RR 和 SERIALIZABLE 隔离级别下，如果一个被 FOR UPDATE 锁定的行在当前事务开始后被修改，该事务会抛出异常报错。</p>
<h3 id="for-share"><a class="header" href="#for-share">FOR SHARE</a></h3>
<p>对于检索记录添加 SHARE LOCK，该模式锁资源会阻塞其他事务对持有锁记录进行 UPDATE、DELETE、SELECT FOR UPDATE、FOR NO KEY UPDATE，但允许其他事务并发添加FOR SHARE 或者 FOR KEY SHARE。</p>
<h3 id="for-key-share"><a class="header" href="#for-key-share">FOR KEY SHARE</a></h3>
<p>相对于FOR SHARE，该模式锁相对更加弱一些,他允许其他事务并发持有 FOR NO KEY UPDATE 模式锁资源。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pg-size"><a class="header" href="#pg-size">pg size</a></h1>
<h2 id="database-size-with-index"><a class="header" href="#database-size-with-index">database size with index</a></h2>
<pre><code>select pg_size_pretty(pg_total_size('mydb'));
</code></pre>
<h2 id="database-size-without-index"><a class="header" href="#database-size-without-index">database size without index</a></h2>
<pre><code>select pg_size_pretty(pg_database_size('mydb'));
</code></pre>
<h2 id="index-size"><a class="header" href="#index-size">index size</a></h2>
<pre><code>select pg_size_pretty(pg_indexes_size('mytable'));
</code></pre>
<h2 id="table-size-with-index"><a class="header" href="#table-size-with-index">table size with index</a></h2>
<pre><code>select pg_size_pretty(pg_total_relation_size('mytable'));
</code></pre>
<h2 id="table-size-without-index"><a class="header" href="#table-size-without-index">table size without index</a></h2>
<pre><code>select pg_size_pretty(pg_relation_size('mytable'));
</code></pre>
<h2 id="tablespace-size"><a class="header" href="#tablespace-size">tablespace size</a></h2>
<pre><code>select pg_size_pretty(pg_tablespace_size('pg_global'));
</code></pre>
<h2 id="table-file-path"><a class="header" href="#table-file-path">table file path</a></h2>
<pre><code>select pg_relation_filepath('mytable');
</code></pre>
<h2 id="switch-log"><a class="header" href="#switch-log">switch log</a></h2>
<pre><code>select pg_switch_xlog();
</code></pre>
<h2 id="switch-next-log-file"><a class="header" href="#switch-next-log-file">switch next log file</a></h2>
<pre><code>select pg_rotate_logfile();
</code></pre>
<h2 id="reference"><a class="header" href="#reference">reference</a></h2>
<pre><code>select
	table_name,
	pg_size_pretty(table_size) as table_size,
	pg_size_pretty(indexes_size) as indexes_size,
	pg_size_pretty(total_size) as total_size
from
	(
	select
		table_name,
		pg_table_size(table_name) as table_size,
		pg_indexes_size(table_name) as indexes_size,
		pg_total_relation_size(table_name) as total_size
	from
		(
		select
			('&quot;' || table_schema || '&quot;.&quot;' || table_name || '&quot;') as table_name
		from
			information_schema.tables
) as all_tables
	order by
		total_size desc
) as pretty_sizes;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="postgres-command"><a class="header" href="#postgres-command">postgres command</a></h1>
<h2 id="connect"><a class="header" href="#connect">connect</a></h2>
<pre><code>psql -h &lt;host&gt; -p &lt;port&gt; -d &lt;dbname&gt; -U &lt;uname&gt; -W &lt;password&gt;
</code></pre>
<h2 id="dump-and-restore"><a class="header" href="#dump-and-restore">dump and restore</a></h2>
<pre><code>pg_dump -h &lt;host&gt; -p &lt;port&gt; -d &lt;dbname&gt; -U &lt;uname&gt; -W &lt;password&gt; -Fc &gt; test.dmp
pg_restore -h &lt;host&gt; -p &lt;port&gt; -d &lt;dbname&gt; -U &lt;uname&gt; -W &lt;password&gt; &lt; test.dmp
psql -h &lt;host&gt; -p &lt;port&gt; -d &lt;dbname&gt; -U &lt;uname&gt; -W &lt;password&gt; -f test.dmp
</code></pre>
<h2 id="display"><a class="header" href="#display">display</a></h2>
<h3 id="list-database"><a class="header" href="#list-database">list database</a></h3>
<pre><code>\l &lt;dbname&gt;
</code></pre>
<h3 id="connect-database"><a class="header" href="#connect-database">connect database</a></h3>
<pre><code>\c &lt;dbname&gt;
</code></pre>
<h3 id="list-table"><a class="header" href="#list-table">list table</a></h3>
<pre><code>\dt
</code></pre>
<h3 id="list-index"><a class="header" href="#list-index">list index</a></h3>
<pre><code>\di
</code></pre>
<h2 id="role-and-user"><a class="header" href="#role-and-user">role and user</a></h2>
<h3 id="create-user"><a class="header" href="#create-user">create user</a></h3>
<pre><code>create role &lt;rname&gt; password &lt;password&gt;;
create user &lt;uname&gt; password &lt;password&gt;;

</code></pre>
<h3 id="change-password"><a class="header" href="#change-password">change password</a></h3>
<pre><code>\password &lt;uname&gt;
alter user &lt;uname&gt; password &lt;password&gt;;
</code></pre>
<h3 id="config-user"><a class="header" href="#config-user">config user</a></h3>
<pre><code>alter role &lt;rname&gt; login;
alter user &lt;uname&gt; superuser|nosuperuser;
alter user &lt;uname&gt; createdb|nocreatedb;
alter user &lt;uname&gt; createrole|nocreaterole;
alter user &lt;uname&gt; createuser|nocreateuser;
alter user &lt;uname&gt; inherit|noinherit;
alter user &lt;uname&gt; login|nologin;
alter user &lt;uname&gt; replication|noreplication;
</code></pre>
<h3 id="config-connection"><a class="header" href="#config-connection">config connection</a></h3>
<pre><code>alter user &lt;uname&gt; connection limit 10|-1;
</code></pre>
<h3 id="config-group"><a class="header" href="#config-group">config group</a></h3>
<pre><code>create group &lt;gname&gt;;
grant &lt;gname&gt; to &lt;rname1&gt;,&lt;rname2&gt;;
revoke &lt;gname&gt; from &lt;rname1&gt;,&lt;rname2&gt;;
grant all on database &lt;dbname&gt; to &lt;gname&gt;;
revoke all on database &lt;dbname&gt; from &lt;gname&gt;;
grant all on all tables in schema &lt;public&gt; to &lt;gname&gt;;
revoke all on all tables in schema &lt;public&gt; from &lt;gname&gt;;
</code></pre>
<h3 id="drop-group"><a class="header" href="#drop-group">drop group</a></h3>
<pre><code>drop owned by &lt;gname&gt; cascade;
drop user &lt;gname&gt;;
</code></pre>
<h3 id="drop-user"><a class="header" href="#drop-user">drop user</a></h3>
<pre><code>revoke all on database &lt;dbname&gt; from &lt;uname&gt;;
revoke all on all tables in schema &lt;public&gt; from &lt;uname&gt;;
alter table &lt;tbname&gt; owner to &lt;newuser&gt;;
drop user &lt;uname&gt;;
</code></pre>
<h2 id="drop-user-other-way"><a class="header" href="#drop-user-other-way">drop user other way</a></h2>
<pre><code>drop owned by &lt;uname&gt; cascade;
drop user &lt;uname&gt;;
</code></pre>
<h3 id="create-database-owner"><a class="header" href="#create-database-owner">create database owner</a></h3>
<pre><code>create database &lt;dbname&gt; owner &lt;uname&gt;;
</code></pre>
<h3 id="change-owner"><a class="header" href="#change-owner">change owner</a></h3>
<pre><code>alter database &lt;dbname&gt; owner to &lt;uname&gt;;
alter table &lt;tbname&gt; owner to &lt;uname&gt;;
</code></pre>
<h2 id="grant"><a class="header" href="#grant">grant</a></h2>
<h3 id="grant-schema"><a class="header" href="#grant-schema">grant schema</a></h3>
<pre><code>grant usage on schema &lt;public&gt; to &lt;uname&gt;;
</code></pre>
<h3 id="grant-database-all-privileges"><a class="header" href="#grant-database-all-privileges">grant database all privileges</a></h3>
<pre><code>grant all on database &lt;dbname&gt; to &lt;uname&gt;;
</code></pre>
<h3 id="revoke-database-all-privileges"><a class="header" href="#revoke-database-all-privileges">revoke database all privileges</a></h3>
<pre><code>revoke all on database &lt;dbname&gt; from &lt;uname&gt;;
</code></pre>
<h3 id="grant-database-connect"><a class="header" href="#grant-database-connect">grant database connect</a></h3>
<pre><code>grant connect on database &lt;dbname&gt; to &lt;uname&gt;;
</code></pre>
<h3 id="grant-one-table-all-privileges"><a class="header" href="#grant-one-table-all-privileges">grant one table all privileges</a></h3>
<pre><code>grant all on table &lt;tbname&gt; to &lt;uname&gt;;
</code></pre>
<h3 id="revoke-one-table-all-privileges"><a class="header" href="#revoke-one-table-all-privileges">revoke one table all privileges</a></h3>
<pre><code>revoke all on table &lt;tbname&gt; from &lt;uname&gt;;
</code></pre>
<h3 id="grant-all-tables-one-operation"><a class="header" href="#grant-all-tables-one-operation">grant all tables one operation</a></h3>
<pre><code>grant &lt;select&gt; on all tables in schema &lt;public&gt; to &lt;uname&gt;;
</code></pre>
<h3 id="revoke-all-tables-one-operation"><a class="header" href="#revoke-all-tables-one-operation">revoke all tables one operation</a></h3>
<pre><code>revoke &lt;select&gt; on all tables in schema &lt;public&gt; from &lt;uname&gt;;
</code></pre>
<h3 id="grant-one-table-one-operation"><a class="header" href="#grant-one-table-one-operation">grant one table one operation</a></h3>
<pre><code>grant &lt;update&gt; on table &lt;tbname&gt; to &lt;uname&gt;;
</code></pre>
<h3 id="revoke-one-table-one-operation"><a class="header" href="#revoke-one-table-one-operation">revoke one table one operation</a></h3>
<pre><code>revoke &lt;update&gt; on table &lt;tbname&gt; from &lt;uname&gt;;
</code></pre>
<h3 id="grant-one-table-one-operation-for-all-user"><a class="header" href="#grant-one-table-one-operation-for-all-user">grant one table one operation for all user</a></h3>
<pre><code>grant &lt;select&gt; on table &lt;tbname&gt; to public;
</code></pre>
<h3 id="revoke-one-table-one-operation-for-all-user"><a class="header" href="#revoke-one-table-one-operation-for-all-user">revoke one table one operation for all user</a></h3>
<pre><code>revoke &lt;select&gt; on table &lt;tbname&gt; from public;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="recursive"><a class="header" href="#recursive">recursive</a></h1>
<h2 id="ddl"><a class="header" href="#ddl">ddl</a></h2>
<pre><code>create table if not exists dept (
    id bigint,
    name varchar,
    pid bigint default 0,
    level int default 1
)
</code></pre>
<h2 id="dml"><a class="header" href="#dml">dml</a></h2>
<pre><code>insert into dept values
(1, 'dept1', 0, 1),
(2, 'dept2', 0, 1),
(3, 'dept11', 1, 2),
(4, 'dept21', 2, 2),
(5, 'dept111', 3, 3),
(6, 'dept211', 4, 3),
(7, 'dept1111', 5, 4),
(8, 'dept2111', 6, 4),
(9, 'dept11111', 7, 5);
</code></pre>
<h2 id="downward"><a class="header" href="#downward">downward</a></h2>
<pre><code>with recursive
dd as (
    select d1.id, d1.pid, d1.name, d1.level
    from dept d1
    where d1.name = 'dept2'
    union
    select d2.id, d2.pid, d2.name, d2.level
    from dept d2
    join dd
    on d2.pid = dd.id
)
select id, pid, name, level from dd;
</code></pre>
<h2 id="upward"><a class="header" href="#upward">upward</a></h2>
<pre><code>with recursive
dd as (
    select d1.id, d1.pid, d1.name, d1.level
    from dept d1
    where d1.name = 'dept11111'
    union
    select d2.id, d2.pid, d2.name, d2.level
    from dept d2
    join dd
    on d2.id = dd.pid
)
select id, pid, name, level from dd;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="uuid"><a class="header" href="#uuid">uuid</a></h1>
<h2 id="postgres-uuid"><a class="header" href="#postgres-uuid">postgres uuid</a></h2>
<pre><code>CREATE EXTENSION &quot;uuid-ossp&quot;;

CREATE TABLE IF NOT EXISTS user_info (
    id uuid DEFAULT uuid_generate_v4(),
    username varchar(100),
    nickname varchar(100)
);

INSERT INTO user_info (username, nickname) VALUES 
('zhangsan', '张三');
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dockerfile-中的-copy-与-add-命令"><a class="header" href="#dockerfile-中的-copy-与-add-命令">Dockerfile 中的 COPY 与 ADD 命令</a></h1>
<h2 id="build-上下文的概念"><a class="header" href="#build-上下文的概念">Build 上下文的概念</a></h2>
<p>在使用 docker build 命令通过 Dockerfile 创建镜像时，会产生一个 build 上下文(context)。所谓的 build 上下文就是 docker build 命令的 PATH 或 URL 指定的路径中的文件的集合。在镜像 build 过程中可以引用上下文中的任何文件，比如我们要介绍的 COPY 和 ADD 命令，就可以引用上下文中的文件。</p>
<p>默认情况下 docker build -t testx . 命令中的 . 表示 build 上下文为当前目录。当然我们可以指定一个目录作为上下文，比如下面的命令：</p>
<pre><code>docker build -t testx /home/nick/hc
</code></pre>
<p>我们指定 /home/nick/hc 目录为 build 上下文，默认情况下 docker 会使用在上下文的根目录下找到的 Dockerfile 文件。</p>
<h3 id="copy-和-add-命令不能拷贝上下文之外的本地文件"><a class="header" href="#copy-和-add-命令不能拷贝上下文之外的本地文件">COPY 和 ADD 命令不能拷贝上下文之外的本地文件</a></h3>
<p>对于 COPY 和 ADD 命令来说，如果要把本地的文件拷贝到镜像中，那么本地的文件必须是在上下文目录中的文件。其实这一点很好解释，因为在执行 build 命令时，docker 客户端会把上下文中的所有文件发送给 docker daemon。考虑 docker 客户端和 docker daemon 不在同一台机器上的情况，build 命令只能从上下文中获取文件。如果我们在 Dockerfile 的 COPY 和 ADD 命令中引用了上下文中没有的文件，就会收到类似下面的错误：</p>
<p><img src="docker/../static/img/docker/d001.png" alt="" /></p>
<h3 id="与-workdir-协同工作"><a class="header" href="#与-workdir-协同工作">与 WORKDIR 协同工作</a></h3>
<p>WORKDIR 命令为后续的 RUN、CMD、COPY、ADD 等命令配置工作目录。在设置了 WORKDIR 命令后，接下来的 COPY 和 ADD 命令中的相对路径就是相对于 WORKDIR 指定的路径。比如我们在 Dockerfile 中添加下面的命令：</p>
<pre><code>WORKDIR /app
COPY checkredis.py .
</code></pre>
<p>然后构建名称为 testx 的容器镜像，并运行一个容器查看文件路径：</p>
<p><img src="docker/../static/img/docker/d002.png" alt="" /></p>
<p>checkredis.py 文件就是被复制到了 WORKDIR /app 目录下。</p>
<h2 id="copy-命令的简单性"><a class="header" href="#copy-命令的简单性">COPY 命令的简单性</a></h2>
<p>如果仅仅是把本地的文件拷贝到容器镜像中，COPY 命令是最合适不过的。其命令的格式为：</p>
<pre><code>COPY &lt;src&gt; &lt;dest&gt;
</code></pre>
<p>除了指定完整的文件名外，COPY 命令还支持 Go 风格的通配符，比如：</p>
<pre><code>COPY check* /testdir/           # 拷贝所有 check 开头的文件
COPY check?.log /testdir/       # ? 是单个字符的占位符，比如匹配文件 check1.log
</code></pre>
<p>对于目录而言，COPY 和 ADD 命令具有相同的特点：只复制目录中的内容而不包含目录自身。比如我们在 Dockerfile 中添加下面的命令：</p>
<pre><code>WORKDIR /app
COPY nickdir .
</code></pre>
<p>其中 nickdir 目录的结构如下：</p>
<p><img src="docker/../static/img/docker/d003.png" alt="" /></p>
<p>重新构建镜像 testx，运行一个容器并查看 /app 目录下的内容：</p>
<p><img src="docker/../static/img/docker/d004.png" alt="" /></p>
<p>这里只有 file1 和 file2，少了一层目录 nickdir。如果想让 file1 和 file2 还保存在 nickdir 目录中，需要在目标路径中指定这个目录的名称，比如：</p>
<pre><code>WORKDIR /app
COPY nickdir ./nickdir
</code></pre>
<p>COPY 命令区别于 ADD 命令的一个用法是在 multistage 场景下。关于 multistage 的介绍和用法请参考笔者的《Dockerfile 中的 multi-stage》一文。在 multistage 的用法中，可以使用 COPY 命令把前一阶段构建的产物拷贝到另一个镜像中，比如：</p>
<pre><code>FROM golang:1.11.11
WORKDIR /go/src/github.com/sparkdevo/href-counter/
RUN go get -d -v golang.org/x/net/html
COPY app.go .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=0 /go/src/github.com/sparkdevo/href-counter/app .
CMD [&quot;./app&quot;]
</code></pre>
<p>这段代码引用自《Dockerfile 中的 multi-stage》一文，其中的 COPY 命令通过指定 --from=0 参数，把前一阶段构建的产物拷贝到了当前的镜像中。</p>
<h2 id="add-命令还可以干其它事情"><a class="header" href="#add-命令还可以干其它事情">ADD 命令还可以干其它事情</a></h2>
<p>ADD 命令的格式和 COPY 命令相同，也是：</p>
<pre><code>ADD &lt;src&gt; &lt;dest&gt;
</code></pre>
<p>除了不能用在 multistage 的场景下，ADD 命令可以完成 COPY 命令的所有功能，并且还可以完成两类超酷的功能：</p>
<ul>
<li>
<p>解压压缩文件并把它们添加到镜像中</p>
</li>
<li>
<p>从 url 拷贝文件到镜像中</p>
</li>
</ul>
<p>当然，这些功能也让 ADD 命令用起来复杂一些，不如 COPY 命令那么直观。</p>
<h3 id="解压压缩文件并把它们添加到镜像中"><a class="header" href="#解压压缩文件并把它们添加到镜像中">解压压缩文件并把它们添加到镜像中</a></h3>
<p>如果我们有一个压缩文件包，并且需要把这个压缩包中的文件添加到镜像中。需不需要先解开压缩包然后执行 COPY 命令呢？当然不需要！我们可以通过 ADD 命令一次搞定：</p>
<pre><code>WORKDIR /app
ADD nickdir.tar.gz .
</code></pre>
<p>这应该是 ADD 命令的最佳使用场景了！</p>
<h3 id="从-url-拷贝文件到镜像中"><a class="header" href="#从-url-拷贝文件到镜像中">从 url 拷贝文件到镜像中</a></h3>
<p>这是一个更加酷炫的用法！但是在 docker 官方文档的最佳实践中却强烈建议不要这么用！！docker 官方建议我们当需要从远程复制文件时，最好使用 curl 或 wget 命令来代替 ADD 命令。原因是，当使用 ADD 命令时，会创建更多的镜像层，当然镜像的 size 也会更大(下面的两段代码来自 docker 官方文档)：</p>
<pre><code>ADD http://example.com/big.tar.xz /usr/src/things/
RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things
RUN make -C /usr/src/things all
</code></pre>
<p>如果使用下面的命令，不仅镜像的层数减少，而且镜像中也不包含 big.tar.xz 文件：</p>
<pre><code>RUN mkdir -p /usr/src/things \
    &amp;&amp; curl -SL http://example.com/big.tar.xz \
    | tar -xJC /usr/src/things \
    &amp;&amp; make -C /usr/src/things all
</code></pre>
<p>好吧，看起来只有在解压压缩文件并把它们添加到镜像中时才需要 ADD 命令！</p>
<h2 id="加速镜像构建的技巧"><a class="header" href="#加速镜像构建的技巧">加速镜像构建的技巧</a></h2>
<p>在使用 COPY 和 ADD 命令时，我们可以通过一些技巧来加速镜像的 build 过程。比如把那些最不容易发生变化的文件的拷贝操作放在较低的镜像层中，这样在重新 build 镜像时就会使用前面 build 产生的缓存。比如笔者构建镜像时需要用到下面几个文件：</p>
<p><img src="docker/../static/img/docker/d005.png" alt="" /></p>
<p>其中 myhc.py 文件不经常变化，而 checkmongo.py、checkmysql.py 和 checkredis.py 这三个文件则经常变化，那么我们可这样来设计 Dockerfile 文件：</p>
<pre><code>WORKDIR /app
COPY myhc.py .
COPY check* ./
</code></pre>
<p>让 COPY myhc.py . 单独占据一个镜像层，当 build 过一次后，每次因 checkmongo.py、checkmysql.py 和 checkredis.py 这三个文件变化而导致的重新 build 都不会重新 build COPY myhc.py . 镜像层：</p>
<p><img src="docker/../static/img/docker/d006.png" alt="" /></p>
<p>如上图所示，第二步和第三步都没有重新 build 镜像层，而是使用了之前的缓存，从第四步才开始重新 build 了镜像层。当文件 size 比较大且文件的数量又比较多，尤其是需要执行安装等操作时，这样的设计对于 build 速度的提升还是很明显的。所以我们应该尽量选择能够使用缓存的 Dockerfile 写法。</p>
<h2 id="总结"><a class="header" href="#总结">总结</a></h2>
<p>当第一次看到 COPY 和 ADD 命令时不免让人感到疑惑。但分析之后大家会发现 COPY 命令是为最基本的用法设计的，概念清晰，操作简单。而 ADD 命令基本上是 COPY 命令的超集(除了 multistage 场景)，可以实现一些方便、酷炫的拷贝操作。ADD 命令在增加了功能的同时也增加了使用它的复杂度，比如从 url 拷贝压缩文件时弊大于利。希望本文能够解去大家对 Dockerfile 中 COPY 和 ADD 命令的疑惑。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker-elk"><a class="header" href="#docker-elk">docker elk</a></h1>
<h2 id="elasticsearch"><a class="header" href="#elasticsearch">elasticsearch</a></h2>
<ul>
<li>Copy and paste to pull this image</li>
</ul>
<pre><code>docker pull elastic/elasticsearch:tag
</code></pre>
<ul>
<li>Running in Development Mode</li>
</ul>
<p>Create user defined network (useful for connecting to other services attached to the same network (e.g. Kibana)):</p>
<pre><code>docker network create somenetwork
</code></pre>
<p>Run Elasticsearch:</p>
<pre><code>docker run -d --name elasticsearch --net somenetwork -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elastic/elasticsearch:7.0.0
</code></pre>
<ul>
<li>Running in Production Mode</li>
</ul>
<p>See Install Elasticsearch with Docker</p>
<h2 id="logstash"><a class="header" href="#logstash">logstash</a></h2>
<ul>
<li>Pipeline Configuration</li>
</ul>
<p>It is essential to place your pipeline configuration where it can be found by Logstash. By default, the container will look in /usr/share/logstash/pipeline/ for pipeline configuration files.</p>
<p>In this example we use a bind-mounted volume to provide the configuration via the docker run command:</p>
<pre><code>docker run --rm -it -v ~/pipeline/:/usr/share/logstash/pipeline/ elastic/logstash:7.0.0
</code></pre>
<p>Every file in the host directory ~/pipeline/ will then be parsed by Logstash as pipeline configuration.</p>
<p>If you don’t provide configuration to Logstash, it will run with a minimal config that listens for messages from the Beats input plugin and echoes any that are received to stdout. In this case, the startup logs will be similar to the following:</p>
<pre><code>Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties.
[2016-10-26T05:11:34,992][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=&gt;&quot;0.0.0.0:5044&quot;}
[2016-10-26T05:11:35,068][INFO ][logstash.pipeline        ] Starting pipeline {&quot;id&quot;=&gt;&quot;main&quot;, &quot;pipeline.workers&quot;=&gt;4, &quot;pipeline.batch.size&quot;=&gt;125, &quot;pipeline.batch.delay&quot;=&gt;5, &quot;pipeline.max_inflight&quot;=&gt;500}
[2016-10-26T05:11:35,078][INFO ][org.logstash.beats.Server] Starting server on port: 5044
[2016-10-26T05:11:35,078][INFO ][logstash.pipeline        ] Pipeline main started
[2016-10-26T05:11:35,105][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=&gt;9600}
</code></pre>
<p>This is the default configuration for the image, defined in /usr/share/logstash/pipeline/logstash.conf. If this is the behaviour that you are observing, ensure that your pipeline configuration is being picked up correctly, and that you are replacing either logstash.conf or the entire pipeline directory.</p>
<ul>
<li>Settings</li>
</ul>
<p>The image provides several methods for configuring settings. The conventional approach is to provide a custom logstash.yml file, but it’s also possible to use environment variables to define settings.</p>
<ul>
<li>Bind-mounted settings files</li>
</ul>
<p>Settings files can also be provided through bind-mounts. Logstash expects to find them at /usr/share/logstash/config/.</p>
<p>It’s possible to provide an entire directory containing all needed files:</p>
<pre><code>docker run --rm -it -v ~/settings/:/usr/share/logstash/config/ elastic/logstash:7.0.0
</code></pre>
<p>Alternatively, a single file can be mounted:</p>
<pre><code>docker run --rm -it -v ~/settings/logstash.yml:/usr/share/logstash/config/logstash.yml elastic/logstash:7.0.0
</code></pre>
<ul>
<li>Custom Images</li>
</ul>
<p>Bind-mounted configuration is not the only option, naturally. If you prefer the Immutable Infrastructure approach, you can prepare a custom image containing your configuration by using a Dockerfile like this one:</p>
<pre><code>FROM docker.elastic.co/logstash/logstash:7.0.0
RUN rm -f /usr/share/logstash/pipeline/logstash.conf
ADD pipeline/ /usr/share/logstash/pipeline/
ADD config/ /usr/share/logstash/config/
</code></pre>
<p>Be sure to replace or delete logstash.conf in your custom image, so that you don’t retain the example config from the base image.</p>
<ul>
<li>Environment variable configuration</li>
</ul>
<p>Under Docker, Logstash settings can be configured via environment variables. When the container starts, a helper process checks the environment for variables that can be mapped to Logstash settings. Settings that are found in the environment are merged into logstash.yml as the container starts up.</p>
<p>For compatibility with container orchestration systems, these environment variables are written in all capitals, with underscores as word separators</p>
<p>Some example translations are shown here:</p>
<p>Table 1. Example Docker Environment Variables</p>
<pre><code>Environment Variable        Logstash Setting
PIPELINE_WORKERS            pipeline.workers
LOG_LEVEL                   log.level
XPACK_MONITORING_ENABLED    xpack.monitoring.enabled
</code></pre>
<p>In general, any setting listed in the settings documentation can be configured with this technique.</p>
<p>Note:Defining settings with environment variables causes logstash.yml to be modified in place. This behaviour is likely undesirable if logstash.yml was bind-mounted from the host system. Thus, it is not recommended to combine the bind-mount technique with the environment variable technique. It is best to choose a single method for defining Logstash settings.</p>
<ul>
<li>Docker defaults</li>
</ul>
<p>The following settings have different default values when using the Docker images:</p>
<pre><code>http.host                               0.0.0.0
xpack.monitoring.elasticsearch.hosts    http://elasticsearch:9200
</code></pre>
<p>Note:The setting xpack.monitoring.elasticsearch.hosts is not defined in the -oss image.</p>
<p>These settings are defined in the default logstash.yml. They can be overridden with a custom logstash.yml or via environment variables.</p>
<ul>
<li>IMPORTANT</li>
</ul>
<p>If replacing logstash.yml with a custom version, be sure to copy the above defaults to the custom file if you want to retain them. If not, they will be &quot;masked&quot; by the new file.</p>
<ul>
<li>Logging Configuration</li>
</ul>
<p>Under Docker, Logstash logs go to standard output by default. To change this behaviour, use any of the techniques above to replace the file at /usr/share/logstash/config/log4j2.properties.</p>
<h2 id="kibana"><a class="header" href="#kibana">kibana</a></h2>
<ul>
<li>Copy and paste to pull this image</li>
</ul>
<pre><code>docker pull elastic/kibana:tag
</code></pre>
<ul>
<li>Running in Development Mode</li>
</ul>
<p>In the given example, Kibana will a attach to a user defined network (useful for connecting to other services (e.g. Elasticsearch)). If network has not yet been created, this can be done with the following command:</p>
<pre><code>docker network create somenetwork
</code></pre>
<p>Note:In this example, Kibana is using the default configuration and expects to connect to a running Elasticsearch instance at http://localhost:9200</p>
<p>Run Kibana</p>
<pre><code>docker run -d --name kibana --net somenetwork -p 5601:5601 elastic/kibana:7.0.0
</code></pre>
<p>Kibana can be accessed by browser via http://localhost:5601 or http://host-ip:5601</p>
<ul>
<li>Running in Production Mode</li>
</ul>
<p>For additional information on running and configuring Kibana on Docker, see Running Kibana on Docker</p>
<h2 id="filebeat"><a class="header" href="#filebeat">filebeat</a></h2>
<ul>
<li>Copy and paste to pull this image</li>
</ul>
<p>Obtaining Filebeat for Docker is as simple as issuing a docker pull command against the Elastic Docker registry.</p>
<pre><code>docker pull elastic/filebeat:tag
</code></pre>
<p>Alternatively, you can download other Docker images that contain only features available under the Apache 2.0 license. To download the images, go to www.docker.elastic.co.</p>
<ul>
<li>Run the Filebeat setup</li>
</ul>
<p>Running Filebeat with the setup command will create the index pattern and load visualizations , dashboards, and machine learning jobs. Run this command:</p>
<pre><code>docker run \
elastic/filebeat:7.0.0 \
setup -E setup.kibana.host=kibana:5601 \
-E output.elasticsearch.hosts=[&quot;elasticsearch:9200&quot;]
</code></pre>
<p>Substitute your Kibana and Elasticsearch hosts and ports.</p>
<p>If you are using the hosted Elasticsearch Service in Elastic Cloud, replace the -E output.elasticsearch.hosts line with the Cloud ID and elastic password using this syntax:</p>
<pre><code>-E cloud.id=&lt;Cloud ID from Elasticsearch Service&gt; \
-E cloud.auth=elastic:&lt;elastic password&gt;
</code></pre>
<ul>
<li>Configure Filebeat on Docker</li>
</ul>
<p>The Docker image provides several methods for configuring Filebeat. The conventional approach is to provide a configuration file via a volume mount, but it’s also possible to create a custom image with your configuration included.</p>
<ul>
<li>Example configuration file</li>
</ul>
<p>Download this example configuration file as a starting point:</p>
<pre><code>curl -L -O https://raw.githubusercontent.com/elastic/beats/7.0/deploy/docker/filebeat.docker.yml
</code></pre>
<ul>
<li>Volume-mounted configuration</li>
</ul>
<p>One way to configure Filebeat on Docker is to provide filebeat.docker.yml via a volume mount. With docker run, the volume mount can be specified like this.</p>
<pre><code>docker run -d \
  --name=filebeat \
  --user=root \
  --volume=&quot;$(pwd)/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml:ro&quot; \
  --volume=&quot;/var/lib/docker/containers:/var/lib/docker/containers:ro&quot; \
  --volume=&quot;/var/run/docker.sock:/var/run/docker.sock:ro&quot; \
  docker.elastic.co/beats/filebeat:7.0.0 filebeat -e -strict.perms=false \
  -E output.elasticsearch.hosts=[&quot;elasticsearch:9200&quot;]
</code></pre>
<p>Substitute your Elasticsearch hosts and ports.</p>
<p>If you are using the hosted Elasticsearch Service in Elastic Cloud, replace the -E output.elasticsearch.hosts line with the Cloud ID and elastic password using the syntax shown earlier.</p>
<ul>
<li>Customize your configuration</li>
</ul>
<p>The filebeat.docker.yml file you downloaded earlier is configured to deploy Beats modules based on the Docker labels applied to your containers. See Hints based autodiscover for more details. Add labels to your application Docker containers, and they will be picked up by the Beats autodiscover feature when they are deployed. Here is an example command for an Apache HTTP Server container with labels to configure the Filebeat and Metricbeat modules for the Apache HTTP Server:</p>
<pre><code>docker run \
  --label co.elastic.logs/module=apache2 \
  --label co.elastic.logs/fileset.stdout=access \
  --label co.elastic.logs/fileset.stderr=error \
  --label co.elastic.metrics/module=apache \
  --label co.elastic.metrics/metricsets=status \
  --label co.elastic.metrics/hosts='${data.host}:${data.port}' \
  --detach=true \
  --name my-apache-app \
  -p 8080:80 \
  httpd:2.4
</code></pre>
<ul>
<li>Custom image configuration</li>
</ul>
<p>It’s possible to embed your Filebeat configuration in a custom image. Here is an example Dockerfile to achieve this:</p>
<pre><code>FROM docker.elastic.co/beats/filebeat:7.0.0
COPY filebeat.yml /usr/share/filebeat/filebeat.yml
USER root
RUN chown root:filebeat /usr/share/filebeat/filebeat.yml
USER filebeat
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker-elk-1"><a class="header" href="#docker-elk-1">docker elk</a></h1>
<h2 id="elasticsearch-1"><a class="header" href="#elasticsearch-1">elasticsearch</a></h2>
<ul>
<li>Copy and paste to pull this image</li>
</ul>
<pre><code>docker pull elastic/elasticsearch:tag
</code></pre>
<ul>
<li>Running in Development Mode</li>
</ul>
<p>Create user defined network (useful for connecting to other services attached to the same network (e.g. Kibana)):</p>
<pre><code>docker network create somenetwork
</code></pre>
<p>Run Elasticsearch:</p>
<pre><code>docker run -d --name elasticsearch --net somenetwork -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elastic/elasticsearch:7.0.0
</code></pre>
<ul>
<li>Running in Production Mode</li>
</ul>
<p>See Install Elasticsearch with Docker</p>
<h2 id="logstash-1"><a class="header" href="#logstash-1">logstash</a></h2>
<ul>
<li>Pipeline Configuration</li>
</ul>
<p>It is essential to place your pipeline configuration where it can be found by Logstash. By default, the container will look in /usr/share/logstash/pipeline/ for pipeline configuration files.</p>
<p>In this example we use a bind-mounted volume to provide the configuration via the docker run command:</p>
<pre><code>docker run --rm -it -v ~/pipeline/:/usr/share/logstash/pipeline/ elastic/logstash:7.0.0
</code></pre>
<p>Every file in the host directory ~/pipeline/ will then be parsed by Logstash as pipeline configuration.</p>
<p>If you don’t provide configuration to Logstash, it will run with a minimal config that listens for messages from the Beats input plugin and echoes any that are received to stdout. In this case, the startup logs will be similar to the following:</p>
<pre><code>Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties.
[2016-10-26T05:11:34,992][INFO ][logstash.inputs.beats    ] Beats inputs: Starting input listener {:address=&gt;&quot;0.0.0.0:5044&quot;}
[2016-10-26T05:11:35,068][INFO ][logstash.pipeline        ] Starting pipeline {&quot;id&quot;=&gt;&quot;main&quot;, &quot;pipeline.workers&quot;=&gt;4, &quot;pipeline.batch.size&quot;=&gt;125, &quot;pipeline.batch.delay&quot;=&gt;5, &quot;pipeline.max_inflight&quot;=&gt;500}
[2016-10-26T05:11:35,078][INFO ][org.logstash.beats.Server] Starting server on port: 5044
[2016-10-26T05:11:35,078][INFO ][logstash.pipeline        ] Pipeline main started
[2016-10-26T05:11:35,105][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=&gt;9600}
</code></pre>
<p>This is the default configuration for the image, defined in /usr/share/logstash/pipeline/logstash.conf. If this is the behaviour that you are observing, ensure that your pipeline configuration is being picked up correctly, and that you are replacing either logstash.conf or the entire pipeline directory.</p>
<ul>
<li>Settings</li>
</ul>
<p>The image provides several methods for configuring settings. The conventional approach is to provide a custom logstash.yml file, but it’s also possible to use environment variables to define settings.</p>
<ul>
<li>Bind-mounted settings files</li>
</ul>
<p>Settings files can also be provided through bind-mounts. Logstash expects to find them at /usr/share/logstash/config/.</p>
<p>It’s possible to provide an entire directory containing all needed files:</p>
<pre><code>docker run --rm -it -v ~/settings/:/usr/share/logstash/config/ elastic/logstash:7.0.0
</code></pre>
<p>Alternatively, a single file can be mounted:</p>
<pre><code>docker run --rm -it -v ~/settings/logstash.yml:/usr/share/logstash/config/logstash.yml elastic/logstash:7.0.0
</code></pre>
<ul>
<li>Custom Images</li>
</ul>
<p>Bind-mounted configuration is not the only option, naturally. If you prefer the Immutable Infrastructure approach, you can prepare a custom image containing your configuration by using a Dockerfile like this one:</p>
<pre><code>FROM docker.elastic.co/logstash/logstash:7.0.0
RUN rm -f /usr/share/logstash/pipeline/logstash.conf
ADD pipeline/ /usr/share/logstash/pipeline/
ADD config/ /usr/share/logstash/config/
</code></pre>
<p>Be sure to replace or delete logstash.conf in your custom image, so that you don’t retain the example config from the base image.</p>
<ul>
<li>Environment variable configuration</li>
</ul>
<p>Under Docker, Logstash settings can be configured via environment variables. When the container starts, a helper process checks the environment for variables that can be mapped to Logstash settings. Settings that are found in the environment are merged into logstash.yml as the container starts up.</p>
<p>For compatibility with container orchestration systems, these environment variables are written in all capitals, with underscores as word separators</p>
<p>Some example translations are shown here:</p>
<p>Table 1. Example Docker Environment Variables</p>
<pre><code>Environment Variable        Logstash Setting
PIPELINE_WORKERS            pipeline.workers
LOG_LEVEL                   log.level
XPACK_MONITORING_ENABLED    xpack.monitoring.enabled
</code></pre>
<p>In general, any setting listed in the settings documentation can be configured with this technique.</p>
<p>Note:Defining settings with environment variables causes logstash.yml to be modified in place. This behaviour is likely undesirable if logstash.yml was bind-mounted from the host system. Thus, it is not recommended to combine the bind-mount technique with the environment variable technique. It is best to choose a single method for defining Logstash settings.</p>
<ul>
<li>Docker defaults</li>
</ul>
<p>The following settings have different default values when using the Docker images:</p>
<pre><code>http.host                               0.0.0.0
xpack.monitoring.elasticsearch.hosts    http://elasticsearch:9200
</code></pre>
<p>Note:The setting xpack.monitoring.elasticsearch.hosts is not defined in the -oss image.</p>
<p>These settings are defined in the default logstash.yml. They can be overridden with a custom logstash.yml or via environment variables.</p>
<ul>
<li>IMPORTANT</li>
</ul>
<p>If replacing logstash.yml with a custom version, be sure to copy the above defaults to the custom file if you want to retain them. If not, they will be &quot;masked&quot; by the new file.</p>
<ul>
<li>Logging Configuration</li>
</ul>
<p>Under Docker, Logstash logs go to standard output by default. To change this behaviour, use any of the techniques above to replace the file at /usr/share/logstash/config/log4j2.properties.</p>
<h2 id="kibana-1"><a class="header" href="#kibana-1">kibana</a></h2>
<ul>
<li>Copy and paste to pull this image</li>
</ul>
<pre><code>docker pull elastic/kibana:tag
</code></pre>
<ul>
<li>Running in Development Mode</li>
</ul>
<p>In the given example, Kibana will a attach to a user defined network (useful for connecting to other services (e.g. Elasticsearch)). If network has not yet been created, this can be done with the following command:</p>
<pre><code>docker network create somenetwork
</code></pre>
<p>Note:In this example, Kibana is using the default configuration and expects to connect to a running Elasticsearch instance at http://localhost:9200</p>
<p>Run Kibana</p>
<pre><code>docker run -d --name kibana --net somenetwork -p 5601:5601 elastic/kibana:7.0.0
</code></pre>
<p>Kibana can be accessed by browser via http://localhost:5601 or http://host-ip:5601</p>
<ul>
<li>Running in Production Mode</li>
</ul>
<p>For additional information on running and configuring Kibana on Docker, see Running Kibana on Docker</p>
<h2 id="filebeat-1"><a class="header" href="#filebeat-1">filebeat</a></h2>
<ul>
<li>Copy and paste to pull this image</li>
</ul>
<p>Obtaining Filebeat for Docker is as simple as issuing a docker pull command against the Elastic Docker registry.</p>
<pre><code>docker pull elastic/filebeat:tag
</code></pre>
<p>Alternatively, you can download other Docker images that contain only features available under the Apache 2.0 license. To download the images, go to www.docker.elastic.co.</p>
<ul>
<li>Run the Filebeat setup</li>
</ul>
<p>Running Filebeat with the setup command will create the index pattern and load visualizations , dashboards, and machine learning jobs. Run this command:</p>
<pre><code>docker run \
elastic/filebeat:7.0.0 \
setup -E setup.kibana.host=kibana:5601 \
-E output.elasticsearch.hosts=[&quot;elasticsearch:9200&quot;]
</code></pre>
<p>Substitute your Kibana and Elasticsearch hosts and ports.</p>
<p>If you are using the hosted Elasticsearch Service in Elastic Cloud, replace the -E output.elasticsearch.hosts line with the Cloud ID and elastic password using this syntax:</p>
<pre><code>-E cloud.id=&lt;Cloud ID from Elasticsearch Service&gt; \
-E cloud.auth=elastic:&lt;elastic password&gt;
</code></pre>
<ul>
<li>Configure Filebeat on Docker</li>
</ul>
<p>The Docker image provides several methods for configuring Filebeat. The conventional approach is to provide a configuration file via a volume mount, but it’s also possible to create a custom image with your configuration included.</p>
<ul>
<li>Example configuration file</li>
</ul>
<p>Download this example configuration file as a starting point:</p>
<pre><code>curl -L -O https://raw.githubusercontent.com/elastic/beats/7.0/deploy/docker/filebeat.docker.yml
</code></pre>
<ul>
<li>Volume-mounted configuration</li>
</ul>
<p>One way to configure Filebeat on Docker is to provide filebeat.docker.yml via a volume mount. With docker run, the volume mount can be specified like this.</p>
<pre><code>docker run -d \
  --name=filebeat \
  --user=root \
  --volume=&quot;$(pwd)/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml:ro&quot; \
  --volume=&quot;/var/lib/docker/containers:/var/lib/docker/containers:ro&quot; \
  --volume=&quot;/var/run/docker.sock:/var/run/docker.sock:ro&quot; \
  docker.elastic.co/beats/filebeat:7.0.0 filebeat -e -strict.perms=false \
  -E output.elasticsearch.hosts=[&quot;elasticsearch:9200&quot;]
</code></pre>
<p>Substitute your Elasticsearch hosts and ports.</p>
<p>If you are using the hosted Elasticsearch Service in Elastic Cloud, replace the -E output.elasticsearch.hosts line with the Cloud ID and elastic password using the syntax shown earlier.</p>
<ul>
<li>Customize your configuration</li>
</ul>
<p>The filebeat.docker.yml file you downloaded earlier is configured to deploy Beats modules based on the Docker labels applied to your containers. See Hints based autodiscover for more details. Add labels to your application Docker containers, and they will be picked up by the Beats autodiscover feature when they are deployed. Here is an example command for an Apache HTTP Server container with labels to configure the Filebeat and Metricbeat modules for the Apache HTTP Server:</p>
<pre><code>docker run \
  --label co.elastic.logs/module=apache2 \
  --label co.elastic.logs/fileset.stdout=access \
  --label co.elastic.logs/fileset.stderr=error \
  --label co.elastic.metrics/module=apache \
  --label co.elastic.metrics/metricsets=status \
  --label co.elastic.metrics/hosts='${data.host}:${data.port}' \
  --detach=true \
  --name my-apache-app \
  -p 8080:80 \
  httpd:2.4
</code></pre>
<ul>
<li>Custom image configuration</li>
</ul>
<p>It’s possible to embed your Filebeat configuration in a custom image. Here is an example Dockerfile to achieve this:</p>
<pre><code>FROM docker.elastic.co/beats/filebeat:7.0.0
COPY filebeat.yml /usr/share/filebeat/filebeat.yml
USER root
RUN chown root:filebeat /usr/share/filebeat/filebeat.yml
USER filebeat
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="1-elasticsearch"><a class="header" href="#1-elasticsearch">1. elasticsearch</a></h1>
<ul>
<li>create network</li>
</ul>
<pre><code>docker network create elk
</code></pre>
<ul>
<li>run elasticsearch </li>
</ul>
<pre><code>docker run --name elasticsearch -d --net elk -p 9200:9200 -p 9300:9300 -e discovery.type=single-node elastic/elasticsearch:7.0.0
</code></pre>
<h1 id="2-logstash"><a class="header" href="#2-logstash">2. logstash</a></h1>
<ul>
<li>run logstash use config file</li>
</ul>
<pre><code>docker run --name logstash -dit --net elk --link elasticsearch:elasticsearch -p 5044:5044 -p 9600:9600 -v ~/logstash:/mnt logstash -f /mnt/logstash-sample.conf
</code></pre>
<ul>
<li>logstash dir content</li>
<li>cd ~/logstash</li>
<li>vi logstash-sample.conf</li>
</ul>
<pre><code>input {
    file {
        path =&gt; &quot;/mnt/logs/sys*.log&quot;
        type =&gt; &quot;system&quot;
        start_position =&gt; &quot;beginning&quot;
    }
    file {
        path =&gt; &quot;/mnt/logs/error*.log&quot;
        type =&gt; &quot;error&quot;
        start_position =&gt; &quot;beginning&quot;
    }
}
output {
    if [type] == &quot;system&quot; {
        elasticsearch {
            hosts =&gt; [&quot;http://elasticsearch:9200&quot;]
            index =&gt; &quot;system-%{+YYYY.MM.dd}&quot;
        }
    }
    if [type] == &quot;error&quot; {
        elasticsearch {
            hosts =&gt; [&quot;http://elasticsearch:9200&quot;]
            index =&gt; &quot;error-%{+YYYY.MM.dd}&quot;
        }
    }
}
</code></pre>
<ul>
<li>run logstash</li>
</ul>
<pre><code>docker run --name logstash -dit --net elk --link elasticsearch:elasticsearch -p 5044:5044 -p 9600:9600 -v ~/logstash/config:/usr/share/logstash/config -v ~/logs:/var/logs elastic/logstash:7.0.0
</code></pre>
<ul>
<li>config dir content</li>
<li>cd ~/logstash/config</li>
<li>vi logstash.yml</li>
</ul>
<pre><code># none
</code></pre>
<ul>
<li>vi pipelines.yml</li>
</ul>
<pre><code>- pipeline.id: logstash-one
  path.config: &quot;/usr/share/logstash/config/*.conf&quot;
  pipeline.workers: 3
</code></pre>
<ul>
<li>vi logstash-sample.conf</li>
</ul>
<pre><code>input {
    file {
        path =&gt; &quot;/var/logs/sys*.log&quot;
        type =&gt; &quot;system&quot;
        start_position =&gt; &quot;beginning&quot;
    }
    file {
        path =&gt; &quot;/var/logs/error*.log&quot;
        type =&gt; &quot;error&quot;
        start_position =&gt; &quot;beginning&quot;
    }
}
output {
    if [type] == &quot;system&quot; {
        elasticsearch {
            hosts =&gt; [&quot;http://elasticsearch:9200&quot;]
            index =&gt; &quot;system-%{+YYYY.MM.dd}&quot;
        }
    }
    if [type] == &quot;error&quot; {
        elasticsearch {
            hosts =&gt; [&quot;http://elasticsearch:9200&quot;]
            index =&gt; &quot;error-%{+YYYY.MM.dd}&quot;
        }
    }
}
</code></pre>
<h1 id="3-kibana"><a class="header" href="#3-kibana">3. kibana</a></h1>
<ul>
<li>run kibana</li>
</ul>
<pre><code>docker run --name kibana -dit --net elk --link elasticsearch:elasticsearch -p 5601:5601 elastic/kibana:7.0.0
</code></pre>
<h1 id="4-fast-setup"><a class="header" href="#4-fast-setup">4. fast setup</a></h1>
<h2 id="41-load-docker-image"><a class="header" href="#41-load-docker-image">4.1 load docker image</a></h2>
<pre><code>docker load -i elasticsearch.tar
docker load -i logstash.tar
docker load -i kibana.tar
</code></pre>
<h2 id="42-edit-logstash-sampleconf"><a class="header" href="#42-edit-logstash-sampleconf">4.2 edit logstash-sample.conf</a></h2>
<ul>
<li>vi ~/logstash/logstash-sample.conf</li>
</ul>
<pre><code>input {
    file {
        path =&gt; &quot;/mnt/logs/sys*.log&quot;
        type =&gt; &quot;system&quot;
        start_position =&gt; &quot;beginning&quot;
    }
    file {
        path =&gt; &quot;/mnt/logs/error*.log&quot;
        type =&gt; &quot;error&quot;
        start_position =&gt; &quot;beginning&quot;
    }
}
output {
    if [type] == &quot;system&quot; {
        elasticsearch {
            hosts =&gt; [&quot;http://elasticsearch:9200&quot;]
            index =&gt; &quot;system-%{+YYYY.MM.dd}&quot;
        }
    }
    if [type] == &quot;error&quot; {
        elasticsearch {
            hosts =&gt; [&quot;http://elasticsearch:9200&quot;]
            index =&gt; &quot;error-%{+YYYY.MM.dd}&quot;
        }
    }
}
</code></pre>
<h2 id="43-run-docker"><a class="header" href="#43-run-docker">4.3 run docker</a></h2>
<pre><code>docker network create elk

docker run --name elasticsearch -d --net elk -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elastic/elasticsearch:7.0.0

docker run --name kibana -dit --net elk --link elasticsearch:elasticsearch -p 5601:5601 elastic/kibana:7.0.0

docker run --name logstash -dit --net elk --link elasticsearch:elasticsearch -p 5044:5044 -p 9600:9600 -v ~/logstash:/mnt elastic/logstash:7.0.0 logstash -f /mnt/logstash-sample.conf
</code></pre>
<h2 id="44-nginx-config"><a class="header" href="#44-nginx-config">4.4 nginx config</a></h2>
<pre><code>server {
    listen 80;
    server_name www.example.com;
    proxy_set_header X-Forwarded-For $remote_addr;

    location / {
        proxy_pass http://localhost:5601;
    }
    location /kibana {
        proxy_pass http://localhost:5601;
        rewrite ^/kibana/(.*)$ /$1 break;
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dockerfile-中的-copy-与-add-命令-1"><a class="header" href="#dockerfile-中的-copy-与-add-命令-1">Dockerfile 中的 COPY 与 ADD 命令</a></h1>
<h2 id="build-上下文的概念-1"><a class="header" href="#build-上下文的概念-1">Build 上下文的概念</a></h2>
<p>在使用 docker build 命令通过 Dockerfile 创建镜像时，会产生一个 build 上下文(context)。所谓的 build 上下文就是 docker build 命令的 PATH 或 URL 指定的路径中的文件的集合。在镜像 build 过程中可以引用上下文中的任何文件，比如我们要介绍的 COPY 和 ADD 命令，就可以引用上下文中的文件。</p>
<p>默认情况下 docker build -t testx . 命令中的 . 表示 build 上下文为当前目录。当然我们可以指定一个目录作为上下文，比如下面的命令：</p>
<pre><code>docker build -t testx /home/nick/hc
</code></pre>
<p>我们指定 /home/nick/hc 目录为 build 上下文，默认情况下 docker 会使用在上下文的根目录下找到的 Dockerfile 文件。</p>
<h3 id="copy-和-add-命令不能拷贝上下文之外的本地文件-1"><a class="header" href="#copy-和-add-命令不能拷贝上下文之外的本地文件-1">COPY 和 ADD 命令不能拷贝上下文之外的本地文件</a></h3>
<p>对于 COPY 和 ADD 命令来说，如果要把本地的文件拷贝到镜像中，那么本地的文件必须是在上下文目录中的文件。其实这一点很好解释，因为在执行 build 命令时，docker 客户端会把上下文中的所有文件发送给 docker daemon。考虑 docker 客户端和 docker daemon 不在同一台机器上的情况，build 命令只能从上下文中获取文件。如果我们在 Dockerfile 的 COPY 和 ADD 命令中引用了上下文中没有的文件，就会收到类似下面的错误：</p>
<p><img src="docker/../static/img/docker/d001.png" alt="" /></p>
<h3 id="与-workdir-协同工作-1"><a class="header" href="#与-workdir-协同工作-1">与 WORKDIR 协同工作</a></h3>
<p>WORKDIR 命令为后续的 RUN、CMD、COPY、ADD 等命令配置工作目录。在设置了 WORKDIR 命令后，接下来的 COPY 和 ADD 命令中的相对路径就是相对于 WORKDIR 指定的路径。比如我们在 Dockerfile 中添加下面的命令：</p>
<pre><code>WORKDIR /app
COPY checkredis.py .
</code></pre>
<p>然后构建名称为 testx 的容器镜像，并运行一个容器查看文件路径：</p>
<p><img src="docker/../static/img/docker/d002.png" alt="" /></p>
<p>checkredis.py 文件就是被复制到了 WORKDIR /app 目录下。</p>
<h2 id="copy-命令的简单性-1"><a class="header" href="#copy-命令的简单性-1">COPY 命令的简单性</a></h2>
<p>如果仅仅是把本地的文件拷贝到容器镜像中，COPY 命令是最合适不过的。其命令的格式为：</p>
<pre><code>COPY &lt;src&gt; &lt;dest&gt;
</code></pre>
<p>除了指定完整的文件名外，COPY 命令还支持 Go 风格的通配符，比如：</p>
<pre><code>COPY check* /testdir/           # 拷贝所有 check 开头的文件
COPY check?.log /testdir/       # ? 是单个字符的占位符，比如匹配文件 check1.log
</code></pre>
<p>对于目录而言，COPY 和 ADD 命令具有相同的特点：只复制目录中的内容而不包含目录自身。比如我们在 Dockerfile 中添加下面的命令：</p>
<pre><code>WORKDIR /app
COPY nickdir .
</code></pre>
<p>其中 nickdir 目录的结构如下：</p>
<p><img src="docker/../static/img/docker/d003.png" alt="" /></p>
<p>重新构建镜像 testx，运行一个容器并查看 /app 目录下的内容：</p>
<p><img src="docker/../static/img/docker/d004.png" alt="" /></p>
<p>这里只有 file1 和 file2，少了一层目录 nickdir。如果想让 file1 和 file2 还保存在 nickdir 目录中，需要在目标路径中指定这个目录的名称，比如：</p>
<pre><code>WORKDIR /app
COPY nickdir ./nickdir
</code></pre>
<p>COPY 命令区别于 ADD 命令的一个用法是在 multistage 场景下。关于 multistage 的介绍和用法请参考笔者的《Dockerfile 中的 multi-stage》一文。在 multistage 的用法中，可以使用 COPY 命令把前一阶段构建的产物拷贝到另一个镜像中，比如：</p>
<pre><code>FROM golang:1.11.11
WORKDIR /go/src/github.com/sparkdevo/href-counter/
RUN go get -d -v golang.org/x/net/html
COPY app.go .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=0 /go/src/github.com/sparkdevo/href-counter/app .
CMD [&quot;./app&quot;]
</code></pre>
<p>这段代码引用自《Dockerfile 中的 multi-stage》一文，其中的 COPY 命令通过指定 --from=0 参数，把前一阶段构建的产物拷贝到了当前的镜像中。</p>
<h2 id="add-命令还可以干其它事情-1"><a class="header" href="#add-命令还可以干其它事情-1">ADD 命令还可以干其它事情</a></h2>
<p>ADD 命令的格式和 COPY 命令相同，也是：</p>
<pre><code>ADD &lt;src&gt; &lt;dest&gt;
</code></pre>
<p>除了不能用在 multistage 的场景下，ADD 命令可以完成 COPY 命令的所有功能，并且还可以完成两类超酷的功能：</p>
<ul>
<li>
<p>解压压缩文件并把它们添加到镜像中</p>
</li>
<li>
<p>从 url 拷贝文件到镜像中</p>
</li>
</ul>
<p>当然，这些功能也让 ADD 命令用起来复杂一些，不如 COPY 命令那么直观。</p>
<h3 id="解压压缩文件并把它们添加到镜像中-1"><a class="header" href="#解压压缩文件并把它们添加到镜像中-1">解压压缩文件并把它们添加到镜像中</a></h3>
<p>如果我们有一个压缩文件包，并且需要把这个压缩包中的文件添加到镜像中。需不需要先解开压缩包然后执行 COPY 命令呢？当然不需要！我们可以通过 ADD 命令一次搞定：</p>
<pre><code>WORKDIR /app
ADD nickdir.tar.gz .
</code></pre>
<p>这应该是 ADD 命令的最佳使用场景了！</p>
<h3 id="从-url-拷贝文件到镜像中-1"><a class="header" href="#从-url-拷贝文件到镜像中-1">从 url 拷贝文件到镜像中</a></h3>
<p>这是一个更加酷炫的用法！但是在 docker 官方文档的最佳实践中却强烈建议不要这么用！！docker 官方建议我们当需要从远程复制文件时，最好使用 curl 或 wget 命令来代替 ADD 命令。原因是，当使用 ADD 命令时，会创建更多的镜像层，当然镜像的 size 也会更大(下面的两段代码来自 docker 官方文档)：</p>
<pre><code>ADD http://example.com/big.tar.xz /usr/src/things/
RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things
RUN make -C /usr/src/things all
</code></pre>
<p>如果使用下面的命令，不仅镜像的层数减少，而且镜像中也不包含 big.tar.xz 文件：</p>
<pre><code>RUN mkdir -p /usr/src/things \
    &amp;&amp; curl -SL http://example.com/big.tar.xz \
    | tar -xJC /usr/src/things \
    &amp;&amp; make -C /usr/src/things all
</code></pre>
<p>好吧，看起来只有在解压压缩文件并把它们添加到镜像中时才需要 ADD 命令！</p>
<h2 id="加速镜像构建的技巧-1"><a class="header" href="#加速镜像构建的技巧-1">加速镜像构建的技巧</a></h2>
<p>在使用 COPY 和 ADD 命令时，我们可以通过一些技巧来加速镜像的 build 过程。比如把那些最不容易发生变化的文件的拷贝操作放在较低的镜像层中，这样在重新 build 镜像时就会使用前面 build 产生的缓存。比如笔者构建镜像时需要用到下面几个文件：</p>
<p><img src="docker/../static/img/docker/d005.png" alt="" /></p>
<p>其中 myhc.py 文件不经常变化，而 checkmongo.py、checkmysql.py 和 checkredis.py 这三个文件则经常变化，那么我们可这样来设计 Dockerfile 文件：</p>
<pre><code>WORKDIR /app
COPY myhc.py .
COPY check* ./
</code></pre>
<p>让 COPY myhc.py . 单独占据一个镜像层，当 build 过一次后，每次因 checkmongo.py、checkmysql.py 和 checkredis.py 这三个文件变化而导致的重新 build 都不会重新 build COPY myhc.py . 镜像层：</p>
<p><img src="docker/../static/img/docker/d006.png" alt="" /></p>
<p>如上图所示，第二步和第三步都没有重新 build 镜像层，而是使用了之前的缓存，从第四步才开始重新 build 了镜像层。当文件 size 比较大且文件的数量又比较多，尤其是需要执行安装等操作时，这样的设计对于 build 速度的提升还是很明显的。所以我们应该尽量选择能够使用缓存的 Dockerfile 写法。</p>
<h2 id="总结-1"><a class="header" href="#总结-1">总结</a></h2>
<p>当第一次看到 COPY 和 ADD 命令时不免让人感到疑惑。但分析之后大家会发现 COPY 命令是为最基本的用法设计的，概念清晰，操作简单。而 ADD 命令基本上是 COPY 命令的超集(除了 multistage 场景)，可以实现一些方便、酷炫的拷贝操作。ADD 命令在增加了功能的同时也增加了使用它的复杂度，比如从 url 拷贝压缩文件时弊大于利。希望本文能够解去大家对 Dockerfile 中 COPY 和 ADD 命令的疑惑。</p>
<div style="break-before: page; page-break-before: always;"></div><h4 id="error-failed-to-get-d-bus-connection-operation-not-permitted"><a class="header" href="#error-failed-to-get-d-bus-connection-operation-not-permitted">ERROR: Failed to get D-Bus connection: Operation not permitted</a></h4>
<pre><code>#centos
docker run --name centos -dit --privileged=true centos:8 /usr/sbin/init
docker exec -it centos bash
systemctl start xxx.service
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debian"><a class="header" href="#debian">debian</a></h1>
<h2 id="base"><a class="header" href="#base">base</a></h2>
<pre><code>FROM irepoing/debian:10

ENV DEBIAN_FRONTEND=noninteractive

RUN apt update -y \
&amp;&amp; apt install -y tzdata less curl wget telnet vim zip unzip git \
&amp;&amp; \cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
&amp;&amp; apt autoremove \
&amp;&amp; apt autoclean \
&amp;&amp; apt clean

CMD [&quot;bash&quot;]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dockerfile"><a class="header" href="#dockerfile">Dockerfile</a></h1>
<pre><code># This my first nginx Dockerfile
# Version 1.0

# Base images (scratch, busybox, alpine, centos, ubuntu, debian)
FROM centos

#MAINTAINER (author)
MAINTAINER sun 

#ENV (set env)
ENV PATH $PATH:/usr/local/nginx/sbin

#ADD (copy and extract)
ADD nginx.tar.gz /usr/local/  
ADD epel-release-latest-7.noarch.rpm /usr/local/  

#RUN (run os command)
RUN rpm -iv /usr/local/epel-release-latest-7.noarch.rpm
RUN yum install -y wget lftp gcc gcc-c++ make openssl-devel pcre-devel pcre &amp;&amp; yum clean all
RUN useradd -s /sbin/nologin -M www

#WORKDIR (like cd)
WORKDIR /usr/local/nginx

RUN ./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-pcre &amp;&amp; make &amp;&amp; make install

RUN echo &quot;daemon off;&quot; &gt;&gt; /etc/nginx.conf

#EXPOSE 映射端口
EXPOSE 80

#CMD 运行以下命令
CMD [&quot;nginx&quot;]
</code></pre>
<h1 id="base-image"><a class="header" href="#base-image">base image</a></h1>
<div class="table-wrapper"><table><thead><tr><th>镜像名称</th><th>大小</th><th>使用场景</th></tr></thead><tbody>
<tr><td>scratch</td><td>0MB</td><td>空镜像，系统保留</td></tr>
<tr><td>busybox</td><td>1.15MB</td><td>临时测试用</td></tr>
<tr><td>alpine</td><td>4.41MB</td><td>主要用于测试，也可用于生产环境</td></tr>
<tr><td>centos</td><td>200MB</td><td>主要用于生产环境，支持CentOS/Red Hat，常用于追求稳定性的企业应用</td></tr>
<tr><td>ubuntu</td><td>81.1MB</td><td>主要用于生产环境，常用于人工智能计算和企业应用</td></tr>
<tr><td>debian</td><td>101MB</td><td>主要用于生产环境</td></tr>
</tbody></table>
</div>
<h2 id="build-scratch"><a class="header" href="#build-scratch">build scratch</a></h2>
<pre><code>tar cv --files-from /dev/null | docker import - scratch
</code></pre>
<h2 id="docker-images--docker-image-ls"><a class="header" href="#docker-images--docker-image-ls">docker images || docker image ls</a></h2>
<pre><code>REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
scratch                 latest              775bfce21429        9 minutes ago       0B
</code></pre>
<h1 id="command-2"><a class="header" href="#command-2">command</a></h1>
<div class="table-wrapper"><table><thead><tr><th>指令</th><th>说明</th></tr></thead><tbody>
<tr><td>FROM</td><td>指定所创建镜像的基础镜像</td></tr>
<tr><td>MAINTAINER</td><td>指定维护者信息</td></tr>
<tr><td>RUN</td><td>运行命令</td></tr>
<tr><td>CMD</td><td>指定启动容器时默认执行的命令</td></tr>
<tr><td>LABEL</td><td>指定生成镜像的元数据标签信息</td></tr>
<tr><td>EXPOSE</td><td>声明镜像内服务所监听的端口</td></tr>
<tr><td>ENV</td><td>指定环境变量</td></tr>
<tr><td>ADD</td><td>赋值指定的路径下的内容到容器中的路径下，可以为URL；如果为tar文件，会自动解压到路径下</td></tr>
<tr><td>COPY</td><td>赋值本地主机的路径下的内容到容器中的路径下；一般情况下推荐使用COPY而不是ADD</td></tr>
<tr><td>ENTRYPOINT</td><td>指定镜像的默认入口</td></tr>
<tr><td>VOLUME</td><td>创建数据挂载点</td></tr>
<tr><td>USER</td><td>指定运行容器时的用户名或UID</td></tr>
<tr><td>WORKDIR</td><td>配置工作目录</td></tr>
<tr><td>ARG</td><td>指定镜像内使用的参数(例如版本号信息等)</td></tr>
<tr><td>ONBUILD</td><td>配置当前所创建的镜像作为其他镜像的基础镜像时，所执行的创建操作的命令</td></tr>
<tr><td>STOPSIGNAL</td><td>容器退出的信号</td></tr>
<tr><td>HEALTHCHECK</td><td>如何进行健康检查</td></tr>
<tr><td>SHELL</td><td>指定使用SHELL时的默认SHELL类型</td></tr>
</tbody></table>
</div>
<h2 id="from--指定基础镜像要在哪个镜像建立"><a class="header" href="#from--指定基础镜像要在哪个镜像建立">FROM : 指定基础镜像，要在哪个镜像建立</a></h2>
<blockquote>
<p>格式为 FROM <image> 或FROM <image>:<tag></p>
</blockquote>
<p>第一条指令必须为 FROM 指令。FROM命令会指定镜像基于哪个基础镜像创建，接下来的命令也会基于这个基础镜像（CentOS和Ubuntu有些命令可是不一样的）。FROM命令可以多次使用，表示会创建多个镜像。</p>
<h2 id="maintainer指定维护者信息"><a class="header" href="#maintainer指定维护者信息">MAINTAINER：指定维护者信息</a></h2>
<blockquote>
<p>格式为 MAINTAINER <name></p>
</blockquote>
<h2 id="arg"><a class="header" href="#arg">ARG</a></h2>
<p>指定一些镜像内使用的参数(例如版本号信息等)，这些参数在执行docker build命令时才以--build-arg<varname>=<value>格式传入。</p>
<blockquote>
<p>格式为：ARG<name>[=<default value>]</p>
</blockquote>
<p>则可以用docker build --build-arg<name>=<value>来指定参数值。</p>
<h2 id="run在镜像中要执行的命令"><a class="header" href="#run在镜像中要执行的命令">RUN：在镜像中要执行的命令</a></h2>
<blockquote>
<p>格式为 RUN <command> 或 RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</p>
</blockquote>
<p>前者默认将在 shell 终端中运行命令，即 /bin/bash -c ；后者则使用 exec 执行。指定使用其它终端可以通过第二种方式实现，例如 RUN [“/bin/bash”, “-c”,”echo hello”] 。</p>
<p>每条RUN指令将在当前镜像的基础上执行指定命令，并提交为新的镜像。当命令较长时可以使用\换行。例如：</p>
<pre><code>RUN apt update \
        &amp;&amp; apt-get install -y libsnappy-dev zliblg-dev \
        &amp;&amp; rm -rf /var/cache/apt
</code></pre>
<h2 id="workdir指定当前工作目录相当于-cd"><a class="header" href="#workdir指定当前工作目录相当于-cd">WORKDIR：指定当前工作目录，相当于 cd</a></h2>
<blockquote>
<p>格式为 WORKDIR /path/to/workdir</p>
</blockquote>
<p>为后续的 RUN 、 CMD 、 ENTRYPOINT 指令配置工作目录。
可以使用多个 WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如</p>
<pre><code>WORKDIR /a
WORKDIR b
WORKDIR c
RUN pwd
</code></pre>
<p>则最终路径为 /a/b/c 。</p>
<h2 id="expose指定容器要打开的端口"><a class="header" href="#expose指定容器要打开的端口">EXPOSE：指定容器要打开的端口</a></h2>
<blockquote>
<p>格式为 EXPOSE <port> [<port>...]</p>
</blockquote>
<p>告诉 Docker 服务端容器暴露的端口号，供互联系统使用。在启动容器时需要通过 -P，Docker 主机会自动分配一个端口转发到指定的端口。</p>
<p>注意：
该命令只是起到声明租用，并不会自动完成端口映射。
在容器启动时需要使用-P(大写P)，Docker主机会自动分配一个宿主机未被使用的临时端口转发到指定的端口；使用-p(小写p)，则可以具体指定哪个宿主机的本地端口映射过来。</p>
<h2 id="env定义环境变量"><a class="header" href="#env定义环境变量">ENV：定义环境变量</a></h2>
<blockquote>
<p>格式为 ENV <key> <value> 。 指定一个环境变量，会被后续 RUN 指令使用，并在容器运行时保持。</p>
</blockquote>
<p>指令指定的环境变量在运行时可以被覆盖掉，如docker run --env <key>=<value> built_image。</p>
<h2 id="copy-复制本地主机的-为-dockerfile-所在目录的相对路径到容器中的"><a class="header" href="#copy-复制本地主机的-为-dockerfile-所在目录的相对路径到容器中的">COPY ：复制本地主机的 （为 Dockerfile 所在目录的相对路径）到容器中的</a></h2>
<blockquote>
<p>格式为 COPY <src> <dest></p>
</blockquote>
<h2 id="add相当于-copy但是比-copy-功能更强大"><a class="header" href="#add相当于-copy但是比-copy-功能更强大">ADD：相当于 COPY，但是比 COPY 功能更强大</a></h2>
<blockquote>
<p>格式为 ADD <src> <dest></p>
</blockquote>
<p>该命令将复制指定的 到容器中的 。 其中<src> 可以是Dockerfile所在目录的一个相对路径；也可以是一个 URL；还可以是一个 tar 文件，复制进容器会自动解压。
<dest>可以使镜像内的绝对路径，或者相当于工作目录(WORKDIR)的相对路径。路径支持正则表达式，例如：</p>
<pre><code>ADD *.c /code/
</code></pre>
<h2 id="volume挂载目录"><a class="header" href="#volume挂载目录">VOLUME：挂载目录</a></h2>
<blockquote>
<p>格式为VOLUME [&quot;/data&quot;]</p>
</blockquote>
<p>创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保持的数据等。</p>
<h2 id="user"><a class="header" href="#user">USER</a></h2>
<blockquote>
<p>格式为 USER daemon</p>
</blockquote>
<p>指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户。当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户，例如： RUN useradd -s /sbin/nologin -M www。</p>
<h2 id="label"><a class="header" href="#label">LABEL</a></h2>
<p>LABEL指令用来生成用于生成镜像的元数据的标签信息。</p>
<blockquote>
<p>格式为：LABEL <key>=<value> <key>=<value> <key>=<value> ...</p>
</blockquote>
<pre><code>LABEL version=&quot;1.0&quot;
LABEL description=&quot;This text illustrates \ that label-values can span multiple lines.&quot;
</code></pre>
<h2 id="entrypoint"><a class="header" href="#entrypoint">ENTRYPOINT</a></h2>
<p>指定镜像的默认入口命令，该入口命令会在启动容器时作为根命令执行，所有传入值作为该命令的参数。</p>
<p>两种格式：</p>
<pre><code>ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]
 
ENTRYPOINT command param1 param2 （shell 中执行）
</code></pre>
<p>此时，CMD指令指定值将作为根命令的参数。每个Dockerfile中只能有一个ENTRYPOINT，当指定多个时，只有最后一个有效。在运行时可以被--entrypoint参数覆盖掉，如docker run --entrypoint。</p>
<h2 id="cmd"><a class="header" href="#cmd">CMD</a></h2>
<p>支持三种格式</p>
<pre><code>CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] 使用 exec 执行，推荐方式；
CMD command param1 param2 在 /bin/bash 中执行，提供给需要交互的应用；
CMD [&quot;param1&quot;,&quot;param2&quot;] 提供给 ENTRYPOINT 的默认参数；
</code></pre>
<p>指定启动容器时执行的命令，每个 Dockerfile 只能有一条 CMD 命令。如果指定了多条命令，只有最后一条会被执行。如果用户启动容器时候指定了运行的命令，则会覆盖掉 CMD 指定的命令。</p>
<h2 id="onbuild在构建本镜像时不生效在基于此镜像构建镜像时生效"><a class="header" href="#onbuild在构建本镜像时不生效在基于此镜像构建镜像时生效">ONBUILD：在构建本镜像时不生效，在基于此镜像构建镜像时生效</a></h2>
<blockquote>
<p>格式为 ONBUILD [INSTRUCTION]</p>
</blockquote>
<p>配置当所创建的镜像作为其它新创建镜像的基础镜像时，所执行的操作指令。</p>
<h2 id="stopsignal"><a class="header" href="#stopsignal">STOPSIGNAL</a></h2>
<p>指定所创建镜像启动的容器接收退出的信号值。例如</p>
<pre><code>STOPSIGNAL singnal
</code></pre>
<h2 id="healthcheck"><a class="header" href="#healthcheck">HEALTHCHECK</a></h2>
<p>配置所启动容器如何进行健康检查(如何判断是否健康)，自Docker 1.12开始支持。</p>
<p>格式有两种：</p>
<pre><code>1.HEALTHCHECK [OPTIONS] CMD command    ：根据所执行命令返回值是否为0判断；
2.HEALTHCHECK NONE    　　　　　　　　　　:禁止基础镜像中的健康检查。
</code></pre>
<p>[OPTION]支持：</p>
<pre><code>--interval=DURATION  (默认为：30s)：多久检查一次；
--timeout=DURATION  (默认为：30s)：每次检查等待结果的超时时间；
--retries=N 　　     (默认为：3)：如果失败了，重试几次才最终确定失败。
</code></pre>
<p>CMD关键字后面可以跟执行shell脚本的命令或者exec数组。CMD后面的命令执行完的返回值代表容器的运行状况，可能的值：0 health状态，1 unhealth状态，2 reserved状态</p>
<p>比如，我们启动一个http服务，我们可以这样写健康检查。</p>
<h2 id="shell"><a class="header" href="#shell">SHELL</a></h2>
<p>指定其他命令使用shell时的默认shell类型。</p>
<blockquote>
<p>格式为： SHELL [&quot;executable&quot;,&quot;parameters&quot;]</p>
</blockquote>
<p>默认值为 [&quot;bin/sh&quot;,&quot;-c&quot;]</p>
<p>注意：
对于Windows系统，建议在Dockerfile开头添加# escape=`来指定转移信息。</p>
<p>ENTRYPOINT 和 CMD 的区别：ENTRYPOINT 指定了该镜像启动时的入口，CMD 则指定了容器启动时的命令，当两者共用时，完整的启动命令像是 ENTRYPOINT + CMD 这样。使用 ENTRYPOINT 的好处是在我们启动镜像就像是启动了一个可执行程序，在 CMD 上仅需要指定参数；另外在我们需要自定义 CMD 时不容易出错。</p>
<p>使用 CMD 的 Dockerfile：</p>
<pre><code>[root@sta2 test]# cat Dockerfile 
FROM mysql

CMD [&quot;echo&quot;,&quot;test&quot;]
</code></pre>
<p>使用 ENTRYPOINT 的 Dockerfile：</p>
<pre><code>[root@sta2 entrypoint]#  cat  Dockerfile 
FROM mysql
 
ENTRYPOINT [&quot;echo&quot;,&quot;test&quot;]
</code></pre>
<p>结论：ENTRYPOINT 不能覆盖掉执行时的参数，CMD 可以掉覆盖默认的参数。</p>
<p>可以使用以下命令覆盖默认的参数，方便调试 Dockerfile 中的 bug：</p>
<pre><code>docker run -it --entrypoint=/bin/bash centos:7
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="golang"><a class="header" href="#golang">golang</a></h1>
<h2 id="build-golang-docker"><a class="header" href="#build-golang-docker">build golang docker</a></h2>
<pre><code>FROM alpine:3.10

RUN echo http://mirrors.aliyun.com/alpine/v3.10/main &gt; /etc/apk/repositories &amp;&amp; \
    echo http://mirrors.aliyun.com/alpine/v3.10/community &gt;&gt; /etc/apk/repositories

RUN apk add --no-cache tzdata &amp;&amp; \
    cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \
    apk del tzdata

RUN apk add --no-cache libc6-compat ca-certificates &amp;&amp; \
    echo &quot;hosts: files dns&quot; &gt; /etc/nsswitch.conf
    
ADD go1.16.10.linux-amd64.tar.gz /usr/local

ENV PATH $PATH:/usr/local/go/bin
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="manifest"><a class="header" href="#manifest">manifest</a></h1>
<h2 id="pull-images-and-tag"><a class="header" href="#pull-images-and-tag">pull images and tag</a></h2>
<pre><code>docker pull alpine:latest@sha256:e7d88de73db3d3fd9b2d63aa7f447a10fd0220b7cbf39803c803f2af9ba256b3
docker tag xxx irepoing/alpine:3-amd
docker push irepoing/alpine:3-amd

docker pull alpine:latest@sha256:c74f1b1166784193ea6c8f9440263b9be6cae07dfe35e32a5df7a31358ac2060
docker tag yyy irepoing/alpine:3-arm
docker push irepoing/alpine:3-arm
</code></pre>
<h2 id="create-manifest"><a class="header" href="#create-manifest">create manifest</a></h2>
<pre><code>docker manifest create irepoing/alpine:3 irepoing/alpine:3-amd irepoing/alpine:3-arm
</code></pre>
<h2 id="annotate-manifest"><a class="header" href="#annotate-manifest">annotate manifest</a></h2>
<pre><code>docker manifest annotate irepoing/alpine:3 irepoing/alpine:3-amd --os linux --arch amd64
docker manifest annotate irepoing/alpine:3 irepoing/alpine:3-arm --os linux --arch arm64
</code></pre>
<h2 id="push-manifest"><a class="header" href="#push-manifest">push manifest</a></h2>
<pre><code>docker manifest push irepoing/alpine:3
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker-mysql"><a class="header" href="#docker-mysql">docker mysql</a></h1>
<h2 id="1pull-mysql"><a class="header" href="#1pull-mysql">1.pull mysql</a></h2>
<pre><code>docker pull mysql:tag
</code></pre>
<h2 id="2docker-run"><a class="header" href="#2docker-run">2.docker run</a></h2>
<pre><code>docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:tag
docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci --name mysql mysql:tag
</code></pre>
<h2 id="3set-host"><a class="header" href="#3set-host">3.set host</a></h2>
<pre><code>mysql -u dbuser -p --default-character-set=gbk
mysql&gt;use mysql; 
mysql&gt;update user set host = '%' where user = 'root'; 
</code></pre>
<h2 id="4grant-privileges"><a class="header" href="#4grant-privileges">4.grant privileges</a></h2>
<pre><code>mysql&gt;grant all privileges on *.* to 'root'@'%' identified by 'toor' with grant option;
</code></pre>
<h2 id="5docker-run-best"><a class="header" href="#5docker-run-best">5.docker run best</a></h2>
<blockquote>
<p>5.1 make dir</p>
</blockquote>
<pre><code>cd /home
mkdir mysql
cd mysql
mkdir conf
mkdir data
cd conf
</code></pre>
<blockquote>
<p>5.2 vi mysql.conf</p>
</blockquote>
<pre><code>#/home/mysql/conf/mysql.conf

[client]
default-character-set=utf8
 
[mysql]
default-character-set=utf8
 
[mysqld]
init_connect='SET collation_connection = utf8_unicode_ci'
init_connect='SET NAMES utf8'
character-set-server=utf8
collation-server=utf8_unicode_ci
skip-character-set-client-handshake
</code></pre>
<blockquote>
<p>5.3 docker run</p>
</blockquote>
<pre><code>docker run -d --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 --restart=always --privileged=true -v ~/mysql/conf/mysql.conf:/etc/mysql/my.cnf -v ~/mysql/data:/var/lib/mysql mysql:tag
# or simple
docker run -d --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -v ~/mysql:/var/lib/mysql mysql:tag
</code></pre>
<h2 id="6docker-command"><a class="header" href="#6docker-command">6.docker command</a></h2>
<pre><code>docker xxx --help
docker images
docker ps -a
docker inspect id
docker tag sourec:tag target:tag
docker build -t repository:tag -f Dockerfile .  
docker save -o one.tar image
docker load -i one.tar
docker export -o one.tar id
docker import one.tar repository:tag
docker logs id
docker start id
docker restart id
docker stop id
docker run -d -it --name cname image
docker exec -it -u root id bash
docker rmi image -f
docker rm id -f
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="other"><a class="header" href="#other">Other</a></h1>
<h2 id="为非root用户添加docker权限"><a class="header" href="#为非root用户添加docker权限">为非root用户添加docker权限</a></h2>
<h3 id="1添加-docker-group"><a class="header" href="#1添加-docker-group">1.添加 docker group</a></h3>
<pre><code>sudo groupadd docker
</code></pre>
<h3 id="2将用户加入该-group-内"><a class="header" href="#2将用户加入该-group-内">2.将用户加入该 group 内</a></h3>
<pre><code>$ sudo usermod -aG docker $USER
# or
$ sudo gpasswd -a ${USER} docker
</code></pre>
<h3 id="3重启服务"><a class="header" href="#3重启服务">3.重启服务</a></h3>
<pre><code>$ sudo service docker restart
# or
$ sudo /etc/init.d/docker restart
</code></pre>
<h3 id="4切换当前会话到新-group-或者重启-x-会话"><a class="header" href="#4切换当前会话到新-group-或者重启-x-会话">4.切换当前会话到新 group 或者重启 X 会话</a></h3>
<p>注意:这一步是必须的，否则因为 groups 命令获取到的是缓存的组信息，刚添加的组信息未能生效，所以 docker images 执行时同样有错。</p>
<pre><code>newgrp - docker
</code></pre>
<h3 id="5centos8安装ffmpeg"><a class="header" href="#5centos8安装ffmpeg">5.Centos8安装FFMPEG</a></h3>
<pre><code>yum install https://download1.rpmfusion.org/free/el/rpmfusion-free-release-8.noarch.rpm
yum install http://rpmfind.net/linux/epel/7/x86_64/Packages/s/SDL2-2.0.10-1.el7.x86_64.rpm
yum install ffmpeg
</code></pre>
<p><a href="docker/../static/file/linux/SDL.rpm">SDL</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="qemu"><a class="header" href="#qemu">QEMU</a></h1>
<h2 id="install"><a class="header" href="#install">install</a></h2>
<pre><code>docker run --privileged --rm tonistiigi/binfmt --install all
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker-覆盖指令"><a class="header" href="#docker-覆盖指令">Docker 覆盖指令</a></h1>
<h2 id="1覆盖entrypoint指令"><a class="header" href="#1覆盖entrypoint指令">1、覆盖ENTRYPOINT指令</a></h2>
<p>Dockerfile文件中的ENTRYPOINT指令，用以给出容器启动后默认入口。
ENTRYPOINT指令给出容器启动后的默认行为，一般难以在启动容器时覆盖，但是可以追加命令参数。示例如下：</p>
<pre><code>#给出容器入口的后续命令参数
docker run --entrypoint /bin/bash ...
#给出容器的新Shell
docker run --entrypoint=&quot;/bin/bash ...&quot; ...
#重置容器入口
docker run -it --entrypoint=&quot;&quot; mysql bash
</code></pre>
<h2 id="2覆盖cmd指令"><a class="header" href="#2覆盖cmd指令">2、覆盖CMD指令</a></h2>
<p>Dockerfile文件中的CMD指令，给出容器启动后默认执行的指令。</p>
<p>可以在启动容器的时候，为docker run设置新的命令选项，从而覆盖掉Dockerfile文件中的CMD指令（不会再咨询Dockerfile文件中的CMD指令）。示例如下：</p>
<pre><code>#可以给出其他命令以覆盖Dockerfile文件中的默认指令
docker run ... &lt;new_command&gt;
</code></pre>
<p>如果Dockerfile文件中还声明了ENTRYPOINT指令，则上述指令都将作为参数追加到ENTRYPOINT指令。</p>
<h2 id="3覆盖expose指令"><a class="header" href="#3覆盖expose指令">3、覆盖EXPOSE指令</a></h2>
<p>用以向容器所在主机保留端口。显然这是运行时容器的一个特性，所以docker run可以方便地覆盖该指令。示例如下：</p>
<pre><code>docker run --expose=&quot;port_number:port_number&quot;
#打开指定范围的端口
docker run -p port_number:port_number/tcp
#链接到其他容器
docker run --link=&quot;another_container_id&quot;
#打开所有端口
docker run -P
</code></pre>
<h2 id="4覆盖env指令"><a class="header" href="#4覆盖env指令">4、覆盖ENV指令</a></h2>
<p>ENV用以设置容器中的环境变量。启动容器时，自动为容器设置如下环境变量：</p>
<ul>
<li>HOME，基于USER设置用户主目录</li>
<li>HOSTNAME，默认容器的主机名</li>
<li>PATH，默认:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</li>
<li>TERM，默认xterm，如果容器被分配了伪TTY</li>
</ul>
<p>docker run可以方便地覆盖该指令。示例如下：</p>
<pre><code>#设置新的环境变量key
docker run -e &quot;key=value&quot; ...
#覆盖HOSTNAME
docker run -h ...
docker run ubuntu /bin/bash -c export
</code></pre>
<pre><code>declare -x HOME=&quot;/&quot;
declare -x HOSTNAME=&quot;85bc26a0e200&quot;
declare -x OLDPWD
declare -x PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;
declare -x PWD=&quot;/&quot;
declare -x SHLVL=&quot;1&quot;
declare -x deep=&quot;purple&quot;
</code></pre>
<p>通过脚本，设置或覆盖环境变量</p>
<h2 id="5覆盖volume指令"><a class="header" href="#5覆盖volume指令">5、覆盖VOLUME指令</a></h2>
<p>VOLUME用以为容器设置的data volumes。</p>
<pre><code>docker run -v ...
docker run -volumes-from ...
</code></pre>
<h2 id="6覆盖user指令"><a class="header" href="#6覆盖user指令">6、覆盖USER指令</a></h2>
<p>容器内部的默认用户是root(uid=0)。
Dockerfile文件中可以通过USER指定其他用户为容器的默认用户。</p>
<pre><code>docker run -u=&quot;&quot; ...
docker run --user=&quot;&quot; ...
</code></pre>
<p>docker run支持-u如下形式：</p>
<ul>
<li>user</li>
<li>user:group</li>
<li>uid</li>
<li>uid:gid</li>
<li>user:gid</li>
<li>uid:group</li>
</ul>
<h2 id="7覆盖workdir指令"><a class="header" href="#7覆盖workdir指令">7、覆盖WORKDIR指令</a></h2>
<p>WORKDIR用以为后续指令设置工作目录。如果设置的路径不存在，则创建该路径，即时在后续指令中根本未使用。
在一个，可以存在多个WORKDIR。对于相对路径，后续指令继承前续指令。在WORKDIR中，可以引用前续已经定义的环境变量。</p>
<pre><code>docker run -w=&quot;&quot; ...
docker run --workdir=&quot;&quot; ...
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="redis-docker"><a class="header" href="#redis-docker">redis docker</a></h1>
<h2 id="start-a-redis-instance"><a class="header" href="#start-a-redis-instance">start a redis instance</a></h2>
<pre><code>docker run --name some-redis -d redis:v6.0.0
</code></pre>
<h2 id="list-the-network"><a class="header" href="#list-the-network">list the network</a></h2>
<pre><code>docker network list
docker network create some-network
</code></pre>
<h2 id="start-with-persistent-storage"><a class="header" href="#start-with-persistent-storage">start with persistent storage</a></h2>
<pre><code>docker run --name some-redis -d redis:v6.0.0 redis-server --appendonly yes
</code></pre>
<h2 id="connecting-via-redis-cli"><a class="header" href="#connecting-via-redis-cli">connecting via redis-cli</a></h2>
<pre><code>#ser
docker run -d --name some-redis -p 6379:6379 --network some-network redis:v6.0.0 redis-server
#cli
docker run -it --rm --network some-network redis:v6.0.0 redis-cli -h some-redis -p 6379 -a 123456
</code></pre>
<h2 id="allow-remote-access"><a class="header" href="#allow-remote-access">allow remote access</a></h2>
<pre><code>docker run -d --name some-redis -p 6379:6379 -v redis.conf:/redis.conf -v data:/data redis:v6.0.0 redis-server /redis.conf --appendonly yes

#redis.conf
bind 0.0.0.0
daemonize NO
protected-mode no
requirepass 123456
</code></pre>
<h2 id="additionally-if-you-want-to-use-your-own-redisconf-"><a class="header" href="#additionally-if-you-want-to-use-your-own-redisconf-">Additionally, If you want to use your own redis.conf ...</a></h2>
<pre><code>docker run --name some-redis -v /myredis/conf/redis.conf:/usr/local/etc/redis/redis.conf redis:v6.0.0 redis-server /usr/local/etc/redis/redis.conf
</code></pre>
<h2 id="redis-set-password"><a class="header" href="#redis-set-password">redis set password</a></h2>
<pre><code>config get requirepass
config set requirepass 123456
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rootfs"><a class="header" href="#rootfs">rootfs</a></h1>
<h2 id="rootfs-1"><a class="header" href="#rootfs-1">rootfs</a></h2>
<pre><code>FROM scratch
ADD rootfs.tar.gz /
CMD [&quot;/bin/sh&quot;]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker-run"><a class="header" href="#docker-run">Docker run</a></h1>
<h2 id="docker-run-options-image-command-arg"><a class="header" href="#docker-run-options-image-command-arg">docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</a></h2>
<ul>
<li>Usage: Run a command in a new container</li>
</ul>
<pre><code>-d, --detach=false， 指定容器运行于前台还是后台，默认为false
-i, --interactive=false， 打开STDIN，用于控制台交互
-t, --tty=false， 分配tty设备，该可以支持终端登录，默认为false
-u, --user=&quot;&quot;， 指定容器的用户
-a, --attach=[]， 登录容器（必须是以docker run -d启动的容器）
-w, --workdir=&quot;&quot;， 指定容器的工作目录
-c, --cpu-shares=0， 设置容器CPU权重，在CPU共享场景使用
-e, --env=[]， 指定环境变量，容器中可以使用该环境变量
-m, --memory=&quot;&quot;， 指定容器的内存上限
-P, --publish-all=false， 指定容器暴露的端口
-p, --publish=[]， 指定容器暴露的端口
-h, --hostname=&quot;&quot;， 指定容器的主机名
-v, --volume=[]， 给容器挂载存储卷，挂载到容器的某个目录
--volumes-from=[]， 给容器挂载其他容器上的卷，挂载到容器的某个目录
--cap-add=[]， 添加权限
--cap-drop=[]， 删除权限
--cidfile=&quot;&quot;， 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法
--cpuset=&quot;&quot;， 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU
--device=[]， 添加主机设备给容器，相当于设备直通
--dns=[]， 指定容器的dns服务器
--dns-search=[]， 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件
--entrypoint=&quot;&quot;， 覆盖image的入口点
--env-file=[]， 指定环境变量文件，文件格式为每行一个环境变量
--expose=[]， 指定容器暴露的端口，即修改镜像的暴露端口
--link=[]， 指定容器间的关联，使用其他容器的IP、env等信息
--lxc-conf=[]， 指定容器的配置文件，只有在指定--exec-driver=lxc时使用
--name=&quot;&quot;， 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字
--net=&quot;bridge&quot;， 容器网络设置:
bridge 使用docker daemon指定的网桥
host //容器使用主机的网络
container:NAME_or_ID &gt;//使用其他容器的网路，共享IP和PORT等网络资源
none 容器使用自己的网络（类似--net=bridge），但是不进行配置
--privileged=false， 指定容器是否为特权容器，特权容器拥有所有的capabilities
--restart=&quot;no&quot;， 指定容器停止后的重启策略:
no：容器退出时不重启
on-failure：容器故障退出（返回值非零）时重启
always：容器退出时总是重启
--rm=false， 指定容器停止后自动删除容器(不支持以docker run -d启动的容器)
--sig-proxy=true， 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理
</code></pre>
<h2 id="示例"><a class="header" href="#示例">示例</a></h2>
<ul>
<li>运行一个在后台执行的容器，同时，还能用控制台管理：</li>
</ul>
<pre><code>docker run -i -t -d ubuntu:latest
</code></pre>
<ul>
<li>运行一个带命令在后台不断执行的容器，不直接展示容器内部信息：</li>
</ul>
<pre><code>docker run -d ubuntu:latest ping www.docker.com
</code></pre>
<ul>
<li>运行一个在后台不断执行的容器，同时带有命令，程序被终止后还能重启继续跑，还能用控制台管理：</li>
</ul>
<pre><code>docker run -d --restart=always ubuntu:latest ping www.docker.com
</code></pre>
<ul>
<li>为容器指定一个名字：</li>
</ul>
<pre><code>docker run -d --name=ubuntu_server ubuntu:latest
</code></pre>
<ul>
<li>容器暴露80端口，并指定宿主机80端口与其通信(: 之前是宿主机端口，之后是容器需暴露的端口)：</li>
</ul>
<pre><code>docker run -d --name=ubuntu_server -p 80:80 ubuntu:latest
</code></pre>
<ul>
<li>指定容器内目录与宿主机目录共享(: 之前是宿主机文件夹，之后是容器需共享的文件夹)：</li>
</ul>
<pre><code>docker run -d --name=ubuntu_server -v /etc/www:/var/www ubuntu:latest
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scratch"><a class="header" href="#scratch">scratch</a></h1>
<h2 id="from-scratch"><a class="header" href="#from-scratch">from scratch</a></h2>
<pre><code>FROM scratch
ADD hello /
CMD [&quot;/hello&quot;]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="vlmcsd-is-a-replacement-for-microsofts-kms-server"><a class="header" href="#vlmcsd-is-a-replacement-for-microsofts-kms-server">vlmcsd is a replacement for Microsoft's KMS server.</a></h2>
<p>It contains vlmcs, a KMS test client, mainly for debugging purposes, that also can &quot;charge&quot; a genuine KMS server designed to run on an always-on or often-on device, e.g. router, NAS Box, ...intended to help people who lost activation of their legally-owned licenses, e.g. due to a change of hardware (motherboard, CPU, ...)
vlmcsd is not a one-click activation or crack tool intended to activate illegal copies of software (Windows, Office, Project, Visio)</p>
<h2 id="info--about-this-docker"><a class="header" href="#info--about-this-docker">Info / About this docker</a></h2>
<p>Docker based in Alpine OS with vlmcsd compiled from &quot;source&quot; (vlmcsd GitHub)</p>
<h2 id="get-image"><a class="header" href="#get-image">Get Image</a></h2>
<pre><code>docker pull ipacking/vlmcsd:1.0.0
</code></pre>
<h2 id="server-usage"><a class="header" href="#server-usage">Server Usage</a></h2>
<pre><code>docker run -d -p 1688:1688 --restart=always --name vlmcsd ipacking/vlmcsd:1.0.0
</code></pre>
<h2 id="to-view-docker-log"><a class="header" href="#to-view-docker-log">To view docker log</a></h2>
<p>Now vlmcsd process send logs to docker.</p>
<pre><code> docker logs vlmcsd (change 'vlmcsd' with the docker's name)
</code></pre>
<h2 id="client"><a class="header" href="#client">Client</a></h2>
<ul>
<li>Windows</li>
</ul>
<pre><code>slmgr.vbs -upk
slmgr.vbs -ipk XXXXX-XXXXX-XXXXX-XXXXX-XXXXX
slmgr.vbs -skms DOCKER_IP
slmgr.vbs -ato
slmgr.vbs -dlv
</code></pre>
<ul>
<li>Office x32</li>
</ul>
<pre><code>cd \Program Files (x86)\Microsoft Office\Office16
cscript ospp.vbs /sethst:DOCKER_IP
cscript ospp.vbs /inpkey:xxxxx-xxxxx-xxxxx-xxxxx-xxxxx
cscript ospp.vbs /act
cscript ospp.vbs /dstatusall
</code></pre>
<ul>
<li>Office x64</li>
</ul>
<pre><code>cd \Program Files\Microsoft Office\Office16
cscript ospp.vbs /sethst:DOCKER_IP
cscript ospp.vbs /inpkey:xxxxx-xxxxx-xxxxx-xxxxx-xxxxx
cscript ospp.vbs /act
cscript ospp.vbs /dstatusall
</code></pre>
<h2 id="docker-link"><a class="header" href="#docker-link">Docker Link</a></h2>
<pre><code>https://hub.docker.com/r/mikolatero/vlmcsd/
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="error"><a class="header" href="#error">error</a></h1>
<h2 id="rpmdb-open-failed"><a class="header" href="#rpmdb-open-failed">rpmdb open failed</a></h2>
<pre><code>rm -f /var/lib/rpm/__db*
rpm --rebuilddb
yum -y update
</code></pre>
<h2 id="cmake-undefined-symbol-archive_write_add_filter_zstd"><a class="header" href="#cmake-undefined-symbol-archive_write_add_filter_zstd">cmake (undefined symbol archive_write_add_filter_zstd)</a></h2>
<pre><code>yum install libarchive
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="error-1"><a class="header" href="#error-1">error</a></h1>
<h2 id="rpmdb-open-failed-1"><a class="header" href="#rpmdb-open-failed-1">rpmdb open failed</a></h2>
<pre><code>rm -f /var/lib/rpm/__db*
rpm --rebuilddb
yum -y update
</code></pre>
<h2 id="cmake-undefined-symbol-archive_write_add_filter_zstd-1"><a class="header" href="#cmake-undefined-symbol-archive_write_add_filter_zstd-1">cmake (undefined symbol archive_write_add_filter_zstd)</a></h2>
<pre><code>yum install libarchive
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hooks"><a class="header" href="#hooks">hooks</a></h1>
<h2 id="local-hooks"><a class="header" href="#local-hooks">local hooks</a></h2>
<pre><code>cd .git/hooks
vi post-commit

#!/usr/bin/sh
./task (task file at project root)
</code></pre>
<h2 id="remote-hooks"><a class="header" href="#remote-hooks">remote hooks</a></h2>
<h3 id="git-server"><a class="header" href="#git-server">git server</a></h3>
<pre><code>adduser git
passwd git
su - git
mkdir -p /home/git/.ssh
vi /home/git/.ssh/authorized_keys
chmod 700 /home/git/.ssh
chmod 600 /home/git/.ssh/authorized_keys
</code></pre>
<h3 id="make-hooks"><a class="header" href="#make-hooks">make hooks</a></h3>
<pre><code>cd /home/git
git init --bare test.git
cd /home/git/test.git/hooks
vi post-receive

#!/usr/bin/sh
./task (task file at project root)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hooks-1"><a class="header" href="#hooks-1">hooks</a></h1>
<h2 id="local-hooks-1"><a class="header" href="#local-hooks-1">local hooks</a></h2>
<pre><code>cd .git/hooks
vi post-commit

#!/usr/bin/sh
./task (task file at project root)
</code></pre>
<h2 id="remote-hooks-1"><a class="header" href="#remote-hooks-1">remote hooks</a></h2>
<h3 id="git-server-1"><a class="header" href="#git-server-1">git server</a></h3>
<pre><code>adduser git
passwd git
su - git
mkdir -p /home/git/.ssh
vi /home/git/.ssh/authorized_keys
chmod 700 /home/git/.ssh
chmod 600 /home/git/.ssh/authorized_keys
</code></pre>
<h3 id="make-hooks-1"><a class="header" href="#make-hooks-1">make hooks</a></h3>
<pre><code>cd /home/git
git init --bare test.git
cd /home/git/test.git/hooks
vi post-receive

#!/usr/bin/sh
./task (task file at project root)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="git-reset"><a class="header" href="#git-reset">git reset</a></h1>
<p>简而言之，git reset 命令是用来将当前 branch 重置到另外一个 commit 的，这个动作可能同时影响到 index 以及 work directory。</p>
<p>先举个例子，来一个感性的认识。下面这两条命令让 hotfix 分支向后回退两个提交。</p>
<pre><code>git checkout hotfix
git reset HEAD~2
</code></pre>
<p><img src="git/../static/img/git/git001.png" alt="" /></p>
<p>hotfix 分支末端的两个提交现在变成了孤儿提交。下次 Git 执行垃圾回收的时候，这两个提交会被删除。如果你的提交还没有共享给别人，可以用git reset撤销这些提交。</p>
<h2 id="三棵树"><a class="header" href="#三棵树">三棵树</a></h2>
<p>理解 reset （以后还要说 checkout ）的最简方法，就是以 Git 的思维框架（将其作为内容管理器）来管理三棵不同的树。“树” 在我们这里的实际意思是 “文件集合”，而不是指特定的数据结构。</p>
<p>Git 作为一个系统，是以它的一般操作来管理并操纵这三棵树的：</p>
<div class="table-wrapper"><table><thead><tr><th>树</th><th>用途</th></tr></thead><tbody>
<tr><td>HEAD</td><td>上一次提交的快照，下一次提交的父结点</td></tr>
<tr><td>Index</td><td>预期的下一次提交的快照</td></tr>
<tr><td>Working Directory</td><td>沙盒</td></tr>
</tbody></table>
</div>
<h2 id="head"><a class="header" href="#head">HEAD</a></h2>
<p>HEAD 是当前分支引用的指针，它总是指向该分支上的最后一次提交。 这表示 HEAD 将是下一次提交的父结点。 通常，可以把 HEAD 看做你的上一次提交的快照。</p>
<p>下面是我从网上搜来的 2 张图片，感谢原作者。</p>
<p><img src="git/../static/img/git/git002.png" alt="" /></p>
<p>大意就是：HEAD 指向分支（branch），分支指向提交。</p>
<h2 id="索引index"><a class="header" href="#索引index">索引（index）</a></h2>
<p>索引是你预期的下一次提交。这就是当你运行 git commit 时 Git 看起来的样子。Git 将上一次检出到工作目录中的所有文件填充到索引（暂存区），之后你会将其中一些文件替换为新版本，接着通过 git commit 将它们转换为树来用作新提交。</p>
<h2 id="工作目录"><a class="header" href="#工作目录">工作目录</a></h2>
<p>另外两棵树以一种高效但并不直观的方式，将它们的内容存储在 .git 文件夹中。工作目录会将它们解包为实际的文件以便编辑。 你可以把工作目录当做 “沙盒”，在你将修改提交到暂存区并记录到历史之前，可以随意更改。</p>
<h2 id="流程图解"><a class="header" href="#流程图解">流程图解</a></h2>
<p>下文会用一幅幅图说明从初始化仓库到操作工作区，再到 add 文件，最后到提交等整个流程。</p>
<h2 id="仅工作目录有内容"><a class="header" href="#仅工作目录有内容">仅工作目录有内容</a></h2>
<p>假设我们进入到一个新目录，其中有一个文件。 我们称其为该文件的 v1 版本，将它标记为蓝色。 现在运行 git init，这会创建一个 Git 仓库，其中的 HEAD 引用指向未创建的分支（master 还不存在）。</p>
<p><img src="git/../static/img/git/git003.png" alt="" /></p>
<h2 id="添加到索引"><a class="header" href="#添加到索引">添加到索引</a></h2>
<p>现在我们想要提交这个文件（file.txt ），所以用 git add 把工作目录中的内容复制到索引中。</p>
<p><img src="git/../static/img/git/git004.png" alt="" /></p>
<h2 id="提交"><a class="header" href="#提交">提交</a></h2>
<p>接着运行 git commit，它会取得索引中的内容并将它保存为一个永久的快照，然后创建一个指向该快照的提交对象，最后更新 master 来指向本次提交。</p>
<p><img src="git/../static/img/git/git005.png" alt="" /></p>
<p>此时如果我们运行 git status，会发现没有任何改动，因为现在三棵树完全相同。</p>
<h2 id="修改文件"><a class="header" href="#修改文件">修改文件</a></h2>
<p>现在我们想要对文件进行修改然后提交它。我们将会经历同样的过程；首先在工作目录中修改文件。 我们称其为该文件的 v2 版本，并将它标记为红色。</p>
<p><img src="git/../static/img/git/git006.png" alt="" /></p>
<p>如果现在运行 git status，我们会看到文件显示在 “Changes not staged for commit” 下面，并被标记为红色，因为该条目在索引与工作目录之间存在不同。 接着我们运行 git add 来将它暂存到索引中。</p>
<h2 id="再次添加到索引"><a class="header" href="#再次添加到索引">再次添加到索引</a></h2>
<p><img src="git/../static/img/git/git007.png" alt="" /></p>
<p>此时，由于 Index 和 HEAD 不同，若运行 git status 的话就会看到 “Changes to be committed” 下的该文件变为绿色 ——也就是说，现在预期的下一次提交与上一次提交不同。 最后，我们运行 git commit 来完成提交。</p>
<h2 id="再次提交"><a class="header" href="#再次提交">再次提交</a></h2>
<p><img src="git/../static/img/git/git008.png" alt="" /></p>
<p>现在运行 git status 会没有输出，因为三棵树又变得相同了。</p>
<p>切换分支或克隆的过程也类似。 当检出一个分支时，它会修改 HEAD 指向新的分支引用，将索引填充为该次提交的快照，然后将索引的内容复制到工作目录中。</p>
<h2 id="reset-的作用"><a class="header" href="#reset-的作用">reset 的作用</a></h2>
<p>在以下情景中观察 reset 命令会更有意义。</p>
<p>为了演示这些例子，假设我们再次修改了 file.txt 文件并第三次提交它。 现在的历史看起来是这样的：</p>
<p><img src="git/../static/img/git/git009.png" alt="" /></p>
<p>现在，假设我们运行git reset HEAD~（后面可能会跟不同的参数）。</p>
<h3 id="第-1-步移动-head"><a class="header" href="#第-1-步移动-head">第 1 步：移动 HEAD</a></h3>
<p>reset 做的第一件事是移动 HEAD 的指向。 这与改变 HEAD 自身不同（checkout 所做的）；reset 移动 HEAD 指向的分支。 这意味着如果 HEAD 设置为 master 分支（例如，你正在 master 分支上），运行 git reset 9e5e6a4 将会使 master 指向 9e5e6a4。</p>
<p><img src="git/../static/img/git/git010.png" alt="" /></p>
<p>使用 reset –soft，它将仅仅停在那儿。</p>
<p>结合上图，我们理解一下发生的事情：它本质上是撤销了上一次 git commit 命令。 当你在运行 git commit 时，Git 会创建一个新的提交，并移动 HEAD 所指向的分支来使其指向该提交。 当你将它 reset 回 HEAD~（HEAD 的父结点）时，其实就是把该分支移回原来的位置，而不会改变索引和工作目录。</p>
<h3 id="第-2-步更新索引mixed"><a class="header" href="#第-2-步更新索引mixed">第 2 步：更新索引（–mixed）</a></h3>
<p>接下来，reset 会用 HEAD 指向的当前快照的内容来更新索引。</p>
<p><img src="git/../static/img/git/git011.png" alt="" /></p>
<p>如果指定 –mixed 选项，reset 将会在这里停止。 这也是默认行为，即如果没有指定任何选项（在本例中是 git reset HEAD~），reset 将会在这里停止。</p>
<p>现在再看一眼上图，理解一下发生的事情：它依然会撤销一上次提交，但还会取消所有暂存。 于是，我们回滚到了所有 git add 和 git commit 的命令执行之前。</p>
<h3 id="第-3-步更新工作目录hard"><a class="header" href="#第-3-步更新工作目录hard">第 3 步：更新工作目录（–hard）</a></h3>
<p>如果使用 –hard 选项，reset 要做的的第三件事情就是让工作目录看起来像索引。</p>
<p><img src="git/../static/img/git/git012.png" alt="" /></p>
<p>现在让我们回想一下刚才发生的事情：你撤销了最后的提交（git commit ）、git add 和工作目录中的所有工作。</p>
<p>必须注意，–hard 标记是 reset 命令唯一的危险用法，它也是 Git 会真正地销毁数据的仅有的几个操作之一。其他任何形式的 reset 调用都可以轻松撤消，但是 –hard 选项不能，因为它强制覆盖了工作目录中的文件。</p>
<h1 id="总结-2"><a class="header" href="#总结-2">总结</a></h1>
<p>reset 命令会以特定的顺序重写这三棵树，在你指定以下选项时停止：</p>
<ul>
<li>
<p>移动 HEAD 指向的分支 （若指定了 --soft，则到此停止）；</p>
</li>
<li>
<p>重置 index 以便和 HEAD 相匹配 （若未指定 --hard，则到此停止）；</p>
</li>
<li>
<p>使工作目录看起来像索引</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="git-file-status"><a class="header" href="#git-file-status">git file status</a></h1>
<pre><code>A: 你本地新增的文件（服务器上没有）
C: 文件的一个新拷贝
D: 你本地删除的文件（服务器上还在）
M: 文件的内容或者mode被修改了
R: 文件名被修改了
T: 文件的类型被修改了
U: 文件没有被合并(你需要完成合并才能进行提交)
X: 未知状态(很可能是遇到git的bug了，你可以向git提交bug report)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-the-go-tools"><a class="header" href="#install-the-go-tools">Install the Go tools</a></h1>
<p>If you are upgrading from an older version of Go you must first remove the existing version.</p>
<h1 id="linux-macos-and-freebsd-tarballs"><a class="header" href="#linux-macos-and-freebsd-tarballs">Linux, macOS, and FreeBSD tarballs</a></h1>
<pre><code>tar -C /usr/local -xzvf go1.11.11.linux.tar.gz
</code></pre>
<p>(Typically these commands must be run as root or through sudo.)</p>
<p>Add /usr/local/go/bin to the PATH environment variable. You can do this by adding this line to your /etc/profile (for a system-wide installation) or $HOME/.profile:</p>
<pre><code>vi /etc/profile
export PATH=$PATH:/usr/local/go/bin
source /etc/profile
# or
echo export PATH=$PATH:/usr/local/go/bin &gt;&gt; /etc/profile
source /etc/profile
</code></pre>
<p>Note: changes made to a profile file may not apply until the next time you log into your computer. To apply the changes immediately, just run the shell commands directly or execute them from the profile using a command such as source $HOME/.profile.</p>
<h1 id="show-go-version"><a class="header" href="#show-go-version">show go version</a></h1>
<pre><code>go version
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-the-go-tools-1"><a class="header" href="#install-the-go-tools-1">Install the Go tools</a></h1>
<p>If you are upgrading from an older version of Go you must first remove the existing version.</p>
<h1 id="linux-macos-and-freebsd-tarballs-1"><a class="header" href="#linux-macos-and-freebsd-tarballs-1">Linux, macOS, and FreeBSD tarballs</a></h1>
<pre><code>tar -C /usr/local -xzvf go1.11.11.linux.tar.gz
</code></pre>
<p>(Typically these commands must be run as root or through sudo.)</p>
<p>Add /usr/local/go/bin to the PATH environment variable. You can do this by adding this line to your /etc/profile (for a system-wide installation) or $HOME/.profile:</p>
<pre><code>vi /etc/profile
export PATH=$PATH:/usr/local/go/bin
source /etc/profile
# or
echo export PATH=$PATH:/usr/local/go/bin &gt;&gt; /etc/profile
source /etc/profile
</code></pre>
<p>Note: changes made to a profile file may not apply until the next time you log into your computer. To apply the changes immediately, just run the shell commands directly or execute them from the profile using a command such as source $HOME/.profile.</p>
<h1 id="show-go-version-1"><a class="header" href="#show-go-version-1">show go version</a></h1>
<pre><code>go version
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="golang-json"><a class="header" href="#golang-json">golang json</a></h1>
<pre><code>package main
 
import (
    &quot;encoding/json&quot;
    &quot;fmt&quot;
    &quot;os&quot;
)
 
type ConfigStruct struct {
    Host              string   `json:&quot;host&quot;`
    Port              int      `json:&quot;port&quot;`
    AnalyticsFile     string   `json:&quot;analytics_file&quot;`
    StaticFileVersion int      `json:&quot;static_file_version&quot;`
    StaticDir         string   `json:&quot;static_dir&quot;`
    TemplatesDir      string   `json:&quot;templates_dir&quot;`
    SerTcpSocketHost  string   `json:&quot;serTcpSocketHost&quot;`
    SerTcpSocketPort  int      `json:&quot;serTcpSocketPort&quot;`
    Fruits            []string `json:&quot;fruits&quot;`
}
 
type Other struct {
    SerTcpSocketHost string   `json:&quot;serTcpSocketHost&quot;`
    SerTcpSocketPort int      `json:&quot;serTcpSocketPort&quot;`
    Fruits           []string `json:&quot;fruits&quot;`
}
 
func main() { 
    jsonStr := `{&quot;host&quot;: &quot;http://localhost:8080&quot;,&quot;port&quot;: 8080,&quot;analytics_file&quot;: &quot;&quot;,&quot;static_file_version&quot;: 1,&quot;static_dir&quot;: &quot;/opt/Project/goTest/src/&quot;,&quot;templates_dir&quot;: &quot;/opt/Project/goTest/src/templates/&quot;,&quot;serTcpSocketHost&quot;: &quot;:12340&quot;,&quot;serTcpSocketPort&quot;: 12340,&quot;fruits&quot;: [&quot;apple&quot;, &quot;peach&quot;]}`
 
    //json str &gt;&gt; map
    var dat map[string]interface{}
    if err := json.Unmarshal([]byte(jsonStr), &amp;dat); err == nil {
        fmt.Println(&quot;============== json str &gt;&gt; map ==============&quot;)
        fmt.Println(dat)
        fmt.Println(dat[&quot;host&quot;])
    }
 
    //json str &gt;&gt; struct
    var config ConfigStruct
    if err := json.Unmarshal([]byte(jsonStr), &amp;config); err == nil {
        fmt.Println(&quot;============== json str &gt;&gt; struct ==============&quot;)
        fmt.Println(config)
        fmt.Println(config.Host)
    }
 
    //json str &gt;&gt; struct
    var part Other
    if err := json.Unmarshal([]byte(jsonStr), &amp;part); err == nil {
        fmt.Println(&quot;============== json str &gt;&gt; struct ==============&quot;)
        fmt.Println(part)
        fmt.Println(part.SerTcpSocketPort)
    }
 
    //struct &gt;&gt; json str
    if b, err := json.Marshal(config); err == nil {
        fmt.Println(&quot;============== struct &gt;&gt; json str ==============&quot;)
        fmt.Println(string(b))
    }
 
    //map &gt;&gt; json str
    fmt.Println(&quot;============== map &gt;&gt; json str ==============&quot;)
    enc := json.NewEncoder(os.Stdout)
    enc.Encode(dat)
 
    //array &gt;&gt; json str
    arr := []string{&quot;hello&quot;, &quot;apple&quot;, &quot;python&quot;, &quot;golang&quot;, &quot;base&quot;, &quot;peach&quot;, &quot;pear&quot;}
    lang, err := json.Marshal(arr)
    if err == nil {
        fmt.Println(&quot;============== array &gt;&gt; json str ==============&quot;)
        fmt.Println(string(lang))
    }
 
    //json &gt;&gt; []string
    var wo []string
    if err := json.Unmarshal(lang, &amp;wo); err == nil {
        fmt.Println(&quot;============== json &gt;&gt; []string ==============&quot;)
        fmt.Println(wo)
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="1-go-micro接口详解"><a class="header" href="#1-go-micro接口详解">1. Go Micro接口详解</a></h1>
<h2 id="11-transort通信接口"><a class="header" href="#11-transort通信接口">1.1. Transort通信接口</a></h2>
<p>通信相关接口</p>
<pre><code>type Socket interface {
   Recv(*Message) error
   Send(*Message) error
   Close() error
}

type Client interface {
   Socket
}

type Listener interface {
   Addr() string
   Close() error
   Accept(func(Socket)) error
}

type Transport interface {
   Dial(addr string, opts ...DialOption) (Client, error)
   Listen(addr string, opts ...ListenOption) (Listener, error)
   String() string
}
</code></pre>
<h2 id="12-codec编码接口"><a class="header" href="#12-codec编码接口">1.2. Codec编码接口</a></h2>
<p>编解码，底层也是protobuf</p>
<pre><code>type Codec interface {
   ReadHeader(*Message, MessageType) error
   ReadBody(interface{}) error
   Write(*Message, interface{}) error
   Close() error
   String() string
}
</code></pre>
<h2 id="13-registry注册接口"><a class="header" href="#13-registry注册接口">1.3. Registry注册接口</a></h2>
<p>服务注册发现的实现：etcd、consul、mdns、kube-DNS、zk</p>
<pre><code>type Registry interface {
   Register(*Service, ...RegisterOption) error
   Deregister(*Service) error
   GetService(string) ([]*Service, error)
   ListServices() ([]*Service, error)
   Watch(...WatchOption) (Watcher, error)
   String() string
   Options() Options
}
</code></pre>
<h2 id="14-selector负载均衡"><a class="header" href="#14-selector负载均衡">1.4. Selector负载均衡</a></h2>
<p>根据不同算法请求主机列表</p>
<pre><code>type Selector interface {
   Init(opts ...Option) error
   Options() Options
   // Select returns a function which should return the next node
   Select(service string, opts ...SelectOption) (Next, error)
   // Mark sets the success/error against a node
   Mark(service string, node *registry.Node, err error)
   // Reset returns state back to zero for a service
   Reset(service string)
   // Close renders the selector unusable
   Close() error
   // Name of the selector
   String() string
}
</code></pre>
<h2 id="15-broker发布订阅接口"><a class="header" href="#15-broker发布订阅接口">1.5. Broker发布订阅接口</a></h2>
<p>pull push watch</p>
<pre><code>type Broker interface {
   Options() Options
   Address() string
   Connect() error
   Disconnect() error
   Init(...Option) error
   Publish(string, *Message, ...PublishOption) error
   Subscribe(string, Handler, ...SubscribeOption) (Subscriber, error)
   String() string
}
</code></pre>
<h2 id="16-client客户端接口"><a class="header" href="#16-client客户端接口">1.6. Client客户端接口</a></h2>
<pre><code>type Client interface {
   Init(...Option) error
   Options() Options
   NewMessage(topic string, msg interface{}, opts ...MessageOption) Message
   NewRequest(service, method string, req interface{}, reqOpts ...RequestOption) Request
   Call(ctx context.Context, req Request, rsp interface{}, opts ...CallOption) error
   Stream(ctx context.Context, req Request, opts ...CallOption) (Stream, error)
   Publish(ctx context.Context, msg Message, opts ...PublishOption) error
   String() string
}
</code></pre>
<h2 id="17-server服务端接口"><a class="header" href="#17-server服务端接口">1.7. Server服务端接口</a></h2>
<pre><code>type Server interface {
   Options() Options
   Init(...Option) error
   Handle(Handler) error
   NewHandler(interface{}, ...HandlerOption) Handler
   NewSubscriber(string, interface{}, ...SubscriberOption) Subscriber
   Subscribe(Subscriber) error
   Register() error
   Deregister() error
   Start() error
   Stop() error
   String() string
}
</code></pre>
<h2 id="18-serveice接口"><a class="header" href="#18-serveice接口">1.8. Serveice接口</a></h2>
<pre><code>type Service interface {
   Init(...Option)
   Options() Options
   Client() client.Client
   Server() server.Server
   Run() error
   String() string
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mod-require--replace"><a class="header" href="#mod-require--replace">mod require &amp; replace</a></h1>
<pre><code>require github.com/article v0.0.0
replace github.com/article =&gt; ./article
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="third-go-pkg"><a class="header" href="#third-go-pkg">third go pkg</a></h1>
<h2 id="go-cli"><a class="header" href="#go-cli">go cli</a></h2>
<pre><code>github.com/urfave/cli
</code></pre>
<h2 id="go-mage"><a class="header" href="#go-mage">go mage</a></h2>
<pre><code>github.com/magefile/mage/
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="fmtprintf"><a class="header" href="#fmtprintf">fmt.printf</a></h1>
<pre><code>package main

import &quot;fmt&quot;
import &quot;os&quot;

type point struct {
	x, y int
}

func main() {
	p := point{1, 2}
	//输出结构体的一个实例
	fmt.Printf(&quot;%v\n&quot;, p) //{1 2}
	//输出实例将包括字段名
	fmt.Printf(&quot;%+v\n&quot;, p) //{x:1 y:2}
	//输出实例的语法表示
	fmt.Printf(&quot;%#v\n&quot;, p) //main.point{x:1, y:2}
	//输出值的类型
	fmt.Printf(&quot;%T\n&quot;, p) //main.point
	//输出布尔值
	fmt.Printf(&quot;%t\n&quot;, true) //true
	//输出二进制
	fmt.Printf(&quot;%b\n&quot;, 14) //1110
    //输出八进制
	fmt.Printf(&quot;%o\n&quot;, 32) //40
	//输出十进制
	fmt.Printf(&quot;%d\n&quot;, 123) //123
	//输出十六进制
	fmt.Printf(&quot;%x\n&quot;, 456) //1c8
	//输出字符
	fmt.Printf(&quot;%c\n&quot;, 33) //!
	//输出字符串
	fmt.Printf(&quot;%s\n&quot;, &quot;\&quot;string\&quot;&quot;) //&quot;string&quot;
	//输出浮点数
	fmt.Printf(&quot;%f\n&quot;, 78.9) //78.900000
	//输出科学记数法形式
	fmt.Printf(&quot;%e\n&quot;, 123400000.0) //1.234000e+08
	fmt.Printf(&quot;%E\n&quot;, 123400000.0) //1.234000E+08
	//输出带双引号形式
	fmt.Printf(&quot;%q\n&quot;, &quot;\&quot;string\&quot;&quot;) //&quot;\&quot;string\&quot;&quot;
	//输出十六进制的字符串形式
	fmt.Printf(&quot;%x\n&quot;, &quot;hex this&quot;) //6865782074686973
	//输出指针
	fmt.Printf(&quot;%p\n&quot;, &amp;p) //0xc000080010
	//输出带宽度的十进制形式
	fmt.Printf(&quot;|%6d|%6d|\n&quot;, 12, 345) //|    12|   345|
	//输出带宽度精度的浮点数形式
	fmt.Printf(&quot;|%6.2f|%6.2f|\n&quot;, 1.2, 3.45) //|  1.20|  3.45|
	//输出带宽度精度左对齐的浮点数形式
	fmt.Printf(&quot;|%-6.2f|%-6.2f|\n&quot;, 1.2, 3.45) //|1.20  |3.45  |
	//输出带宽度的字符串形式
	fmt.Printf(&quot;|%6s|%6s|\n&quot;, &quot;foo&quot;, &quot;b&quot;) //|   foo|     b|
	//输出带宽度左对齐的字符串形式
	fmt.Printf(&quot;|%-6s|%-6s|\n&quot;, &quot;foo&quot;, &quot;b&quot;) //|foo   |b     |
	//返回指定形式的值
	s := fmt.Sprintf(&quot;a %s&quot;, &quot;string&quot;)
	fmt.Println(s) //a string
	//重定向指定形式的值
	fmt.Fprintf(os.Stderr, &quot;an %s\n&quot;, &quot;error&quot;) //an error
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="type"><a class="header" href="#type">TYPE</a></h1>
<h2 id="1值类型与引用类型的区别"><a class="header" href="#1值类型与引用类型的区别">1、值类型与引用类型的区别</a></h2>
<h3 id="11-本质存储区别"><a class="header" href="#11-本质存储区别">1.1 本质存储区别</a></h3>
<p>值类型与引用类型的区别主要在于：</p>
<ul>
<li>
<p>值类型的变量：存储当前类型的存储的数据。值类型包括:布尔、数值、字符串、数组、结构体。</p>
</li>
<li>
<p>引用类型变量：存储地址，该地址对应的空间才是真正存储的数据。引用类型包括：切片、集合、通道、指针、接口等类型。</p>
</li>
</ul>
<h3 id="12-使用区别"><a class="header" href="#12-使用区别">1.2 使用区别</a></h3>
<ul>
<li>
<p>值类型：声明变量之后可以直接使用</p>
</li>
<li>
<p>引用类型：对于引用类型，若使用var进行声明变量，必须使用make函数对其进行分配内存。若不初始化，该变量默认值为nil，向其添加元素时会导致panic。</p>
</li>
</ul>
<h2 id="2示例验证"><a class="header" href="#2示例验证">2、示例验证</a></h2>
<p>我们可以通过下面的小程序来验证上述的想法:</p>
<ul>
<li>
<p>对于int类型的a，将其转换为地址进行打印，结果打印表示错误类型，不是地址类型.a:%!p</p>
</li>
<li>
<p>对于map类型b，将其转换为地址打印可看出其存储的为指针类型且为0xc000078150，将其传入函数中，该函数接受的参数值也为该变量存储的地址值test:0xc000078150。</p>
</li>
</ul>
<pre><code>package main

import &quot;fmt&quot;

func test(test map[string]string) {
    // test:0xc000078150
	fmt.Printf(&quot;test:%p\n&quot;, test)
	// &amp;test:0xc000098028
	fmt.Printf(&quot;&amp;test:%p\n&quot;, &amp;test)
}

func main() {
	a := 10
	// a:%!p(int=10)
	fmt.Printf(&quot;a:%p\n&quot;, a)
	// &amp;a:0xc000096010
	fmt.Printf(&quot;&amp;a:%p\n&quot;, &amp;a)

	b := map[string]string{}
	// b:0xc000078150
	fmt.Printf(&quot;b:%p\n&quot;, b)
	// &amp;b:0xc000098020
	fmt.Printf(&quot;&amp;b:%p\n&quot;, &amp;b)
	test(b)
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tools"><a class="header" href="#tools">tools</a></h1>
<h2 id="dlv"><a class="header" href="#dlv">dlv</a></h2>
<pre><code>go install github.com/go-delve/delve/cmd/dlv@latest
</code></pre>
<h2 id="gopls"><a class="header" href="#gopls">gopls</a></h2>
<pre><code>go install golang.org/x/tools/gopls@latest
</code></pre>
<h2 id="impl"><a class="header" href="#impl">impl</a></h2>
<pre><code>go install github.com/josharian/impl@latest
</code></pre>
<h2 id="gotests"><a class="header" href="#gotests">gotests</a></h2>
<pre><code>go install github.com/cweill/gotests/gotests@latest
</code></pre>
<h2 id="goplay"><a class="header" href="#goplay">goplay</a></h2>
<pre><code>go install github.com/haya14busa/goplay/cmd/goplay@latest
</code></pre>
<h2 id="go-outline"><a class="header" href="#go-outline">go-outline</a></h2>
<pre><code>go install github.com/ramya-rao-a/go-outline@latest
</code></pre>
<h2 id="gomodifytags"><a class="header" href="#gomodifytags">gomodifytags</a></h2>
<pre><code>go install github.com/fatih/gomodifytags@latest
</code></pre>
<h2 id="staticcheck"><a class="header" href="#staticcheck">staticcheck</a></h2>
<pre><code>go install honnef.co/go/tools/cmd/staticcheck@latest
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="alpine"><a class="header" href="#alpine">alpine</a></h1>
<h2 id="apk-repository"><a class="header" href="#apk-repository">apk repository</a></h2>
<pre><code>vi /etc/apk/repositories

https://mirrors.aliyun.com/alpine/v3.10/main
https://mirrors.aliyun.com/alpine/v3.10/community
</code></pre>
<h2 id="service"><a class="header" href="#service">service</a></h2>
<pre><code>apk add openrc
</code></pre>
<h2 id="use-open-rc"><a class="header" href="#use-open-rc">use open rc</a></h2>
<pre><code>rc-status
rc-update
rc-service
</code></pre>
<h2 id="gcc-compile"><a class="header" href="#gcc-compile">gcc compile</a></h2>
<pre><code>FROM scratch
ADD alpine.tar.gz /
RUN echo https://mirrors.aliyun.com/alpine/v3.10/main &gt; /etc/apk/repositories \
    &amp;&amp; echo https://mirrors.aliyun.com/alpine/v3.10/community &gt;&gt; /etc/apk/repositories \
    &amp;&amp; apk --no-cache add gcc g++ make cmake clang zip unzip openrc xz wget curl git subversion
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="alpine-1"><a class="header" href="#alpine-1">alpine</a></h1>
<h2 id="apk-repository-1"><a class="header" href="#apk-repository-1">apk repository</a></h2>
<pre><code>vi /etc/apk/repositories

https://mirrors.aliyun.com/alpine/v3.10/main
https://mirrors.aliyun.com/alpine/v3.10/community
</code></pre>
<h2 id="service-1"><a class="header" href="#service-1">service</a></h2>
<pre><code>apk add openrc
</code></pre>
<h2 id="use-open-rc-1"><a class="header" href="#use-open-rc-1">use open rc</a></h2>
<pre><code>rc-status
rc-update
rc-service
</code></pre>
<h2 id="gcc-compile-1"><a class="header" href="#gcc-compile-1">gcc compile</a></h2>
<pre><code>FROM scratch
ADD alpine.tar.gz /
RUN echo https://mirrors.aliyun.com/alpine/v3.10/main &gt; /etc/apk/repositories \
    &amp;&amp; echo https://mirrors.aliyun.com/alpine/v3.10/community &gt;&gt; /etc/apk/repositories \
    &amp;&amp; apk --no-cache add gcc g++ make cmake clang zip unzip openrc xz wget curl git subversion
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-language"><a class="header" href="#install-language">install language</a></h1>
<h2 id="ubuntu"><a class="header" href="#ubuntu">ubuntu</a></h2>
<h3 id="search-language"><a class="header" href="#search-language">search language</a></h3>
<pre><code>apt search language-pack
</code></pre>
<h3 id="install-zh_cn"><a class="header" href="#install-zh_cn">install zh_CN</a></h3>
<pre><code>apt install language-pack-zh-hans
</code></pre>
<h3 id="install-en_us"><a class="header" href="#install-en_us">install en_US</a></h3>
<pre><code>apt install language-pack-en
</code></pre>
<h3 id="set-language"><a class="header" href="#set-language">set language</a></h3>
<pre><code>vi /etc/profile (~/.bashrc)
export LANG=en_US.UTF-8
export LANGUAGE=en_US.UTF-8
export LC_ALL=en_US.UTF-8
</code></pre>
<h2 id="centos"><a class="header" href="#centos">centos</a></h2>
<h3 id="search-language-1"><a class="header" href="#search-language-1">search language</a></h3>
<pre><code>yum search langpacks
</code></pre>
<h3 id="install-zh_cn-1"><a class="header" href="#install-zh_cn-1">install zh_CN</a></h3>
<pre><code>yum install glibc-all-langpacks
yum install langpacks-zh_CN
</code></pre>
<h3 id="install-en_us-1"><a class="header" href="#install-en_us-1">install en_US</a></h3>
<pre><code>yum install glibc-all-langpacks
yum install langpacks-en_US
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-tool"><a class="header" href="#install-tool">install tool</a></h1>
<h2 id="ping"><a class="header" href="#ping">ping</a></h2>
<pre><code>apt install inetutils-ping
</code></pre>
<h2 id="ifconfig"><a class="header" href="#ifconfig">ifconfig</a></h2>
<pre><code>apt install net-tools
</code></pre>
<h2 id="ssh"><a class="header" href="#ssh">ssh</a></h2>
<pre><code>apt install openssh-server
apt install openssh-client
</code></pre>
<h2 id="compile"><a class="header" href="#compile">compile</a></h2>
<pre><code>apt install cmake make 
apt install gcc
</code></pre>
<h2 id="build-env"><a class="header" href="#build-env">build env</a></h2>
<pre><code>apt install build-essential
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="install-dep"><a class="header" href="#install-dep">install dep</a></h2>
<pre><code>apt install cmake make gcc g++ pkg-config
</code></pre>
<h2 id="install-opencv"><a class="header" href="#install-opencv">install opencv</a></h2>
<pre><code>cmake -D CMAKE_BUILD_TYPE=RELEASE \
      -D WITH_IPP=OFF \
      -D WITH_OPENGL=OFF \
      -D WITH_QT=OFF \
      -D BUILD_EXAMPLES=OFF \
      -D BUILD_TESTS=OFF \
      -D BUILD_PERF_TESTS=OFF  \
      -D BUILD_opencv_java=OFF \
      -D BUILD_opencv_python=OFF \
      -D BUILD_opencv_python2=OFF \
      -D BUILD_opencv_python3=OFF \
      -D OPENCV_GENERATE_PKGCONFIG=ON \
      -D OPENCV_ENABLE_NONFREE=ON \
      -D OPENCV_EXTRA_MODULES_PATH=/usr/local/opencv_contrib/modules \
      -D CMAKE_INSTALL_PREFIX=/usr/local/opencv ..
make
make install
ldconfig
</code></pre>
<h2 id="set-env"><a class="header" href="#set-env">set env</a></h2>
<pre><code>echo &quot;export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/opencv/lib/pkgconfig&quot; &gt;&gt; ~/.bashrc
echo &quot;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/opencv/lib&quot; &gt;&gt; ~/.bashrc
source ~/.bashrc
</code></pre>
<h2 id="make-java-env-jar--so"><a class="header" href="#make-java-env-jar--so">make java env (jar &amp; so)</a></h2>
<pre><code>cmake -D CMAKE_BUILD_TYPE=RELEASE \
      -D BUILD_SHARED_LIBS=OFF \
      -D BUILD_FAT_JAVA_LIB=ON \
      -D CMAKE_INSTALL_PREFIX=/usr/local/opencv ..
make
make install
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wxwidgets"><a class="header" href="#wxwidgets">wxWidgets</a></h1>
<h2 id="build-on-windows-mingw"><a class="header" href="#build-on-windows-mingw">build on windows (MinGW)</a></h2>
<pre><code>cd ${SRC_ROOT}/build/msw
make -f makefile.gcc CPPFLAGS=-std=c++11 SHARED=0 BUILD=debug UNICODE=1
make -f makefile.gcc CPPFLAGS=-std=c++11 SHARED=0 BUILD=release UNICODE=1
make -f makefile.gcc CPPFLAGS=-std=c++11 SHARED=1 BUILD=release UNICODE=1
</code></pre>
<h3 id="the-library-file"><a class="header" href="#the-library-file">the library file</a></h3>
<pre><code>${SRC_ROOT}/lib/gcc_lib
${SRC_ROOT}/lib/gcc_dll
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="jvm"><a class="header" href="#jvm">jvm</a></h1>
<h2 id="get-thread-list"><a class="header" href="#get-thread-list">get thread list</a></h2>
<pre><code>jstack &lt;pid&gt;
</code></pre>
<h2 id="get-dump-file"><a class="header" href="#get-dump-file">get dump file</a></h2>
<pre><code>jmap -dump&lt;:live&gt;,format=b,file=out.dump &lt;pid&gt;
-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="maven"><a class="header" href="#maven">maven</a></h1>
<h2 id="deploy"><a class="header" href="#deploy">deploy</a></h2>
<h3 id="1-settingsxml"><a class="header" href="#1-settingsxml">1. settings.xml</a></h3>
<pre><code>&lt;servers&gt;
    &lt;server&gt;
        &lt;id&gt;one&lt;/id&gt;
        &lt;username&gt;admin&lt;/username&gt;
        &lt;password&gt;123456&lt;/password&gt;
    &lt;/server&gt;

&lt;/servers&gt;
</code></pre>
<h3 id="2-pomxml"><a class="header" href="#2-pomxml">2. pom.xml</a></h3>
<h4 id="21-distribution"><a class="header" href="#21-distribution">2.1 distribution</a></h4>
<pre><code>&lt;distributionManagement&gt;
    &lt;repository&gt;
        &lt;id&gt;one&lt;/id&gt;
        &lt;name&gt;Repository one&lt;/name&gt;
        &lt;url&gt;http://one.com/repository/maven-public&lt;/url&gt;
        &lt;layout&gt;default&lt;/layout&gt;
        &lt;uniqueVersion&gt;false&lt;/uniqueVersion&gt;
    &lt;/repository&gt;

&lt;/distributionManagement&gt;
</code></pre>
<h4 id="22-skip-test"><a class="header" href="#22-skip-test">2.2 skip test</a></h4>
<pre><code>mvn -DskipTests clean package
mvn -Dmaven.test.skip=true clean package
</code></pre>
<blockquote>
<p>or</p>
</blockquote>
<pre><code>&lt;properties&gt;
    &lt;maven.test.skip&gt;true&lt;/maven.test.skip&gt;
&lt;/properties&gt;
</code></pre>
<h4 id="23-build-sub-module"><a class="header" href="#23-build-sub-module">2.3 build sub module</a></h4>
<pre><code>mvn clean install
mvn clean package -pl sub1/sub2/sub3 -am
mvn clean package -pl :sub3 -am -o
mvn clean package -pl :sub3 -am -Drevision=1.0.0-snapshot
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="maven-1"><a class="header" href="#maven-1">maven</a></h1>
<h2 id="deploy-1"><a class="header" href="#deploy-1">deploy</a></h2>
<h3 id="1-settingsxml-1"><a class="header" href="#1-settingsxml-1">1. settings.xml</a></h3>
<pre><code>&lt;servers&gt;
    &lt;server&gt;
        &lt;id&gt;one&lt;/id&gt;
        &lt;username&gt;admin&lt;/username&gt;
        &lt;password&gt;123456&lt;/password&gt;
    &lt;/server&gt;

&lt;/servers&gt;
</code></pre>
<h3 id="2-pomxml-1"><a class="header" href="#2-pomxml-1">2. pom.xml</a></h3>
<h4 id="21-distribution-1"><a class="header" href="#21-distribution-1">2.1 distribution</a></h4>
<pre><code>&lt;distributionManagement&gt;
    &lt;repository&gt;
        &lt;id&gt;one&lt;/id&gt;
        &lt;name&gt;Repository one&lt;/name&gt;
        &lt;url&gt;http://one.com/repository/maven-public&lt;/url&gt;
        &lt;layout&gt;default&lt;/layout&gt;
        &lt;uniqueVersion&gt;false&lt;/uniqueVersion&gt;
    &lt;/repository&gt;

&lt;/distributionManagement&gt;
</code></pre>
<h4 id="22-skip-test-1"><a class="header" href="#22-skip-test-1">2.2 skip test</a></h4>
<pre><code>mvn -DskipTests clean package
mvn -Dmaven.test.skip=true clean package
</code></pre>
<blockquote>
<p>or</p>
</blockquote>
<pre><code>&lt;properties&gt;
    &lt;maven.test.skip&gt;true&lt;/maven.test.skip&gt;
&lt;/properties&gt;
</code></pre>
<h4 id="23-build-sub-module-1"><a class="header" href="#23-build-sub-module-1">2.3 build sub module</a></h4>
<pre><code>mvn clean install
mvn clean package -pl sub1/sub2/sub3 -am
mvn clean package -pl :sub3 -am -o
mvn clean package -pl :sub3 -am -Drevision=1.0.0-snapshot
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="springboot-logback"><a class="header" href="#springboot-logback">springboot logback</a></h1>
<p>springboot默认的日志文件是不会自动按天分割的，所以生产环境的日志文件越来越大，很不利于排错。查了很多资料最终配置如下，可以完美按天按错误等级分割日志文件，配置如下。</p>
<p>由于springboot采用约定优先于配置的方式，日志文件也是，SpringBoot项目中在官方文档中https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-logging.html 说明，默认已经依赖了一些日志框架。而其中推荐使用的就是Logback，说明一下，SpringBoot已经依赖了Logback所以不需要手动添加依赖。</p>
<p>首先不同环境下的logback配置肯定是不一样的，所以我的解决办法是：</p>
<p>项目中的application.properties已经通过spring.profiles.active来分割成不同环境下使用不同的properties配置，比如application-dev.properties(开发环境)，application-test.properties(测试环境)，application-prod.properties（生产环境）,再加上application.properties（这个文件可能只包含spring.profiles.active就够了，真正的配置可能都在带-的文件里，因为springboot默认会加载它，然后通过它来指定使用哪个文件） 共有4个properties 文件，然后在application.properties 通过spring.profiles.active指定要使用的真正的properties</p>
<p>ok 上面是简单的聊了一下application.properties配置的问题，正戏来了</p>
<p>接下来就要创建出来 logback-spring-dev.xml，logback-spring-test.xml，logback-spring-prod.xml三个文件，然后在每个对应环境的properties通过 logging.config 来指定logback 的xml文件</p>
<p>logging.config=classpath:logback-spring-dev.xml</p>
<p>至于logback的xml文件内容如下：</p>
<p>logback-spring-dev.xml 开发环境下，不需要输出到文件，只需要打印在控制台就行了。</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;

&lt;!-- ALL &lt; TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL &lt; OFF --&gt;
&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;
    &lt;contextName&gt;d1money-web-ys-ems&lt;/contextName&gt;

    &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;
                %d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger -%msg%n
            &lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;logger name=&quot;java.sql.PreparedStatement&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;java.sql.Connection&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;java.sql.Statement&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.common.jdbc.SimpleDataSource&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.common.jdbc.ScriptRunner&quot; level=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;TRACE&quot;/&gt;

    &lt;root level=&quot;debug&quot;&gt;
        &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;
    &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>
<p>然后是 logback-spring-test.xml 和logback-spring-prod.xml，test环境与prod的只是文件位置不同所以只贴一份了，改下路径就行了，并且测试和生产是不需要控制台输出的，不然catalina.out文件就要爆炸了！</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;

&lt;!-- 从高到地低 OFF 、 FATAL 、 ERROR 、 WARN 、 INFO 、 DEBUG 、 TRACE 、 ALL --&gt;
&lt;!-- 日志输出规则 根据当前ROOT 级别，日志输出时，级别高于root默认的级别时 会输出 --&gt;
&lt;!-- 以下 每个配置的 filter 是过滤掉输出文件里面，会出现高级别文件，依然出现低级别的日志信息，通过filter 过滤只记录本级别的日志 --&gt;
&lt;!-- 属性描述 scan：性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 
	debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;
&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;
    &lt;contextName&gt;d1money-web-ys-ems&lt;/contextName&gt;
    &lt;!-- 定义日志文件 输入位置 --&gt;
    &lt;property name=&quot;log_dir&quot; value=&quot;/soft/apache-tomcat-8.5.30-ems/logs&quot;/&gt;
    &lt;!-- 日志最大的历史 30天 --&gt;
    &lt;property name=&quot;maxHistory&quot; value=&quot;30&quot;/&gt;
    &lt;property name=&quot;maxFileSize&quot; value=&quot;10MB&quot;/&gt;
    &lt;!-- ERROR级别日志 --&gt;
    &lt;!-- 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 RollingFileAppender --&gt;
    &lt;appender name=&quot;ERROR&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录WARN级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;ERROR&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;!-- 最常用的滚动策略，它根据时间来制定滚动策略.既负责滚动也负责出发滚动 --&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;

            &lt;!--日志输出位置 可相对、和绝对路径 --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_error.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件假设设置每个月滚动，且&lt;maxHistory&gt;是6， 则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;
            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;

        &lt;/rollingPolicy&gt;
        &lt;!-- 按照固定窗口模式生成日志文件，当文件大于20MB时，生成新的日志文件。窗口大小是1到3，当保存了3个归档文件后，将覆盖最早的日志。--&gt;
        &lt;!--&lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.FixedWindowRollingPolicy&quot;&gt;
            &lt;fileNamePattern&gt;${log_dir}/%d{yyyy-MM-dd}/.log.zip&lt;/fileNamePattern&gt;
            &lt;minIndex&gt;1&lt;/minIndex&gt;
            &lt;maxIndex&gt;3&lt;/maxIndex&gt;
        &lt;/rollingPolicy&gt;--&gt;
        &lt;!-- 查看当前活动文件的大小，如果超过指定大小会告知RollingFileAppender 触发当前活动文件滚动--&gt;
        &lt;!--&lt;triggeringPolicy
                class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt;
            &lt;maxFileSize&gt;5MB&lt;/maxFileSize&gt;
        &lt;/triggeringPolicy&gt;--&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!-- WARN级别日志 appender --&gt;
    &lt;appender name=&quot;WARN&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录WARN级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;WARN&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天回滚 daily --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_warn.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 日志最大的历史 30天 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;
            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;
        &lt;/rollingPolicy&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!-- INFO级别日志 appender --&gt;
    &lt;appender name=&quot;INFO&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录INFO级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;INFO&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天回滚 daily --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_info.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 日志最大的历史 30天 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;
            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;
        &lt;/rollingPolicy&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!-- DEBUG级别日志 appender --&gt;
    &lt;appender name=&quot;DEBUG&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录DEBUG级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;DEBUG&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天回滚 daily --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_debug.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 日志最大的历史 30天 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;
            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;
        &lt;/rollingPolicy&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!-- TRACE级别日志 appender --&gt;
    &lt;appender name=&quot;TRACE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录ERROR级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;TRACE&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天回滚 daily --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_trace.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 日志最大的历史 30天 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;

            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;
        &lt;/rollingPolicy&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;logger name=&quot;java.sql.PreparedStatement&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;java.sql.Connection&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;java.sql.Statement&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.common.jdbc.SimpleDataSource&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.common.jdbc.ScriptRunner&quot; level=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;TRACE&quot;/&gt;

    &lt;!-- root级别 DEBUG --&gt;
    &lt;root level=&quot;debug&quot;&gt;
        &lt;!-- 文件输出 --&gt;
        &lt;appender-ref ref=&quot;ERROR&quot;/&gt;
        &lt;appender-ref ref=&quot;INFO&quot;/&gt;
        &lt;appender-ref ref=&quot;WARN&quot;/&gt;
        &lt;appender-ref ref=&quot;DEBUG&quot;/&gt;
        &lt;appender-ref ref=&quot;TRACE&quot;/&gt;
    &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>
<p>最后达到的效果是按大小日期生成日志文件，超过设定大小就会重新生成新文件，由0开始累积。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="springboot-logback-1"><a class="header" href="#springboot-logback-1">springboot logback</a></h1>
<p>springboot默认的日志文件是不会自动按天分割的，所以生产环境的日志文件越来越大，很不利于排错。查了很多资料最终配置如下，可以完美按天按错误等级分割日志文件，配置如下。</p>
<p>由于springboot采用约定优先于配置的方式，日志文件也是，SpringBoot项目中在官方文档中https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-logging.html 说明，默认已经依赖了一些日志框架。而其中推荐使用的就是Logback，说明一下，SpringBoot已经依赖了Logback所以不需要手动添加依赖。</p>
<p>首先不同环境下的logback配置肯定是不一样的，所以我的解决办法是：</p>
<p>项目中的application.properties已经通过spring.profiles.active来分割成不同环境下使用不同的properties配置，比如application-dev.properties(开发环境)，application-test.properties(测试环境)，application-prod.properties（生产环境）,再加上application.properties（这个文件可能只包含spring.profiles.active就够了，真正的配置可能都在带-的文件里，因为springboot默认会加载它，然后通过它来指定使用哪个文件） 共有4个properties 文件，然后在application.properties 通过spring.profiles.active指定要使用的真正的properties</p>
<p>ok 上面是简单的聊了一下application.properties配置的问题，正戏来了</p>
<p>接下来就要创建出来 logback-spring-dev.xml，logback-spring-test.xml，logback-spring-prod.xml三个文件，然后在每个对应环境的properties通过 logging.config 来指定logback 的xml文件</p>
<p>logging.config=classpath:logback-spring-dev.xml</p>
<p>至于logback的xml文件内容如下：</p>
<p>logback-spring-dev.xml 开发环境下，不需要输出到文件，只需要打印在控制台就行了。</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;

&lt;!-- ALL &lt; TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL &lt; OFF --&gt;
&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;
    &lt;contextName&gt;d1money-web-ys-ems&lt;/contextName&gt;

    &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;
                %d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger -%msg%n
            &lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;logger name=&quot;java.sql.PreparedStatement&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;java.sql.Connection&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;java.sql.Statement&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.common.jdbc.SimpleDataSource&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.common.jdbc.ScriptRunner&quot; level=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;TRACE&quot;/&gt;

    &lt;root level=&quot;debug&quot;&gt;
        &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;
    &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>
<p>然后是 logback-spring-test.xml 和logback-spring-prod.xml，test环境与prod的只是文件位置不同所以只贴一份了，改下路径就行了，并且测试和生产是不需要控制台输出的，不然catalina.out文件就要爆炸了！</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;

&lt;!-- 从高到地低 OFF 、 FATAL 、 ERROR 、 WARN 、 INFO 、 DEBUG 、 TRACE 、 ALL --&gt;
&lt;!-- 日志输出规则 根据当前ROOT 级别，日志输出时，级别高于root默认的级别时 会输出 --&gt;
&lt;!-- 以下 每个配置的 filter 是过滤掉输出文件里面，会出现高级别文件，依然出现低级别的日志信息，通过filter 过滤只记录本级别的日志 --&gt;
&lt;!-- 属性描述 scan：性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 
	debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;
&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;
    &lt;contextName&gt;d1money-web-ys-ems&lt;/contextName&gt;
    &lt;!-- 定义日志文件 输入位置 --&gt;
    &lt;property name=&quot;log_dir&quot; value=&quot;/soft/apache-tomcat-8.5.30-ems/logs&quot;/&gt;
    &lt;!-- 日志最大的历史 30天 --&gt;
    &lt;property name=&quot;maxHistory&quot; value=&quot;30&quot;/&gt;
    &lt;property name=&quot;maxFileSize&quot; value=&quot;10MB&quot;/&gt;
    &lt;!-- ERROR级别日志 --&gt;
    &lt;!-- 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 RollingFileAppender --&gt;
    &lt;appender name=&quot;ERROR&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录WARN级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;ERROR&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;!-- 最常用的滚动策略，它根据时间来制定滚动策略.既负责滚动也负责出发滚动 --&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;

            &lt;!--日志输出位置 可相对、和绝对路径 --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_error.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件假设设置每个月滚动，且&lt;maxHistory&gt;是6， 则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;
            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;

        &lt;/rollingPolicy&gt;
        &lt;!-- 按照固定窗口模式生成日志文件，当文件大于20MB时，生成新的日志文件。窗口大小是1到3，当保存了3个归档文件后，将覆盖最早的日志。--&gt;
        &lt;!--&lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.FixedWindowRollingPolicy&quot;&gt;
            &lt;fileNamePattern&gt;${log_dir}/%d{yyyy-MM-dd}/.log.zip&lt;/fileNamePattern&gt;
            &lt;minIndex&gt;1&lt;/minIndex&gt;
            &lt;maxIndex&gt;3&lt;/maxIndex&gt;
        &lt;/rollingPolicy&gt;--&gt;
        &lt;!-- 查看当前活动文件的大小，如果超过指定大小会告知RollingFileAppender 触发当前活动文件滚动--&gt;
        &lt;!--&lt;triggeringPolicy
                class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt;
            &lt;maxFileSize&gt;5MB&lt;/maxFileSize&gt;
        &lt;/triggeringPolicy&gt;--&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!-- WARN级别日志 appender --&gt;
    &lt;appender name=&quot;WARN&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录WARN级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;WARN&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天回滚 daily --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_warn.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 日志最大的历史 30天 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;
            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;
        &lt;/rollingPolicy&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!-- INFO级别日志 appender --&gt;
    &lt;appender name=&quot;INFO&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录INFO级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;INFO&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天回滚 daily --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_info.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 日志最大的历史 30天 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;
            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;
        &lt;/rollingPolicy&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!-- DEBUG级别日志 appender --&gt;
    &lt;appender name=&quot;DEBUG&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录DEBUG级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;DEBUG&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天回滚 daily --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_debug.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 日志最大的历史 30天 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;
            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;
        &lt;/rollingPolicy&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!-- TRACE级别日志 appender --&gt;
    &lt;appender name=&quot;TRACE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;!-- 过滤器，只记录ERROR级别的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;TRACE&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天回滚 daily --&gt;
            &lt;fileNamePattern&gt;
                ${log_dir}/app_trace.%d{yyyy-MM-dd}.%i.log
            &lt;/fileNamePattern&gt;
            &lt;!-- 日志最大的历史 30天 --&gt;
            &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt;

            &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt;
                &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt;
            &lt;/timeBasedFileNamingAndTriggeringPolicy&gt;
        &lt;/rollingPolicy&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;logger name=&quot;java.sql.PreparedStatement&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;java.sql.Connection&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;java.sql.Statement&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.common.jdbc.SimpleDataSource&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.common.jdbc.ScriptRunner&quot; level=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate&quot; value=&quot;DEBUG&quot;/&gt;
    &lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;TRACE&quot;/&gt;

    &lt;!-- root级别 DEBUG --&gt;
    &lt;root level=&quot;debug&quot;&gt;
        &lt;!-- 文件输出 --&gt;
        &lt;appender-ref ref=&quot;ERROR&quot;/&gt;
        &lt;appender-ref ref=&quot;INFO&quot;/&gt;
        &lt;appender-ref ref=&quot;WARN&quot;/&gt;
        &lt;appender-ref ref=&quot;DEBUG&quot;/&gt;
        &lt;appender-ref ref=&quot;TRACE&quot;/&gt;
    &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>
<p>最后达到的效果是按大小日期生成日志文件，超过设定大小就会重新生成新文件，由0开始累积。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logback-自定义变量"><a class="header" href="#logback-自定义变量">LOGBACK 自定义变量</a></h1>
<p>当使用logback来记录Web应用的日志时，我们通过在logback.xml中配置appender来指定日志输出格式及输出文件路径，这在一台主机或一个文件系统上部署单个实例没有问题，但是如果部署多个实例（比如通过容器的方式），多个实例同时往同一文件写日志可能就会引起问题。这时可以将每个实例的日志文件加以区分，如IP或UUID，或两者结合的形式。这其实就涉及如何在logback.xml中自定义动态属性的问题。</p>
<p>可以有4种方式来实现logback.xml中获取自定义变量值：</p>
<ol>
<li>通过设置环境变量或传递系统属性（比如在程序启动时通过-D传递）的方式，两者是可以直接在logback.xml中通过 ${变量名} 获取的。</li>
<li>自定义logback.xml的加载时机，在其加载前将需要设置的属性注入到logback的context中，这种方式相对复杂，本文不讨论。</li>
<li>通过实现PropertyDefiner接口来提供属性值设置。</li>
<li>通过实现LoggerContextListener接口来设置属性值。</li>
</ol>
<p>第一种方式简单，但不能通过程序生成属性值，第二种方式稍显复杂，本文主要介绍后两种方式。</p>
<h2 id="propertydefiner方式"><a class="header" href="#propertydefiner方式">PropertyDefiner方式</a></h2>
<p>首先定义一个类，实现PropertyDefiner接口，可以通过继承PropertyDefinerBase会更方便</p>
<pre><code>import ch.qos.logback.core.PropertyDefinerBase;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.UUID;
/***
 * 将本地IP拼接到日志文件名中，以区分不同实例，避免存储到同一位置时的覆盖冲突问题
 * @Author ronwxy
 * @Date 2019/8/20 16:17   
 */
public class IPLogDefiner extends PropertyDefinerBase {

    private static final Logger LOG = LoggerFactory.getLogger(IPLogDefiner.class);

    private String getUniqName() {
        String localIp = null;
        try {
            localIp = InetAddress.getLocalHost().getHostAddress();
        } catch (UnknownHostException e) {
            LOG.error(&quot;fail to get ip...&quot;, e);
        }
        String uniqName = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;);
        if (localIp != null) {
            uniqName = localIp + &quot;-&quot; + uniqName;
        }
        return uniqName;
    }


    @Override
    public String getPropertyValue() {
        return getUniqName();
    }
}
</code></pre>
<p>然后在logback.xml中，添加 <define> 配置，指定属性名（本例中为localIP）及获取属性值的实现类，这样就可以在配置中通过 ${localIP}来引用该属性值了。在实现方法 getPropertyValue 中返回你需要生成的值，本例中是返回 本地IP-UUID 的形式。</p>
<pre><code>&lt;configuration&gt;
    &lt;define name=&quot;localIP&quot; class=&quot;cn.jboost.common.IPLogDefiner&quot;/&gt;
    &lt;appender name=&quot;interfaceLogFile&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;encoding&gt;UTF-8&lt;/encoding&gt;
        &lt;File&gt;D:\\logs\\elk\\interface-${localIP}.log&lt;/File&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;
            &lt;level&gt;INFO&lt;/level&gt;
    # 省略了其它配置
</code></pre>
<h2 id="loggercontextlistener方式"><a class="header" href="#loggercontextlistener方式">LoggerContextListener方式</a></h2>
<p>定义一个实现LoggerContextListener接口的类，在start方法中，将需要设置的属性设置到logback的Context中，</p>
<pre><code>import ch.qos.logback.classic.Level;
import ch.qos.logback.classic.Logger;
import ch.qos.logback.classic.LoggerContext;
import ch.qos.logback.classic.spi.LoggerContextListener;
import ch.qos.logback.core.Context;
import ch.qos.logback.core.spi.ContextAwareBase;
import ch.qos.logback.core.spi.LifeCycle;

import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.UUID;

/***
 * 第二种实现方式
 * @Author ronwxy
 * @Date 2019/8/20 18:45   
 */
public class LoggerStartupListener extends ContextAwareBase 
    implements LoggerContextListener, LifeCycle {

    private boolean started = false;

    @Override
    public void start() {
        if (started) {
            return;
        }
        Context context = getContext();
        context.putProperty(&quot;localIP&quot;, getUniqName());
        started = true;
    }

    private String getUniqName() {
        String localIp = null;
        try {
            localIp = InetAddress.getLocalHost().getHostAddress();
        } catch (UnknownHostException e) {
            //LOG.error(&quot;fail to get ip...&quot;, e);
        }
        String uniqName = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;);
        if (localIp != null) {
            uniqName = localIp + &quot;-&quot; + uniqName;
        }
        return uniqName;
    }
//省略了其它函数
</code></pre>
<p>然后在logback.xml中，配置如上监听器类，这样就可以通过 ${localIP} 获取到上面 context.putProperty(&quot;localIP&quot;, getUniqName()); 设置的值了。</p>
<pre><code>&lt;configuration&gt;

    &lt;!--&lt;define name=&quot;localIP&quot; class=&quot;com.cnbot.common.IPLogDefiner&quot;/&gt;--&gt;
    &lt;contextListener class=&quot;cn.jboost.common.LoggerStartupListener&quot;/&gt;
    &lt;define name=&quot;localIP&quot; class=&quot;com.cnbot.common.IPLogDefiner&quot;/&gt;
    &lt;appender name=&quot;interfaceLogFile&quot;
              class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;encoding&gt;UTF-8&lt;/encoding&gt;
        &lt;File&gt;D:\\logs\\elk\\interface-${localIP}.log&lt;/File&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;
            &lt;level&gt;INFO&lt;/level&gt;
        &lt;/filter&gt;
# 省略了其它配置
</code></pre>
<p>这种方式能设置任意个数的属性值，比前一种方式灵活。</p>
<h2 id="总结-3"><a class="header" href="#总结-3">总结</a></h2>
<p>在logback.xml中获取自定义属性值，主要是需要在加载前将对应的属性值进行设置，这样加载时才能有效获取。本文虽是自定义日志文件名称，但不局限于此，所有需要动态获取的变量都可以按这种方式实现。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="java-command"><a class="header" href="#java-command">java command</a></h1>
<h2 id="java"><a class="header" href="#java">java</a></h2>
<h3 id="java--jar"><a class="header" href="#java--jar">java -jar</a></h3>
<pre><code>java -Dloader.path=lib -jar app.jar
</code></pre>
<h3 id="java--server--java--client"><a class="header" href="#java--server--java--client">java -server / java -client</a></h3>
<pre><code>java -server -jar app.jar
</code></pre>
<h3 id="java--cp"><a class="header" href="#java--cp">java -cp</a></h3>
<pre><code>java -cp /path/config:/path/app.jar com.xxx.App
</code></pre>
<h3 id="java-params"><a class="header" href="#java-params">java params</a></h3>
<pre><code>java $JAVA_OPTS -Dfile.encoding=UTF-8 -Duser.timezone=Asia/Shanghai -jar app.jar
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="jdk"><a class="header" href="#jdk">jdk</a></h1>
<h2 id="build-jdk-debian"><a class="header" href="#build-jdk-debian">build jdk (debian)</a></h2>
<pre><code>FROM debian:10.0
COPY jdk-17 /usr/local/jdk
COPY apache-maven /usr/local/maven
COPY gradle-8.0 /usr/local/gradle
COPY gradle-8.0-bin.zip /root/.gradle/wrapper/dists/gradle-8.0-bin.zip

RUN apt update -y \
&amp;&amp; apt install -y tzdata less curl wget telnet vim zip unzip git \
&amp;&amp; \cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
&amp;&amp; apt autoremove \
&amp;&amp; apt autoclean \
&amp;&amp; apt clean

ENV JAVA_HOME=/usr/local/jdk
ENV CLASSPATH=${JAVA_HOME}/lib
ENV MAVEN_HOME=/usr/local/maven
ENV GRADLE_HOME=/usr/local/gradle
ENV GRADLE_USER_HOME=/root/.gradle
ENV PATH=${PATH}:${JAVA_HOME}/bin:${MAVEN_HOME}/bin:${GRADLE_HOME}/bin
</code></pre>
<h2 id="build-jdk-oraclelinux"><a class="header" href="#build-jdk-oraclelinux">build jdk (oraclelinux)</a></h2>
<pre><code>FROM oraclelinux:8.0
COPY jdk-17 /usr/local/jdk
COPY apache-maven /usr/local/maven
COPY gradle-8.0 /usr/local/gradle
COPY gradle-8.0-bin.zip /root/.gradle/wrapper/dists/gradle-8.0-bin.zip

RUN yum makecache -y \
&amp;&amp; yum install -y tzdata less curl wget telnet vim zip unzip git \
&amp;&amp; \cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
&amp;&amp; yum clean all

ENV JAVA_HOME=/usr/local/jdk
ENV CLASSPATH=${JAVA_HOME}/lib
ENV MAVEN_HOME=/usr/local/maven
ENV GRADLE_HOME=/usr/local/gradle
ENV GRADLE_USER_HOME=/root/.gradle
ENV PATH=${PATH}:${JAVA_HOME}/bin:${MAVEN_HOME}/bin:${GRADLE_HOME}/bin
</code></pre>
<h2 id="build-jdk-myself"><a class="header" href="#build-jdk-myself">build jdk myself</a></h2>
<pre><code>FROM irepoing/debian:base
COPY jdk-17 /usr/local/jdk
COPY apache-maven /usr/local/maven
COPY gradle-8.0 /usr/local/gradle
COPY gradle-8.0-bin.zip /root/.gradle/wrapper/dists/gradle-8.0-bin.zip

ENV JAVA_HOME=/usr/local/jdk
ENV CLASSPATH=${JAVA_HOME}/lib
ENV MAVEN_HOME=/usr/local/maven
ENV GRADLE_HOME=/usr/local/gradle
ENV GRADLE_USER_HOME=/root/.gradle
ENV PATH=${PATH}:${JAVA_HOME}/bin:${MAVEN_HOME}/bin:${GRADLE_HOME}/bin
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="base-image-1"><a class="header" href="#base-image-1">base image</a></h1>
<h2 id="debian-10"><a class="header" href="#debian-10">debian 10</a></h2>
<pre><code>FROM scratch

ADD debian-rootfs.tar.xz /

CMD [&quot;bash&quot;]
</code></pre>
<h2 id="debian-base"><a class="header" href="#debian-base">debian base</a></h2>
<pre><code>FROM irepoing/debian:10

RUN apt update -y &amp;&amp; apt install -y procps less curl wget telnet vim zip unzip git net-tools iputils-ping lsof tcpdump strace traceroute \
    &amp;&amp; apt install -y tzdata &amp;&amp; \cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;&amp; apt autoremove &amp;&amp; apt autoclean &amp;&amp; apt clean

CMD [&quot;bash&quot;]
</code></pre>
<h2 id="ubuntu-base"><a class="header" href="#ubuntu-base">ubuntu base</a></h2>
<pre><code>FROM irepoing/ubuntu:20

ENV DEBIAN_FRONTEND=noninteractive

RUN apt update -y &amp;&amp; apt install -y procps less curl wget telnet vim zip unzip git net-tools iputils-ping lsof tcpdump strace traceroute \
    &amp;&amp; apt install -y tzdata &amp;&amp; \cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;&amp; apt autoremove &amp;&amp; apt autoclean &amp;&amp; apt clean

CMD [&quot;bash&quot;]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="alpine-2"><a class="header" href="#alpine-2">alpine</a></h1>
<h2 id="cmd-1"><a class="header" href="#cmd-1">cmd</a></h2>
<h3 id="source"><a class="header" href="#source">source</a></h3>
<pre><code>echo http://mirrors.aliyun.com/alpine/v3.10/main &gt; /etc/apk/repositories
echo http://mirrors.aliyun.com/alpine/v3.10/community &gt;&gt; /etc/apk/repositories
</code></pre>
<h3 id="update"><a class="header" href="#update">update</a></h3>
<pre><code>apk update
apk upgrade
</code></pre>
<h3 id="info"><a class="header" href="#info">info</a></h3>
<pre><code>apk info xxx
apk info -a xxx
apk info --who-owns /bin/xxx
</code></pre>
<h3 id="add-xxx"><a class="header" href="#add-xxx">add xxx</a></h3>
<pre><code>apk add xxx
apk add xxx=version
apk add 'xxx&lt;version'
apk add 'xxx&gt;version'
apk add --upgrade xxx
apk add --no-cache xxx
apk add --update-cache xxx
apk add --repository http://mirrors.aliyun.com/alpine/v3.10/main --allow-untrusted xxx
</code></pre>
<h3 id="del-xxx"><a class="header" href="#del-xxx">del xxx</a></h3>
<pre><code>apk del xxx \
    &amp;&amp; rm -rf /var/cache/apk/* \
    &amp;&amp; rm -rf /root/.cache \
    &amp;&amp; rm -rf /tmp/*
</code></pre>
<h3 id="search-xxx"><a class="header" href="#search-xxx">search xxx</a></h3>
<pre><code>apk search xxx
apk search -v xxx
</code></pre>
<h2 id="service-2"><a class="header" href="#service-2">service</a></h2>
<h3 id="install-rc-service"><a class="header" href="#install-rc-service">install rc-service</a></h3>
<pre><code>apk add --no-cache openrc
</code></pre>
<h3 id="list-service"><a class="header" href="#list-service">list service</a></h3>
<pre><code>rc-service --list
</code></pre>
<h3 id="manage-xxx-service"><a class="header" href="#manage-xxx-service">manage xxx service</a></h3>
<pre><code>rc-service xxx start/stop/restart

#or
/etc/init.d/xxx start/stop/restart
</code></pre>
<h3 id="set-boot-xxx"><a class="header" href="#set-boot-xxx">set boot xxx</a></h3>
<pre><code>rc-update add xxx
</code></pre>
<h3 id="set-service-etcinitdxxx"><a class="header" href="#set-service-etcinitdxxx">set service (/etc/init.d/xxx)</a></h3>
<pre><code>#!/sbin/openrc-run
 
name=&quot;actc&quot;
command=&quot;/path/to/${name}&quot;
#command_background=&quot;yes&quot;
 
depend() {
	after sshd
}
</code></pre>
<h2 id="lib"><a class="header" href="#lib">lib</a></h2>
<h3 id="musl-compatible-glibc"><a class="header" href="#musl-compatible-glibc">musl compatible glibc</a></h3>
<pre><code>apk add --no-cache libc6-compat

#or amd
mkdir /lib64
ln -s /lib/libc.musl-x86_64.so.1 /lib64/ld-linux-x86-64.so.2

#or arm
ln -s /lib/libc.musl-aarch64.so.1 /lib/ld-linux-aarch64.so.1
</code></pre>
<h2 id="docker"><a class="header" href="#docker">docker</a></h2>
<h3 id="use-shanghai-timezone"><a class="header" href="#use-shanghai-timezone">use shanghai timezone</a></h3>
<pre><code>COPY localtime /etc/localtime
</code></pre>
<h3 id="golang-1"><a class="header" href="#golang-1">golang</a></h3>
<pre><code>FROM scratch
ADD arm.tar.gz /
ADD go.xxx.tar.gz /usr/local
ENV PATH $PATH:/usr/local/go/bin
CMD [&quot;/bin/sh&quot;]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="alpine-3"><a class="header" href="#alpine-3">alpine</a></h1>
<h2 id="cmd-2"><a class="header" href="#cmd-2">cmd</a></h2>
<h3 id="source-1"><a class="header" href="#source-1">source</a></h3>
<pre><code>echo http://mirrors.aliyun.com/alpine/v3.10/main &gt; /etc/apk/repositories
echo http://mirrors.aliyun.com/alpine/v3.10/community &gt;&gt; /etc/apk/repositories
</code></pre>
<h3 id="update-1"><a class="header" href="#update-1">update</a></h3>
<pre><code>apk update
apk upgrade
</code></pre>
<h3 id="info-1"><a class="header" href="#info-1">info</a></h3>
<pre><code>apk info xxx
apk info -a xxx
apk info --who-owns /bin/xxx
</code></pre>
<h3 id="add-xxx-1"><a class="header" href="#add-xxx-1">add xxx</a></h3>
<pre><code>apk add xxx
apk add xxx=version
apk add 'xxx&lt;version'
apk add 'xxx&gt;version'
apk add --upgrade xxx
apk add --no-cache xxx
apk add --update-cache xxx
apk add --repository http://mirrors.aliyun.com/alpine/v3.10/main --allow-untrusted xxx
</code></pre>
<h3 id="del-xxx-1"><a class="header" href="#del-xxx-1">del xxx</a></h3>
<pre><code>apk del xxx \
    &amp;&amp; rm -rf /var/cache/apk/* \
    &amp;&amp; rm -rf /root/.cache \
    &amp;&amp; rm -rf /tmp/*
</code></pre>
<h3 id="search-xxx-1"><a class="header" href="#search-xxx-1">search xxx</a></h3>
<pre><code>apk search xxx
apk search -v xxx
</code></pre>
<h2 id="service-3"><a class="header" href="#service-3">service</a></h2>
<h3 id="install-rc-service-1"><a class="header" href="#install-rc-service-1">install rc-service</a></h3>
<pre><code>apk add --no-cache openrc
</code></pre>
<h3 id="list-service-1"><a class="header" href="#list-service-1">list service</a></h3>
<pre><code>rc-service --list
</code></pre>
<h3 id="manage-xxx-service-1"><a class="header" href="#manage-xxx-service-1">manage xxx service</a></h3>
<pre><code>rc-service xxx start/stop/restart

#or
/etc/init.d/xxx start/stop/restart
</code></pre>
<h3 id="set-boot-xxx-1"><a class="header" href="#set-boot-xxx-1">set boot xxx</a></h3>
<pre><code>rc-update add xxx
</code></pre>
<h3 id="set-service-etcinitdxxx-1"><a class="header" href="#set-service-etcinitdxxx-1">set service (/etc/init.d/xxx)</a></h3>
<pre><code>#!/sbin/openrc-run
 
name=&quot;actc&quot;
command=&quot;/path/to/${name}&quot;
#command_background=&quot;yes&quot;
 
depend() {
	after sshd
}
</code></pre>
<h2 id="lib-1"><a class="header" href="#lib-1">lib</a></h2>
<h3 id="musl-compatible-glibc-1"><a class="header" href="#musl-compatible-glibc-1">musl compatible glibc</a></h3>
<pre><code>apk add --no-cache libc6-compat

#or amd
mkdir /lib64
ln -s /lib/libc.musl-x86_64.so.1 /lib64/ld-linux-x86-64.so.2

#or arm
ln -s /lib/libc.musl-aarch64.so.1 /lib/ld-linux-aarch64.so.1
</code></pre>
<h2 id="docker-1"><a class="header" href="#docker-1">docker</a></h2>
<h3 id="use-shanghai-timezone-1"><a class="header" href="#use-shanghai-timezone-1">use shanghai timezone</a></h3>
<pre><code>COPY localtime /etc/localtime
</code></pre>
<h3 id="golang-2"><a class="header" href="#golang-2">golang</a></h3>
<pre><code>FROM scratch
ADD arm.tar.gz /
ADD go.xxx.tar.gz /usr/local
ENV PATH $PATH:/usr/local/go/bin
CMD [&quot;/bin/sh&quot;]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="alpine-4"><a class="header" href="#alpine-4">alpine</a></h1>
<h2 id="login-docker"><a class="header" href="#login-docker">login docker</a></h2>
<pre><code>docker login docker.io
</code></pre>
<h2 id="build-docker"><a class="header" href="#build-docker">build docker</a></h2>
<pre><code>FROM scratch
ADD rootfs.tar.gz /
CMD [&quot;/bin/sh&quot;]
</code></pre>
<h3 id="change-source"><a class="header" href="#change-source">change source</a></h3>
<pre><code>FROM alpine:3.10
RUN echo http://mirrors.aliyun.com/alpine/v3.10/main &gt; /etc/apk/repositories \
    &amp;&amp; echo http://mirrors.aliyun.com/alpine/v3.10/community &gt;&gt; /etc/apk/repositories
</code></pre>
<h3 id="change-timezone"><a class="header" href="#change-timezone">change timezone</a></h3>
<pre><code>FROM alpine:3.10
RUN apk add --no-cache tzdata \
    &amp;&amp; \cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;&amp; apk del tzdata
</code></pre>
<pre><code>FROM debian:10.0
RUN apt update \
    &amp;&amp; apt install -y tzdata \
    &amp;&amp; \cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;&amp; apt autoremove \
    &amp;&amp; apt autoclean \
    &amp;&amp; apt clean
</code></pre>
<h3 id="build-golang-env"><a class="header" href="#build-golang-env">build golang env</a></h3>
<pre><code>FROM alpine:3.10
RUN apk add --no-cache libc6-compat ca-certificates \
    &amp;&amp; echo &quot;hosts: files dns&quot; &gt; /etc/nsswitch.conf
ADD go.xxx.tar.gz /usr/local
ENV PATH $PATH:/usr/local/go/bin
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tar"><a class="header" href="#tar">tar</a></h1>
<h2 id="tar-compress"><a class="header" href="#tar-compress">tar compress</a></h2>
<pre><code>tar -czvf xxx.tar.gz src
tar -czvf xxx.tar.gz src -C dir
</code></pre>
<h2 id="tar-extract"><a class="header" href="#tar-extract">tar extract</a></h2>
<pre><code>tar -xzvf xxx.tar.gz
tar -xzvf xxx.tar.gz -C dir
tar -xzvf xxx.tar.gz -C dir --strip-components N  // N=1,2,3...
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tar-1"><a class="header" href="#tar-1">tar</a></h1>
<h2 id="tar-compress-1"><a class="header" href="#tar-compress-1">tar compress</a></h2>
<pre><code>tar -czvf xxx.tar.gz src
tar -czvf xxx.tar.gz src -C dir
</code></pre>
<h2 id="tar-extract-1"><a class="header" href="#tar-extract-1">tar extract</a></h2>
<pre><code>tar -xzvf xxx.tar.gz
tar -xzvf xxx.tar.gz -C dir
tar -xzvf xxx.tar.gz -C dir --strip-components N  // N=1,2,3...
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="base-image-2"><a class="header" href="#base-image-2">base image</a></h1>
<h2 id="debian-10-1"><a class="header" href="#debian-10-1">debian 10</a></h2>
<pre><code>FROM scratch

ADD debian-rootfs.tar.xz /

CMD [&quot;bash&quot;]
</code></pre>
<h2 id="debian-base-1"><a class="header" href="#debian-base-1">debian base</a></h2>
<pre><code>FROM irepoing/debian:10

RUN apt update -y &amp;&amp; apt install -y procps less curl wget telnet vim zip unzip git net-tools iputils-ping lsof tcpdump strace traceroute \
    &amp;&amp; apt install -y tzdata &amp;&amp; \cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;&amp; apt autoremove &amp;&amp; apt autoclean &amp;&amp; apt clean

CMD [&quot;bash&quot;]
</code></pre>
<h2 id="ubuntu-base-1"><a class="header" href="#ubuntu-base-1">ubuntu base</a></h2>
<pre><code>FROM irepoing/ubuntu:20

ENV DEBIAN_FRONTEND=noninteractive

RUN apt update -y &amp;&amp; apt install -y procps less curl wget telnet vim zip unzip git net-tools iputils-ping lsof tcpdump strace traceroute \
    &amp;&amp; apt install -y tzdata &amp;&amp; \cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    &amp;&amp; apt autoremove &amp;&amp; apt autoclean &amp;&amp; apt clean

CMD [&quot;bash&quot;]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="centos-1"><a class="header" href="#centos-1">centos</a></h1>
<h2 id="synchronize-cache-appstream"><a class="header" href="#synchronize-cache-appstream">Synchronize cache AppStream</a></h2>
<h3 id="centos-appstreamrepo"><a class="header" href="#centos-appstreamrepo">CentOS-AppStream.repo</a></h3>
<pre><code>[AppStream]
name=CentOS-$releasever - AppStream
baseurl=https://mirrors.aliyun.com/centos/8-stream/AppStream/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial
</code></pre>
<h3 id="centos-baserepo"><a class="header" href="#centos-baserepo">CentOS-Base.repo</a></h3>
<pre><code>[BaseOS]
name=CentOS-$releasever - Base
baseurl=https://mirrors.aliyun.com/centos/8-stream/BaseOS/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial
</code></pre>
<h3 id="centos-extrasrepo"><a class="header" href="#centos-extrasrepo">CentOS-Extras.repo</a></h3>
<pre><code>[extras]
name=CentOS-$releasever - Extras
baseurl=https://mirrors.aliyun.com/centos/8-stream/extras/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial
</code></pre>
<h3 id="centos-powertoolsrepo"><a class="header" href="#centos-powertoolsrepo">CentOS-PowerTools.repo</a></h3>
<pre><code>[PowerTools]
name=CentOS-$releasever - PowerTools
baseurl=https://mirrors.aliyun.com/centos/8-stream/PowerTools/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-centosofficial
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h3 id="linux-curl"><a class="header" href="#linux-curl">linux curl</a></h3>
<pre><code>Usage: curl [options...] &lt;url&gt;
Options: (H) means HTTP/HTTPS only, (F) means FTP only
     --anyauth       Pick &quot;any&quot; authentication method (H)
 -a, --append        Append to target file when uploading (F/SFTP)
     --basic         Use HTTP Basic Authentication (H)
     --cacert FILE   CA certificate to verify peer against (SSL)
     --capath DIR    CA directory to verify peer against (SSL)
 -E, --cert CERT[:PASSWD]  Client certificate file and password (SSL)
     --cert-status   Verify the status of the server certificate (SSL)
     --cert-type TYPE  Certificate file type (DER/PEM/ENG) (SSL)
     --ciphers LIST  SSL ciphers to use (SSL)
     --compressed    Request compressed response (using deflate or gzip)
 -K, --config FILE   Read config from FILE
     --connect-timeout SECONDS  Maximum time allowed for connection
     --connect-to HOST1:PORT1:HOST2:PORT2 Connect to host (network level)
 -C, --continue-at OFFSET  Resumed transfer OFFSET
 -b, --cookie STRING/FILE  Read cookies from STRING/FILE (H)
 -c, --cookie-jar FILE  Write cookies to FILE after operation (H)
     --create-dirs   Create necessary local directory hierarchy
     --crlf          Convert LF to CRLF in upload
     --crlfile FILE  Get a CRL list in PEM format from the given file
 -d, --data DATA     HTTP POST data (H)
     --data-raw DATA  HTTP POST data, '@' allowed (H)
     --data-ascii DATA  HTTP POST ASCII data (H)
     --data-binary DATA  HTTP POST binary data (H)
     --data-urlencode DATA  HTTP POST data url encoded (H)
     --delegation STRING  GSS-API delegation permission
     --digest        Use HTTP Digest Authentication (H)
     --disable-eprt  Inhibit using EPRT or LPRT (F)
     --disable-epsv  Inhibit using EPSV (F)
     --dns-servers   DNS server addrs to use: 1.1.1.1;2.2.2.2
     --dns-interface  Interface to use for DNS requests
     --dns-ipv4-addr  IPv4 address to use for DNS requests, dot notation
     --dns-ipv6-addr  IPv6 address to use for DNS requests, dot notation
 -D, --dump-header FILE  Write the received headers to FILE
     --egd-file FILE  EGD socket path for random data (SSL)
     --engine ENGINE  Crypto engine (use &quot;--engine list&quot; for list) (SSL)
     --expect100-timeout SECONDS How long to wait for 100-continue (H)
 -f, --fail          Fail silently (no output at all) on HTTP errors (H)
     --fail-early    Fail on first transfer error, do not continue
     --false-start   Enable TLS False Start.
 -F, --form CONTENT  Specify HTTP multipart POST data (H), (upload file use -F &quot;file=@path&quot;)
     --form-string STRING  Specify HTTP multipart POST data (H)
     --ftp-account DATA  Account data string (F)
     --ftp-alternative-to-user COMMAND  String to replace &quot;USER [name]&quot; (F)
     --ftp-create-dirs  Create the remote dirs if not present (F)
     --ftp-method [MULTICWD/NOCWD/SINGLECWD]  Control CWD usage (F)
     --ftp-pasv      Use PASV/EPSV instead of PORT (F)
 -P, --ftp-port ADR  Use PORT with given address instead of PASV (F)
     --ftp-skip-pasv-ip  Skip the IP address for PASV (F)
     --ftp-pret      Send PRET before PASV (for drftpd) (F)
     --ftp-ssl-ccc   Send CCC after authenticating (F)
     --ftp-ssl-ccc-mode ACTIVE/PASSIVE  Set CCC mode (F)
     --ftp-ssl-control  Require SSL/TLS for FTP login, clear for transfer (F)
 -G, --get           Send the -d data with a HTTP GET (H)
 -g, --globoff       Disable URL sequences and ranges using {} and []
 -H, --header LINE   Pass custom header LINE to server (H)
 -I, --head          Show document info only
 -h, --help          This help text
     --hostpubmd5 MD5  Hex-encoded MD5 string of the host public key. (SSH)
 -0, --http1.0       Use HTTP 1.0 (H)
     --http1.1       Use HTTP 1.1 (H)
     --http2         Use HTTP 2 (H)
     --http2-prior-knowledge  Use HTTP 2 without HTTP/1.1 Upgrade (H)
     --ignore-content-length  Ignore the HTTP Content-Length header
 -i, --include       Include protocol headers in the output (H/F)
 -k, --insecure      Allow connections to SSL sites without certs (H)
     --interface INTERFACE  Use network INTERFACE (or address)
 -4, --ipv4          Resolve name to IPv4 address
 -6, --ipv6          Resolve name to IPv6 address
 -j, --junk-session-cookies  Ignore session cookies read from file (H)
     --keepalive-time SECONDS  Wait SECONDS between keepalive probes
     --key KEY       Private key file name (SSL/SSH)
     --key-type TYPE  Private key file type (DER/PEM/ENG) (SSL)
     --krb LEVEL     Enable Kerberos with security LEVEL (F)
     --libcurl FILE  Dump libcurl equivalent code of this command line
     --limit-rate RATE  Limit transfer speed to RATE
 -l, --list-only     List only mode (F/POP3)
     --local-port RANGE  Force use of RANGE for local port numbers
 -L, --location      Follow redirects (H)
     --location-trusted  Like '--location', and send auth to other hosts (H)
     --login-options OPTIONS  Server login options (IMAP, POP3, SMTP)
 -M, --manual        Display the full manual
     --mail-from FROM  Mail from this address (SMTP)
     --mail-rcpt TO  Mail to this/these addresses (SMTP)
     --mail-auth AUTH  Originator address of the original email (SMTP)
     --max-filesize BYTES  Maximum file size to download (H/F)
     --max-redirs NUM  Maximum number of redirects allowed (H)
 -m, --max-time SECONDS  Maximum time allowed for the transfer
     --metalink      Process given URLs as metalink XML file
     --negotiate     Use HTTP Negotiate (SPNEGO) authentication (H)
 -n, --netrc         Must read .netrc for user name and password
     --netrc-optional  Use either .netrc or URL; overrides -n
     --netrc-file FILE  Specify FILE for netrc
 -:, --next          Allows the following URL to use a separate set of options
     --no-alpn       Disable the ALPN TLS extension (H)
 -N, --no-buffer     Disable buffering of the output stream
     --no-keepalive  Disable keepalive use on the connection
     --no-npn        Disable the NPN TLS extension (H)
     --no-sessionid  Disable SSL session-ID reusing (SSL)
     --noproxy       List of hosts which do not use proxy
     --ntlm          Use HTTP NTLM authentication (H)
     --ntlm-wb       Use HTTP NTLM authentication with winbind (H)
     --oauth2-bearer TOKEN  OAuth 2 Bearer Token (IMAP, POP3, SMTP)
 -o, --output FILE   Write to FILE instead of stdout
     --pass PASS     Pass phrase for the private key (SSL/SSH)
     --path-as-is    Do not squash .. sequences in URL path
     --pinnedpubkey FILE/HASHES Public key to verify peer against (SSL)
     --post301       Do not switch to GET after following a 301 redirect (H)
     --post302       Do not switch to GET after following a 302 redirect (H)
     --post303       Do not switch to GET after following a 303 redirect (H)
     --preproxy [PROTOCOL://]HOST[:PORT] Proxy before HTTP(S) proxy
 -#, --progress-bar  Display transfer progress as a progress bar
     --proto PROTOCOLS  Enable/disable PROTOCOLS
     --proto-default PROTOCOL  Use PROTOCOL for any URL missing a scheme
     --proto-redir PROTOCOLS   Enable/disable PROTOCOLS on redirect
 -x, --proxy [PROTOCOL://]HOST[:PORT]  Use proxy on given port
     --proxy-anyauth  Pick &quot;any&quot; proxy authentication method (H)
     --proxy-basic   Use Basic authentication on the proxy (H)
     --proxy-digest  Use Digest authentication on the proxy (H)
     --proxy-cacert FILE CA certificate to verify peer against for proxy (SSL)
     --proxy-capath DIR CA directory to verify peer against for proxy (SSL)
     --proxy-cert CERT[:PASSWD] Client certificate file and password for proxy (SSL)
     --proxy-cert-type TYPE Certificate file type (DER/PEM/ENG) for proxy (SSL)
     --proxy-ciphers LIST SSL ciphers to use for proxy (SSL)
     --proxy-crlfile FILE Get a CRL list in PEM format from the given file for proxy
     --proxy-insecure Allow connections to SSL sites without certs for proxy (H)
     --proxy-key KEY Private key file name for proxy (SSL)
     --proxy-key-type TYPE Private key file type for proxy (DER/PEM/ENG) (SSL)
     --proxy-negotiate  Use HTTP Negotiate (SPNEGO) authentication on the proxy (H)
     --proxy-ntlm    Use NTLM authentication on the proxy (H)
     --proxy-header LINE Pass custom header LINE to proxy (H)
     --proxy-pass PASS Pass phrase for the private key for proxy (SSL)
     --proxy-ssl-allow-beast Allow security flaw to improve interop for proxy (SSL)
     --proxy-tlsv1   Use TLSv1 for proxy (SSL)
     --proxy-tlsuser USER TLS username for proxy
     --proxy-tlspassword STRING TLS password for proxy
     --proxy-tlsauthtype STRING TLS authentication type for proxy (default SRP)
     --proxy-service-name NAME  SPNEGO proxy service name
     --service-name NAME  SPNEGO service name
 -U, --proxy-user USER[:PASSWORD]  Proxy user and password
     --proxy1.0 HOST[:PORT]  Use HTTP/1.0 proxy on given port
 -p, --proxytunnel   Operate through a HTTP proxy tunnel (using CONNECT)
     --pubkey KEY    Public key file name (SSH)
 -Q, --quote CMD     Send command(s) to server before transfer (F/SFTP)
     --random-file FILE  File for reading random data from (SSL)
 -r, --range RANGE   Retrieve only the bytes within RANGE
     --raw           Do HTTP &quot;raw&quot;; no transfer decoding (H)
 -e, --referer       Referer URL (H)
 -J, --remote-header-name  Use the header-provided filename (H)
 -O, --remote-name   Write output to a file named as the remote file
     --remote-name-all  Use the remote file name for all URLs
 -R, --remote-time   Set the remote file's time on the local output
 -X, --request COMMAND  Specify request command to use（GET, POST, DELETE...）
     --resolve HOST:PORT:ADDRESS  Force resolve of HOST:PORT to ADDRESS
     --retry NUM   Retry request NUM times if transient problems occur
     --retry-connrefused  Retry on connection refused (use with --retry)
     --retry-delay SECONDS  Wait SECONDS between retries
     --retry-max-time SECONDS  Retry only within this period
     --sasl-ir       Enable initial response in SASL authentication
 -S, --show-error    Show error. With -s, make curl show errors when they occur
 -s, --silent        Silent mode (don't output anything)
     --socks4 HOST[:PORT]  SOCKS4 proxy on given host + port
     --socks4a HOST[:PORT]  SOCKS4a proxy on given host + port
     --socks5 HOST[:PORT]  SOCKS5 proxy on given host + port
     --socks5-hostname HOST[:PORT]  SOCKS5 proxy, pass host name to proxy
     --socks5-gssapi-service NAME  SOCKS5 proxy service name for GSS-API
     --socks5-gssapi-nec  Compatibility with NEC SOCKS5 server
 -Y, --speed-limit RATE  Stop transfers below RATE for 'speed-time' secs
 -y, --speed-time SECONDS  Trigger 'speed-limit' abort after SECONDS (default: 30)
     --ssl           Try SSL/TLS (FTP, IMAP, POP3, SMTP)
     --ssl-reqd      Require SSL/TLS (FTP, IMAP, POP3, SMTP)
 -2, --sslv2         Use SSLv2 (SSL)
 -3, --sslv3         Use SSLv3 (SSL)
     --ssl-allow-beast  Allow security flaw to improve interop (SSL)
     --ssl-no-revoke    Disable cert revocation checks (WinSSL)
     --stderr FILE   Where to redirect stderr (use &quot;-&quot; for stdout)
     --suppress-connect-headers  Suppress proxy CONNECT response headers
     --tcp-nodelay   Use the TCP_NODELAY option
     --tcp-fastopen  Use TCP Fast Open
 -t, --telnet-option OPT=VAL  Set telnet option
     --tftp-blksize VALUE  Set TFTP BLKSIZE option (must be &gt;512)
     --tftp-no-options  Do not send TFTP options requests
 -z, --time-cond TIME   Transfer based on a time condition
 -1, --tlsv1         Use &gt;= TLSv1 (SSL)
     --tlsv1.0       Use TLSv1.0 (SSL)
     --tlsv1.1       Use TLSv1.1 (SSL)
     --tlsv1.2       Use TLSv1.2 (SSL)
     --tlsv1.3       Use TLSv1.3 (SSL)
     --tls-max VERSION  Use TLS up to VERSION (SSL)
     --trace FILE    Write a debug trace to FILE
     --trace-ascii FILE  Like --trace, but without hex output
     --trace-time    Add time stamps to trace/verbose output
     --tr-encoding   Request compressed transfer encoding (H)
 -T, --upload-file FILE  Transfer FILE to destination
     --url URL       URL to work with
 -B, --use-ascii     Use ASCII/text transfer
 -u, --user USER[:PASSWORD]  Server user and password
     --tlsuser USER  TLS username
     --tlspassword STRING  TLS password
     --tlsauthtype STRING  TLS authentication type (default: SRP)
     --unix-socket PATH    Connect through this Unix domain socket
     --abstract-unix-socket PATH Connect to an abstract Unix domain socket
 -A, --user-agent STRING  Send User-Agent STRING to server (H)
 -v, --verbose       Make the operation more talkative
 -V, --version       Show version number and quit
 -w, --write-out FORMAT  Use output FORMAT after completion
     --xattr         Store metadata in extended file attributes
 -q, --disable       Disable .curlrc (must be first parameter)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debian-1"><a class="header" href="#debian-1">debian</a></h1>
<h2 id="source-etcaptsourceslistdaliyunlist"><a class="header" href="#source-etcaptsourceslistdaliyunlist">source (/etc/apt/sources.list.d/aliyun.list)</a></h2>
<pre><code>deb http://mirrors.aliyun.com/debian buster main
deb http://mirrors.aliyun.com/debian buster-updates main
deb http://mirrors.aliyun.com/debian-security buster/updates main
</code></pre>
<h2 id="gcc-2"><a class="header" href="#gcc-2">gcc</a></h2>
<pre><code>apt install build-essential make cmake gcc g++ clang clang+ zlib1g
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lang"><a class="header" href="#lang">LANG</a></h1>
<h2 id="en"><a class="header" href="#en">EN</a></h2>
<p>LANG = en_US.UTF-8</p>
<h2 id="cn"><a class="header" href="#cn">CN</a></h2>
<p>LANG = zh_CN.UTF-8</p>
<h2 id="lc_all"><a class="header" href="#lc_all">LC_ALL</a></h2>
<p>LC_ALL = en_US.UTF-8</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="replace-sources"><a class="header" href="#replace-sources">replace sources</a></h1>
<h2 id="debian-replace-sourceslist"><a class="header" href="#debian-replace-sourceslist">debian replace sources.list</a></h2>
<h3 id="huawei"><a class="header" href="#huawei">huawei</a></h3>
<pre><code>sed -i 's/deb.debian.org/mirrors.huaweicloud.com/g' /etc/apt/sources.list
sed -i 's/security.debian.org/mirrors.huaweicloud.com/g' /etc/apt/sources.list
</code></pre>
<h3 id="aliyun"><a class="header" href="#aliyun">aliyun</a></h3>
<pre><code>sed -i 's/deb.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.list
sed -i 's/security.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.list
</code></pre>
<h3 id="tencent"><a class="header" href="#tencent">tencent</a></h3>
<pre><code>sed -i 's/deb.debian.org/mirrors.cloud.tencent.com/g' /etc/apt/sources.list
sed -i 's/security.debian.org/mirrors.cloud.tencent.com/g' /etc/apt/sources.list
</code></pre>
<h3 id="debian-buster-etcaptsourceslist"><a class="header" href="#debian-buster-etcaptsourceslist">debian buster (/etc/apt/sources.list)</a></h3>
<pre><code>deb http://mirrors.huaweicloud.com/debian buster main
deb http://mirrors.huaweicloud.com/debian buster-updates main
deb http://mirrors.huaweicloud.com/debian-security buster/updates main
</code></pre>
<h2 id="ubuntu-replace-sourceslist"><a class="header" href="#ubuntu-replace-sourceslist">ubuntu replace sources.list</a></h2>
<pre><code>sed -i 's/archive.ubuntu.com/mirrors.huaweicloud.com/g' /etc/apt/sources.list
sed -i 's/security.ubuntu.com/mirrors.huaweicloud.com/g' /etc/apt/sources.list
</code></pre>
<h3 id="ubuntu-focal-etcaptsourceslist"><a class="header" href="#ubuntu-focal-etcaptsourceslist">ubuntu focal (/etc/apt/sources.list)</a></h3>
<pre><code>deb http://mirrors.huaweicloud.com/ubuntu/ focal main restricted universe multiverse
deb http://mirrors.huaweicloud.com/ubuntu/ focal-security main restricted universe multiverse
deb http://mirrors.huaweicloud.com/ubuntu/ focal-updates main restricted universe multiverse
deb http://mirrors.huaweicloud.com/ubuntu/ focal-proposed main restricted universe multiverse
deb http://mirrors.huaweicloud.com/ubuntu/ focal-backports main restricted universe multiverse
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debian-10-buster-origin"><a class="header" href="#debian-10-buster-origin">Debian 10 (buster origin)</a></h1>
<pre><code>deb http://deb.debian.org/debian buster main
deb http://security.debian.org/debian-security buster/updates main
deb http://deb.debian.org/debian buster-updates main
</code></pre>
<h1 id="debian-10-buster-aliyun"><a class="header" href="#debian-10-buster-aliyun">Debian 10 (buster aliyun)</a></h1>
<pre><code>deb http://mirrors.aliyun.com/debian/ buster main non-free contrib
deb http://mirrors.aliyun.com/debian/ buster-updates main non-free contrib
deb http://mirrors.aliyun.com/debian/ buster-backports main non-free contrib
deb http://mirrors.aliyun.com/debian-security buster/updates main
deb-src http://mirrors.aliyun.com/debian-security buster/updates main
deb-src http://mirrors.aliyun.com/debian/ buster main non-free contrib
deb-src http://mirrors.aliyun.com/debian/ buster-updates main non-free contrib
deb-src http://mirrors.aliyun.com/debian/ buster-backports main non-free contrib
</code></pre>
<h1 id="ubuntu-2004-focal-aliyun"><a class="header" href="#ubuntu-2004-focal-aliyun">Ubuntu 20.04 (focal aliyun)</a></h1>
<pre><code>deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
# deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
# deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
# deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
# deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
# deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
</code></pre>
<h1 id="ubuntu-2004-focal-tuna"><a class="header" href="#ubuntu-2004-focal-tuna">Ubuntu 20.04 (focal tuna)</a></h1>
<pre><code>deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse
# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse
deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse
# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse
deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse
# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse
deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse
# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse
deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse
# deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse
</code></pre>
<h1 id="centos-7-origin"><a class="header" href="#centos-7-origin">Centos 7 (origin)</a></h1>
<pre><code># CentOS-Base.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the
# remarked out baseurl= line instead.
#
#

[base]
name=CentOS-$releasever - Base
mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os&amp;infra=$infra
#baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#released updates
[updates]
name=CentOS-$releasever - Updates
mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates&amp;infra=$infra
#baseurl=http://mirror.centos.org/centos/$releasever/updates/$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras
mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras&amp;infra=$infra
#baseurl=http://mirror.centos.org/centos/$releasever/extras/$basearch/
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus
mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplus&amp;infra=$infra
#baseurl=http://mirror.centos.org/centos/$releasever/centosplus/$basearch/
gpgcheck=1
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7
</code></pre>
<h1 id="centos-7-aliyun"><a class="header" href="#centos-7-aliyun">CentOS 7 (aliyun)</a></h1>
<pre><code># CentOS-Base.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the 
# remarked out baseurl= line instead.
#
#
 
[base]
name=CentOS-$releasever - Base - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
#released updates 
[updates]
name=CentOS-$releasever - Updates - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/updates/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/updates/$basearch/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/extras/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/extras/$basearch/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/centosplus/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/centosplus/$basearch/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
#contrib - packages by Centos Users
[contrib]
name=CentOS-$releasever - Contrib - mirrors.aliyun.com
failovermethod=priority
baseurl=http://mirrors.aliyun.com/centos/$releasever/contrib/$basearch/
        http://mirrors.aliyuncs.com/centos/$releasever/contrib/$basearch/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/contrib/$basearch/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
</code></pre>
<h1 id="centos-8-aliyun"><a class="header" href="#centos-8-aliyun">CentOS 8 (aliyun)</a></h1>
<pre><code># CentOS-Base.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the 
# remarked out baseurl= line instead.
#
#
 
[base]
name=CentOS-$releasever - Base - mirrors.aliyun.com
failovermethod=priority
baseurl=https://mirrors.aliyun.com/centos/$releasever/BaseOS/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/BaseOS/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/BaseOS/$basearch/os/
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras - mirrors.aliyun.com
failovermethod=priority
baseurl=https://mirrors.aliyun.com/centos/$releasever/extras/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/extras/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/extras/$basearch/os/
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus - mirrors.aliyun.com
failovermethod=priority
baseurl=https://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/centosplus/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/centosplus/$basearch/os/
gpgcheck=1
enabled=0
gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
 
[PowerTools]
name=CentOS-$releasever - PowerTools - mirrors.aliyun.com
failovermethod=priority
baseurl=https://mirrors.aliyun.com/centos/$releasever/PowerTools/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/PowerTools/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/PowerTools/$basearch/os/
gpgcheck=1
enabled=0
gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official


[AppStream]
name=CentOS-$releasever - AppStream - mirrors.aliyun.com
failovermethod=priority
baseurl=https://mirrors.aliyun.com/centos/$releasever/AppStream/$basearch/os/
        http://mirrors.aliyuncs.com/centos/$releasever/AppStream/$basearch/os/
        http://mirrors.cloud.aliyuncs.com/centos/$releasever/AppStream/$basearch/os/
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-Official
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ssh-1"><a class="header" href="#ssh-1">ssh</a></h1>
<h2 id="ssh-alias-vi-sshconfig"><a class="header" href="#ssh-alias-vi-sshconfig">ssh alias (vi ~/.ssh/config)</a></h2>
<pre><code>Host xxx
User root
HostName 10.1.1.10
</code></pre>
<h2 id="use-ssh-alias"><a class="header" href="#use-ssh-alias">use ssh alias</a></h2>
<pre><code>ssh xxx
scp one.txt xxx:/tmp/
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linux-allow-remote-login"><a class="header" href="#linux-allow-remote-login">Linux allow remote login</a></h1>
<h2 id="1check-service-ssh"><a class="header" href="#1check-service-ssh">1.check service ssh</a></h2>
<pre><code>service sshd status
# or
systemctl status sshd
</code></pre>
<h2 id="2install-ssh-service"><a class="header" href="#2install-ssh-service">2.install ssh service</a></h2>
<pre><code>apt install ssh
# or
yum install ssh-server ssh-clients
</code></pre>
<h2 id="3start-ssh-service"><a class="header" href="#3start-ssh-service">3.start ssh service</a></h2>
<pre><code>/etc/init.d/ssh start
# or
systemctl start sshd
</code></pre>
<h2 id="4edit-ssh-config"><a class="header" href="#4edit-ssh-config">4.edit ssh config</a></h2>
<pre><code>sudo vi /etc/ssh/sshd_config
# PermitRootLogin without-password
PermitRootLogin yes
</code></pre>
<h2 id="5restart-ssh-service"><a class="header" href="#5restart-ssh-service">5.restart ssh service</a></h2>
<pre><code>service ssh restart
# or
systemctl restart sshd
</code></pre>
<h2 id="6ssh-login"><a class="header" href="#6ssh-login">6.ssh login</a></h2>
<pre><code>ssh root@hostname
</code></pre>
<h2 id="7login-without-password"><a class="header" href="#7login-without-password">7.login without password</a></h2>
<pre><code>#local copy
ssh-keygen -t rsa
cat ~/.ssh/id_rsa.pub

#remote paste
vi ~/.ssh/authorized_keys
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ubuntu-1"><a class="header" href="#ubuntu-1">ubuntu</a></h1>
<h2 id="gcc-3"><a class="header" href="#gcc-3">gcc</a></h2>
<pre><code>apt install build-essential make cmake gcc g++ clang clang+ zlib1g
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="user--group"><a class="header" href="#user--group">user &amp; group</a></h1>
<h2 id="user-1"><a class="header" href="#user-1">user</a></h2>
<ul>
<li>users</li>
<li>useradd</li>
<li>userdel</li>
<li>usermod</li>
</ul>
<h2 id="group"><a class="header" href="#group">group</a></h2>
<ul>
<li>groups</li>
<li>groupadd</li>
<li>groupdel</li>
<li>groupmod</li>
<li>groupmems</li>
</ul>
<h2 id="example-3"><a class="header" href="#example-3">example</a></h2>
<blockquote>
<p>create user</p>
</blockquote>
<pre><code>sudo useradd -p password
</code></pre>
<blockquote>
<p>append group (sudo)</p>
</blockquote>
<pre><code>sudo usermod -aG sudo username
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="brew"><a class="header" href="#brew">brew</a></h1>
<h2 id="edit-source"><a class="header" href="#edit-source">edit source</a></h2>
<pre><code>cd $(brew --repo)
git remote -v
# origin	https://github.com/Homebrew/brew (fetch)
# origin	https://github.com/Homebrew/brew (push)
git remote set-url origin https://mirrors.aliyun.com/homebrew/brew.git
git remote -v
# origin	https://mirrors.aliyun.com/homebrew/brew.git (fetch)
# origin	https://mirrors.aliyun.com/homebrew/brew.git (push)
cd $(brew --repo)/Library/Taps/homebrew/homebrew-core
git remote  -v
# origin	https://github.com/Homebrew/homebrew-core (fetch)
# origin	https://github.com/Homebrew/homebrew-core (push)
git remote set-url origin https://mirrors.aliyun.com/homebrew/homebrew-core.git
git remote -v
# origin	https://mirrors.aliyun.com/homebrew/homebrew-core.git (fetch)
# origin	https://mirrors.aliyun.com/homebrew/homebrew-core.git (push)
brew update
# Already up-to-date.
</code></pre>
<h2 id="origin-install"><a class="header" href="#origin-install">origin install</a></h2>
<pre><code>/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot;
</code></pre>
<h2 id="change-source-1"><a class="header" href="#change-source-1">change source</a></h2>
<pre><code>cd &quot;$(brew --repo)&quot;
git remote set-url origin https://mirrors.ustc.edu.cn/brew.git
 
cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;
git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git
</code></pre>
<h2 id="restore-source"><a class="header" href="#restore-source">restore source</a></h2>
<pre><code>cd &quot;$(brew --repo)&quot;
git remote set-url origin https://github.com/Homebrew/brew.git
 
cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;
git remote set-url origin https://github.com/Homebrew/homebrew-core.git
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="brew-1"><a class="header" href="#brew-1">brew</a></h1>
<h2 id="edit-source-1"><a class="header" href="#edit-source-1">edit source</a></h2>
<pre><code>cd $(brew --repo)
git remote -v
# origin	https://github.com/Homebrew/brew (fetch)
# origin	https://github.com/Homebrew/brew (push)
git remote set-url origin https://mirrors.aliyun.com/homebrew/brew.git
git remote -v
# origin	https://mirrors.aliyun.com/homebrew/brew.git (fetch)
# origin	https://mirrors.aliyun.com/homebrew/brew.git (push)
cd $(brew --repo)/Library/Taps/homebrew/homebrew-core
git remote  -v
# origin	https://github.com/Homebrew/homebrew-core (fetch)
# origin	https://github.com/Homebrew/homebrew-core (push)
git remote set-url origin https://mirrors.aliyun.com/homebrew/homebrew-core.git
git remote -v
# origin	https://mirrors.aliyun.com/homebrew/homebrew-core.git (fetch)
# origin	https://mirrors.aliyun.com/homebrew/homebrew-core.git (push)
brew update
# Already up-to-date.
</code></pre>
<h2 id="origin-install-1"><a class="header" href="#origin-install-1">origin install</a></h2>
<pre><code>/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot;
</code></pre>
<h2 id="change-source-2"><a class="header" href="#change-source-2">change source</a></h2>
<pre><code>cd &quot;$(brew --repo)&quot;
git remote set-url origin https://mirrors.ustc.edu.cn/brew.git
 
cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;
git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git
</code></pre>
<h2 id="restore-source-1"><a class="header" href="#restore-source-1">restore source</a></h2>
<pre><code>cd &quot;$(brew --repo)&quot;
git remote set-url origin https://github.com/Homebrew/brew.git
 
cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;
git remote set-url origin https://github.com/Homebrew/homebrew-core.git
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="homebrew"><a class="header" href="#homebrew">homebrew</a></h1>
<h2 id="install-origin"><a class="header" href="#install-origin">install origin</a></h2>
<pre><code>/bin/bash -c &quot;$(curl -fsSL https://github.com/Homebrew/install/raw/master/install.sh)&quot;
</code></pre>
<h2 id="install-aliyun"><a class="header" href="#install-aliyun">install aliyun</a></h2>
<pre><code>git clone https://mirrors.aliyun.com/homebrew/install.git brew-install
/bin/bash brew-install/install.sh
rm -rf brew-install
</code></pre>
<h2 id="show-version"><a class="header" href="#show-version">show version</a></h2>
<pre><code>brew -v
</code></pre>
<h2 id="setup-aliyun-source"><a class="header" href="#setup-aliyun-source">setup aliyun source</a></h2>
<pre><code># temporary config

export HOMEBREW_INSTALL_FROM_API=1
export HOMEBREW_API_DOMAIN=&quot;https://mirrors.aliyun.com/homebrew-bottles/api&quot;
export HOMEBREW_BREW_GIT_REMOTE=&quot;https://mirrors.aliyun.com/homebrew/brew.git&quot;
export HOMEBREW_CORE_GIT_REMOTE=&quot;https://mirrors.aliyun.com/homebrew/homebrew-core.git&quot;
export HOMEBREW_BOTTLE_DOMAIN=&quot;https://mirrors.aliyun.com/homebrew/homebrew-bottles&quot;
brew update
</code></pre>
<pre><code># permanent config

# zsh user
echo 'export HOMEBREW_API_DOMAIN=&quot;https://mirrors.aliyun.com/homebrew-bottles/api&quot;' &gt;&gt; ~/.zshrc
echo 'export HOMEBREW_BREW_GIT_REMOTE=&quot;https://mirrors.aliyun.com/homebrew/brew.git&quot;' &gt;&gt; ~/.zshrc
echo 'export HOMEBREW_CORE_GIT_REMOTE=&quot;https://mirrors.aliyun.com/homebrew/homebrew-core.git&quot;' &gt;&gt; ~/.zshrc
echo 'export HOMEBREW_BOTTLE_DOMAIN=&quot;https://mirrors.aliyun.com/homebrew/homebrew-bottles&quot;' &gt;&gt; ~/.zshrc
source ~/.zshrc
brew update

# bash user
echo 'export HOMEBREW_API_DOMAIN=&quot;https://mirrors.aliyun.com/homebrew-bottles/api&quot;' &gt;&gt; ~/.bash_profile
echo 'export HOMEBREW_BREW_GIT_REMOTE=&quot;https://mirrors.aliyun.com/homebrew/brew.git&quot;' &gt;&gt; ~/.bash_profile
echo 'export HOMEBREW_CORE_GIT_REMOTE=&quot;https://mirrors.aliyun.com/homebrew/homebrew-core.git&quot;' &gt;&gt; ~/.bash_profile
echo 'export HOMEBREW_BOTTLE_DOMAIN=&quot;https://mirrors.aliyun.com/homebrew/homebrew-bottles&quot;' &gt;&gt; ~/.bash_profile
source ~/.bash_profile
brew update
</code></pre>
<h2 id="config-tap-repository-optional"><a class="header" href="#config-tap-repository-optional">config tap repository (optional)</a></h2>
<pre><code>brew tap -v --custom-remote --force-auto-update homebrew/core https://mirrors.aliyun.com/homebrew/homebrew-core.git
brew tap -v --custom-remote --force-auto-update homebrew/cask https://mirrors.aliyun.com/homebrew/homebrew-cask.git

# other taps
brew tap -v --custom-remote --force-auto-update homebrew/services https://mirrors.aliyun.com/homebrew/homebrew-services.git
brew tap -v --custom-remote --force-auto-update homebrew/cask-fonts https://mirrors.aliyun.com/homebrew/homebrew-cask-fonts.git
brew tap -v --custom-remote --force-auto-update homebrew/cask-versions https://mirrors.aliyun.com/homebrew/homebrew-cask-versions.git
brew tap -v --custom-remote --force-auto-update homebrew/command-not-found https://mirrors.aliyun.com/homebrew/homebrew-command-not-found.git
</code></pre>
<h2 id="restore-default-config"><a class="header" href="#restore-default-config">restore default config</a></h2>
<blockquote>
<p>edit ~/.zshrc or ~/.bash_profile env variable &quot;HOMEBREW&quot; if use permanent config</p>
</blockquote>
<pre><code>unset HOMEBREW_BREW_GIT_REMOTE
git -C &quot;$(brew --repo)&quot; remote set-url origin https://github.com/Homebrew/brew

unset HOMEBREW_API_DOMAIN
unset HOMEBREW_CORE_GIT_REMOTE
BREW_TAPS=&quot;$(BREW_TAPS=&quot;$(brew tap 2&gt;/dev/null)&quot;; echo -n &quot;${BREW_TAPS//$'\n'/:}&quot;)&quot;
for tap in core cask{,-fonts,-versions} command-not-found services; do
    if [[ &quot;:${BREW_TAPS}:&quot; == *&quot;:homebrew/${tap}:&quot;* ]]; then
        brew tap --custom-remote &quot;homebrew/${tap}&quot; &quot;https://github.com/Homebrew/homebrew-${tap}&quot;
    fi
done

brew update
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="homebrew-1"><a class="header" href="#homebrew-1">homebrew</a></h1>
<h2 id="set-env-1"><a class="header" href="#set-env-1">set env</a></h2>
<pre><code>export HOMEBREW_BREW_GIT_REMOTE=&quot;https://mirrors.ustc.edu.cn/brew.git&quot;
export HOMEBREW_CORE_GIT_REMOTE=&quot;https://mirrors.ustc.edu.cn/homebrew-core.git&quot;
export HOMEBREW_BOTTLE_DOMAIN=&quot;https://mirrors.ustc.edu.cn/homebrew-bottles&quot;
</code></pre>
<h2 id="install-brew"><a class="header" href="#install-brew">install brew</a></h2>
<pre><code>/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot;
</code></pre>
<h2 id="install-brew-cask"><a class="header" href="#install-brew-cask">install brew cask</a></h2>
<pre><code>brew tap --custom-remote --force-auto-update homebrew/cask https://mirrors.ustc.edu.cn/homebrew-cask.git
brew tap --custom-remote --force-auto-update homebrew/cask-versions https://mirrors.ustc.edu.cn/homebrew-cask-versions.git
</code></pre>
<h2 id="update-brew"><a class="header" href="#update-brew">update brew</a></h2>
<pre><code>brew update-reset
brew update
brew config
</code></pre>
<h2 id="config-env"><a class="header" href="#config-env">config env</a></h2>
<pre><code># echo sheel
echo $SHELL

# bash user
echo 'export HOMEBREW_BREW_GIT_REMOTE=&quot;https://mirrors.ustc.edu.cn/brew.git&quot;' &gt;&gt; ~/.bash_profile
echo 'export HOMEBREW_CORE_GIT_REMOTE=&quot;https://mirrors.ustc.edu.cn/homebrew-core.git&quot;' &gt;&gt; ~/.bash_profile
echo 'export HOMEBREW_BOTTLE_DOMAIN=&quot;https://mirrors.ustc.edu.cn/homebrew-bottles&quot;' &gt;&gt; ~/.bash_profile

# zsh user
echo 'export HOMEBREW_BREW_GIT_REMOTE=&quot;https://mirrors.ustc.edu.cn/brew.git&quot;' &gt;&gt; ~/.zshrc
echo 'export HOMEBREW_CORE_GIT_REMOTE=&quot;https://mirrors.ustc.edu.cn/homebrew-core.git&quot;' &gt;&gt; ~/.zshrc
echo 'export HOMEBREW_BOTTLE_DOMAIN=&quot;https://mirrors.ustc.edu.cn/homebrew-bottles&quot;' &gt;&gt; ~/.zshrc

# echo env
cat ~/.bash_profile
cat ~/.zshrc
</code></pre>
<h2 id="uninstall-brew"><a class="header" href="#uninstall-brew">uninstall brew</a></h2>
<pre><code>/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/uninstall.sh)&quot;
</code></pre>
<h2 id="brew-command"><a class="header" href="#brew-command">brew command</a></h2>
<pre><code># install xxx
brew install xxx

# uninstall xxx
brew uninstall xxx

# search xxx
brew search xxx

# upgrade xxx
brew upgrade xxx

# list install
brew list

# update
brew update

# cleanup
brew cleanup

# cleanup old version
brew cleanup $FORMULA

# show cleanup old version
brew cleanup -n
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mac-launchpad"><a class="header" href="#mac-launchpad">mac launchpad</a></h1>
<h2 id="change-icon-size"><a class="header" href="#change-icon-size">change icon size</a></h2>
<pre><code>defaults write com.apple.dock springboard-rows -int 6
defaults write com.apple.dock springboard-columns -int 9
</code></pre>
<h2 id="restart-dock"><a class="header" href="#restart-dock">restart dock</a></h2>
<pre><code>killall Dock
</code></pre>
<h2 id="reset-dock"><a class="header" href="#reset-dock">reset dock</a></h2>
<pre><code>defaults write com.apple.dock ResetLaunchPad -bool TRUE
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="net"><a class="header" href="#net">NET</a></h1>
<h2 id="tcp"><a class="header" href="#tcp">TCP</a></h2>
<p>TCP（传输控制协议），负责在不可靠的传输信道之上提供可靠的抽象层。
TCP的存在价值主要专注于可靠两个字，也就是它能够确保发送的所有字节流都能够完整的被接收到，而且到达客户端的顺序也是一样。但凡事都有两面性，如果精确性得到了保证的话，就会牺牲一定的速度和效率。
先来看TCP的连接和断开连接，也就是我们都熟悉的三次握手四次挥手：</p>
<h3 id="一三次握手"><a class="header" href="#一三次握手">一、三次握手</a></h3>
<p><img src="net/../static/img/net/tcp001.png" alt="" /></p>
<ol>
<li>首先客户端会生成一个随机序列号x，并发送一个SYN分组，其中可能还包括其他TCP标志和选项。</li>
<li>服务端收到分组以后给x+1，并生成一个随机序列号y，追加自己的标志和选项，然后返回给客户端。</li>
<li>客户端收到服务端消息以后给x和y都+1，然后发送一个ACK分组。</li>
</ol>
<p>经过这个三次握手以后客户端和服务端就可以互相传输数据了。这里客户端可以在发送ACK分组之后立即发送数据，服务端必须在接收到第三部的ACK分组以后才能传输数据。</p>
<p>那么接下来又有一个问题了，为什么是三次握手呢？为什么不是两次，或者四次五次握手呢？
TCP是一个双向通信协议，为了数据传输的可靠性，通信双方会维护一个序列号，以标识发出去的数据包里有哪些数据是被对方收到的。如果只有两次握手的话，服务端就无法确认他的序列号是否得到了确认，只有客户端的序列号得到了确认。而四次，五次握手的话则会造成资源的浪费。可以肯定的是，三次握手是在确保可靠性的基础上，性能上的最优解。</p>
<h3 id="二四次挥手"><a class="header" href="#二四次挥手">二、四次挥手</a></h3>
<p><img src="net/../static/img/net/tcp002.png" alt="" /></p>
<p>重点：TCP关闭连接的时候每个方向都必须要单独进行关闭。当一方发送一个FIN消息的时候，就意味申请终止这一个方向上的数据连接，当收到一个FIN就意味着这一方向上没有数据消息再传过来了，也就不会收到数据了。
TCP客户端服务端双方都可以发起close，这里我们以客户端发起close为图例，来看下过程：</p>
<ol>
<li>首先客户端发送一个FIN，这就意味着客户端不会再发送任何数据消息到服务端了，然后进入FIN-WAIT1状态。</li>
<li>服务端收到FIN消息以后呢，发送i 个ACK给客户端，确认序号为收到的的序号u+1，然后进入CLOSE_WAIT状态。</li>
<li>服务端发送一个FIN，这就意味着服务端不再发送任何数据消息到客户端，然后进入LAST_ACK状态。</li>
<li>客户端收到FIN消息以后，进入TIME_WAIT状态，然后发送一个ACK给服务端，确认序号为收到的序号w+1，然后进入TIME_WAIT状态。服务端收到ACK报文段以后就关闭连接了。。。客户端等待2MSL以后没有收到任何回复，就说明服务端已经正常关闭，然后自己关闭。</li>
</ol>
<p>那么为什么要四次挥手呢？？？
TCP的一端发出FIN报文段之后，仅仅表示这一端没有数据要发送给另一端了，但是他仍然能接受来自另一端的数据。所以如上面所示客户端先发送消息给服务端说我不发数据消息给你了，然后服务端发给客户端确认，然后服务端再发消息给客户端跟客户端说我也不发数据消息给你了，然后客户端回复确认，然后服务端关闭，之后客户端等待了以后也关闭。所以这就是需要四次挥手才能来关闭连接的原因。</p>
<p>在实际的网络传输过程中，很容易出现拥塞的现象，TCP对于拥塞控制主要有以下四个算法：</p>
<ol>
<li>慢启动</li>
<li>拥塞预防</li>
<li>拥塞发生时，快速重传</li>
<li>快速恢复</li>
</ol>
<h4 id="1-慢启动"><a class="header" href="#1-慢启动">1. 慢启动</a></h4>
<p>要理解这四个算法的话，首先先要理解拥塞窗口(cwnd)的概念：发送端对从客户端接受确认(ACK)之前可以发送数据的限制。
TCP的拥塞控制主要依赖于这个拥塞窗口来控制，首先三次握手的时候，客户端和服务端会通过ACK分组告知对方自己的接收窗口(rwnd)的大小，然后三次握手ACK消息成功传递以后双方就可以互相发消息了，但是如果在一开始连接刚建立就向网络中发送大量的数据包的话，就很容易导致网络中路由器的缓存空间耗尽，发声拥塞，所以即客户端与服务器之间最大可以传输(未经 ACK 确认的)数据量取 rwnd 和 cwnd 变量中的最小值。而这个cwnd的值会根据算法慢慢指数级增加，同时也设置了一个ssthresh门限值，如果cwnd达到这个值以后会让cwnd增长变得平滑，也就是慢启动。</p>
<h4 id="2-拥塞预防"><a class="header" href="#2-拥塞预防">2. 拥塞预防</a></h4>
<p>拥塞预防的原理就是加入ssthresh门限值来限制 cwnd的增长，当cwnd超过该值以后，慢启动过程结束，进入拥塞避免阶段。拥塞避免的主要思想是加法增大，也就是cwnd的值不再指数级往上升，开始加法增加。此时当窗口中所有的报文段都被确认时，cwnd的大小加1，cwnd的值就随着RTT开始线性增加，这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。</p>
<h4 id="3-快速重传"><a class="header" href="#3-快速重传">3. 快速重传</a></h4>
<p>TCP的每一个报文段都有一个定时器，叫做重传定时器，如果重传定时器超时并且没有得到数据确认的话，TCP就会对该报文段进行重传处理，这里TCP也就把网络定义为拥塞的状态，会进行如下操作：</p>
<pre><code>3.1. 把ssthresh降低为cwnd值的一半
3.2. 把cwnd重新设置为1
3.3. 重新进入慢启动过程
</code></pre>
<h4 id="4-快速恢复"><a class="header" href="#4-快速恢复">4. 快速恢复</a></h4>
<p>快速恢复是当收到3个重复ACK的时候才会触发，进入快速恢复阶段：</p>
<pre><code>4.1 当收到3个重复ACK时，把ssthresh设置为cwnd的一半，把cwnd设置为ssthresh的值加3，然后重传丢失的报文段，加3的原因是因为收到3个重复的ACK，表明有3个“老”的数据包离开了网络。
4.2 再收到重复的ACK时，拥塞窗口增加1。
4.3 当收到新的数据包的ACK时，把cwnd设置为第一步中的ssthresh的值。原因是因为该ACK确认了新的数据，说明从重复ACK时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态。
</code></pre>
<h2 id="udp"><a class="header" href="#udp">UDP</a></h2>
<p>上面介绍TCP的时候我们已经看出来，TCP是基于连接的协议，建立了可靠的连接以后双方才能互相传递数据。而UDP正好跟TCP相反，UDP是面向非连接的协议，不与对方建立连接，直接把数据包发过去就好了的一种协议，UDP是尽最大努力交付的。
所以UDP的传输速度快，因为不需要什么三次握手这种操作，而且UDP 没有拥塞控制。UDP只适合用于一些只需要传递少量数据，对可靠性要求不是很高的应用场景，比如一些多媒体通信的要求。</p>
<h2 id="tls"><a class="header" href="#tls">TLS</a></h2>
<p>首先这里我们先来弄清楚一个概念，也就是TLS和SSL的区别，这也是我在看《web性能权威指南》时候一脸懵逼的。
TLS：传输层安全协议，用于两个应用程序之间提供保密性和数据完整性。该协议由两层组成：TLS记录协议和TLS握手协议。
SSL：安全套接字层，位于可靠的面向连接的网络层协议和应用层协议之间的一种协议层。SSL通过互相认证、使用数字签名确保完整性、使用加密确保私密性，以确保客户端和服务端之间的安全通讯。由两层组成：SSL记录协议和SSL握手协议。
两者有什么联系呢？
TLS是以SSL 3.0为基础于1999年作为SSL的新版本推出的，也就是说SSL是TLS的前世，提供更强大的支持。
现在应该弄清楚两者之间的区别以后，我们就可以来看TLS协议的原理了。</p>
<h3 id="tls握手"><a class="header" href="#tls握手">TLS握手</a></h3>
<p>先来看流程图：
<img src="net/../static/img/net/tls001.png" alt="" /></p>
<ol>
<li>首先服务器生成自己的公钥和私钥，将公钥发送给CA机构</li>
<li>CA机构生成自己的公钥和私钥，并用私钥对服务器发送给自己的公钥签名生CA证书</li>
<li>CA机构把CA证书发送给服务端</li>
<li>浏览器内置了CA根证书的CA公钥</li>
<li>以上都为准备阶段，接下来开始正式连接，客户端向服务端发起三次握手</li>
<li>服务端将CA证书发给客户端，里面包含了服务端生成的公钥，有效期等</li>
<li>客户端根据自己的CA公钥验证CA证书的有效性</li>
<li>客户端生成随机对称密钥</li>
<li>将这个随机对称密钥用服务端给的公钥加密发给服务端</li>
<li>这里如果是银行U盾这种的话，服务器会有一个验证客户端的合法性的步骤，其他基本用不到</li>
<li>然后双方就可以通过这个随机密钥来进行通信了</li>
</ol>
<p>注意这里的随机对称密钥是对称加密，所以运算速度非常快，而服务器公钥只用于加密&quot;对话密钥&quot;本身，这样就减少了加密运算的消耗时间。另外为了优化性能，为了弥补完整的TLS握手所带来的额外的延迟和计算量，TLS提供了会话恢复功能，即在多个连接间共享这个协商后的安全密钥，也就是上面第9部中生成的用公钥加密的随机对称密钥：
在内部服务器会给每个客户端保存一个会话ID和协商后的会话参数就是密钥，对应客户端也会有保存，这样下次连接的时候就可以告诉对方自己有保存上次连接的资料，这样就可以迅速连接，节省一次往返，相当于加了一层缓冲层。</p>
<p>TLS的握手过程基本确保了传输的信息加密过；有身份认证机制，A想发消息给B，A能确保发送到的是B而不是中间被人拦截接受；有校验机制，能保证信息不会被篡改，这三个机制就是TLS出现的意义所在。</p>
<h2 id="http-1x"><a class="header" href="#http-1x">HTTP 1.x</a></h2>
<p>HTTP 1.1出现的一个重要目标就是为了提升HTTP 1.0的性能。
接下来列举几个比较重要的性能优化点：</p>
<ol>
<li>持久化连接以支持连接复用；</li>
<li>分块传输编码以支持流失响应；</li>
<li>引入HTTP 管道概念做到可以并行处理；</li>
<li>引入更多的缓存控制策略等。</li>
</ol>
<h3 id="持久化连接"><a class="header" href="#持久化连接">持久化连接</a></h3>
<p>我们知道一个TCP连接创建的时候要经过三次握手才能进行数据传递，而且还可能存在慢启动延迟，所以如果每次去调一个请求如果都需要创建一个TCP连接的话那么显然是很不友好的。所以HTTP 1.1.的时候加入了持久化连接，也就是支持场连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，HTTP1.1中是默认开启keep-alive的。这个持久化连接不会被一直保留，在空闲一段时间后被关闭，节约资源。</p>
<p>但是如果仅仅通过一个持久化连接，然后不断在这个连接上发送一个又一个的请求的话，经过实践效率并不理想，所以HTTP 1.1又加入了向同一个IP地址重复建立多个TCP连接的机制。大家可以用wireshark抓数据包试试，你会发现在几秒钟里面会建立好几个目的端口为80的TCP连接。现在大多数现代浏览器，包括桌面和移动浏览器，都支持每个主机打开 6 个连接。</p>
<h3 id="http管道化"><a class="header" href="#http管道化">HTTP管道化</a></h3>
<p>HTTP管道化在我的理解其实就是，客户端发送多个http以FIFO队列的形式请求到服务端以后，服务端返回这些请求的响应按照同样的FIFO队列的形式输出到客户端。这里，服务端会严格按照FIFO队列输出，如果服务端并发处理且优先级较高的请求处理时间比较长的话，那么优先级较低且先处理完的请求会被放入服务器的缓冲区，等待优先级较高的请求先回复以后再回复较低的，以FIFO队列形式。
在出现管道化之前，http请求都是顺序请求的，也就是说下一个请求只有在当前请求的响应被完全接受以后才能发送。所以这就有一个问题，http两个请求之间会有很大的延迟。</p>
<p>一般来说，只有幂等的请求才会进行管道化操作，幂等的请求其实就是多次操作都不会改变结果的请求，比如GET和HEAD。所以一般PUT和POST都不会被管道化。</p>
<h2 id="http-20"><a class="header" href="#http-20">HTTP 2.0</a></h2>
<p>2012年Google提出了SPDY方案，优化了HTTP 1.X的请求延迟、安全性等问题，而HTTP 2.0可以说是在SPDY的基础上设计出来的升级版plus。
HTTP 2.0最大的特点就是在不该动HTTP 语义，HTTP方法、状态码、URI及首部字段等等核心的东西的基础上，突破了HTTP 1.X的性能限制，最大的改变就是HTTP 2.0新加了一个二进制分帧层。</p>
<p><img src="net/../static/img/net/http001.png" alt="" /></p>
<p>从上面的图中我们可以看到，二进制分帧层的位置是在应用层和传输层之间，把HTTP 1.1中的首部信息封装到Headers帧中，把request body封装到了DATA 帧中。HTTP 2.0会把所有的传输信息分割为更小的消息和帧，并对他们采用二进制格式的编码形式。
先来看几个在HTTP 2.0中的新概念：</p>
<ul>
<li>流<br />
已建立的连接上的双向字节流</li>
<li>消息<br />
与逻辑消息对应的完整的一系列数据帧</li>
<li>帧<br />
HTTP 2.0通信的最小单位</li>
</ul>
<p>HTTP 2.0简而言之，就是在一个TCP连接上，建立任意数量的双向字节流，在每条字节流上以消息的形式来传递消息，而消息的是由一个或者多个帧组成的。
这里这个帧是可以乱序传递的，每个帧都有一个帧首部，帧首部上会有一个流标识符，最后会根据这个流标识符来重新组装顺序。
另外为了进一步增加效率，HTTP 2.0有一个首部压缩的机制，HTTP 2.0在客户端和服务端都会用一个“首部表”来跟踪和存储之前发送的键值对，对于相同的数据，就不会再通过每次请求和响应来发送了。
如果首部发生变化了，那么只需要发送变化了的数据放到Headers帧里，新增或者修改的首部帧就会跟踪到“首部表”，然后不断的更新变化。</p>
<h2 id="websocket"><a class="header" href="#websocket">WebSocket</a></h2>
<p>WebSocket 是HTML5中一种全新的web通信技术，是一种最通用最灵活的一个传输机制，真正实现了浏览器与服务器的全双工实时通信。
WebSocket 资源 URL 采用了自定义模式:ws 表示纯文本通信(如 ws://example. com/socket)，wss 表示使用加密信道通信(TCP+TLS)。WebSocket协议可以算是HTTP协议的一种补充，一种增强，以HTTP协议为基础，跟HTTP协议最大的区别在我理解就是：HTTP协议中只有你发送了一个request，你才会得到一个response，是轮询机制的，也就是说response是被动的，不能主动发起。而WebSocket中服务器则随时可以向客户端传递消息，全双工实时通信。</p>
<h3 id="协议详解"><a class="header" href="#协议详解">协议详解</a></h3>
<p>上面讲区别的时候讲到WebSocket是基于HTTP协议的，其实说的直白点，WebSocket是借用了HTTP的协议来完成了一部分握手，起到向下兼容现有浏览器的作用。
WebSocket协议有两部分组成：握手和数据传输。</p>
<h3 id="握手"><a class="header" href="#握手">握手</a></h3>
<p>我们来看一个RFC6455文档中给出的一个客户端握手消息实例：</p>
<pre><code>GET /chat HTTP/1.1
Host: server.example.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==
Sec-WebSocket-Protocol: chat, superchat
Sec-WebSocket-Version: 13
Origin: http://example.com
</code></pre>
<p>这里我们可以看到WebSocket使用HTTP来建立连接，但其中又定义了一系列心的header域：Upgrade: websocket
Connection: Upgrade来告诉服务器，我发起的是WebSocket协议，并通过Sec-WebSocket-Key、Sec-WebSocket-Protocol、Sec-WebSocket-Version三个值来校验以及告诉服务器Draft协议版本。
这之后服务器会返回一个标准的HTTP的Response消息来通知客户端我已经接受请求切换为WebSocket协议了：</p>
<pre><code>HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk=
Sec-WebSocket-Protocol: chat
</code></pre>
<h3 id="数据传输"><a class="header" href="#数据传输">数据传输</a></h3>
<p>建立了 WebSocket 连接后，客户端就可以随时发送或接收 UTF-8 或二进制消息。 WebSocket 提供的是一条双向通信的信道，也就是说，在同一个 TCP 连接上，可以双向传输数据，不再需要Request消息。WebSocket 通信只涉及消息，应用代码无需担心缓冲、解析、重建接收到的数据。
另外，WebSocket的数据帧是有序的。</p>
<h3 id="心跳机制"><a class="header" href="#心跳机制">心跳机制</a></h3>
<p>websocket为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的TCP通道保持连接没有断开，所以会有一个心跳包机制：</p>
<ul>
<li>发送方 -&gt; 接受方：ping，对应opcode为ox9</li>
<li>接收方 -&gt; 发送方：pong，对应opcode为0xA</li>
</ul>
<h3 id="经典的性能优化最佳实践"><a class="header" href="#经典的性能优化最佳实践">经典的性能优化最佳实践</a></h3>
<p>以下内容摘自《web性能权威指南》，我觉得很有参考价值:<br />
无论什么网络，也不管所用网络协议是什么版本，所有应用都应该致力于消除或减 少不必要的网络延迟，将需要传输的数据压缩至最少。这两条标准是经典的性能优 化最佳实践，是其他数十条性能准则的出发点。</p>
<ul>
<li>减少DNS查找<br />
每一次主机名解析都需要一次网络往返，从而增加请求的延迟时间，同时还会阻 塞后续请求。</li>
<li>重用TCP连接<br />
尽可能使用持久连接，以消除 TCP 握手和慢启动延迟</li>
<li>减少HTTP重定向<br />
HTTP 重定向极费时间，特别是不同域名之间的重定向，更加费时;这里面既有 额外的 DNS 查询、TCP 握手，还有其他延迟。最佳的重定向次数为零。</li>
<li>使用CDN(内容分发网络)<br />
把数据放到离用户地理位置更近的地方，可以显著减少每次 TCP 连接的网络延 迟，增大吞吐量。这一条既适用于静态内容，也适用于动态内容</li>
<li>去掉不必要的资源<br />
任何请求都不如没有请求快。</li>
<li>在客户端缓存资源<br />
应该缓存应用资源，从而避免每次请求都发送相同的内容。</li>
<li>传输压缩过的内容<br />
传输前应该压缩应用资源，把要传输的字节减至最少:确保对每种要传输的资源 采用最好的压缩手段。</li>
<li>消除不必要的请求开销<br />
减少请求的 HTTP 首部数据(比如 HTTP cookie)，节省的时间相当于几次往返 的延迟时间。</li>
<li>并行处理请求和响应<br />
请求和响应的排队都会导致延迟，无论是客户端还是服务器端。这一点经常被忽 视，但却会无谓地导致很长延迟。</li>
<li>针对协议版本采取优化措施<br />
HTTP 1.x 支持有限的并行机制，要求打包资源、跨域分散资源，等等。相对而 言，HTTP 2.0 只要建立一个连接就能实现最优性能，同时无需针对 HTTP 1.x 的 那些优化方法。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="net-1"><a class="header" href="#net-1">NET</a></h1>
<h2 id="tcp-1"><a class="header" href="#tcp-1">TCP</a></h2>
<p>TCP（传输控制协议），负责在不可靠的传输信道之上提供可靠的抽象层。
TCP的存在价值主要专注于可靠两个字，也就是它能够确保发送的所有字节流都能够完整的被接收到，而且到达客户端的顺序也是一样。但凡事都有两面性，如果精确性得到了保证的话，就会牺牲一定的速度和效率。
先来看TCP的连接和断开连接，也就是我们都熟悉的三次握手四次挥手：</p>
<h3 id="一三次握手-1"><a class="header" href="#一三次握手-1">一、三次握手</a></h3>
<p><img src="net/../static/img/net/tcp001.png" alt="" /></p>
<ol>
<li>首先客户端会生成一个随机序列号x，并发送一个SYN分组，其中可能还包括其他TCP标志和选项。</li>
<li>服务端收到分组以后给x+1，并生成一个随机序列号y，追加自己的标志和选项，然后返回给客户端。</li>
<li>客户端收到服务端消息以后给x和y都+1，然后发送一个ACK分组。</li>
</ol>
<p>经过这个三次握手以后客户端和服务端就可以互相传输数据了。这里客户端可以在发送ACK分组之后立即发送数据，服务端必须在接收到第三部的ACK分组以后才能传输数据。</p>
<p>那么接下来又有一个问题了，为什么是三次握手呢？为什么不是两次，或者四次五次握手呢？
TCP是一个双向通信协议，为了数据传输的可靠性，通信双方会维护一个序列号，以标识发出去的数据包里有哪些数据是被对方收到的。如果只有两次握手的话，服务端就无法确认他的序列号是否得到了确认，只有客户端的序列号得到了确认。而四次，五次握手的话则会造成资源的浪费。可以肯定的是，三次握手是在确保可靠性的基础上，性能上的最优解。</p>
<h3 id="二四次挥手-1"><a class="header" href="#二四次挥手-1">二、四次挥手</a></h3>
<p><img src="net/../static/img/net/tcp002.png" alt="" /></p>
<p>重点：TCP关闭连接的时候每个方向都必须要单独进行关闭。当一方发送一个FIN消息的时候，就意味申请终止这一个方向上的数据连接，当收到一个FIN就意味着这一方向上没有数据消息再传过来了，也就不会收到数据了。
TCP客户端服务端双方都可以发起close，这里我们以客户端发起close为图例，来看下过程：</p>
<ol>
<li>首先客户端发送一个FIN，这就意味着客户端不会再发送任何数据消息到服务端了，然后进入FIN-WAIT1状态。</li>
<li>服务端收到FIN消息以后呢，发送i 个ACK给客户端，确认序号为收到的的序号u+1，然后进入CLOSE_WAIT状态。</li>
<li>服务端发送一个FIN，这就意味着服务端不再发送任何数据消息到客户端，然后进入LAST_ACK状态。</li>
<li>客户端收到FIN消息以后，进入TIME_WAIT状态，然后发送一个ACK给服务端，确认序号为收到的序号w+1，然后进入TIME_WAIT状态。服务端收到ACK报文段以后就关闭连接了。。。客户端等待2MSL以后没有收到任何回复，就说明服务端已经正常关闭，然后自己关闭。</li>
</ol>
<p>那么为什么要四次挥手呢？？？
TCP的一端发出FIN报文段之后，仅仅表示这一端没有数据要发送给另一端了，但是他仍然能接受来自另一端的数据。所以如上面所示客户端先发送消息给服务端说我不发数据消息给你了，然后服务端发给客户端确认，然后服务端再发消息给客户端跟客户端说我也不发数据消息给你了，然后客户端回复确认，然后服务端关闭，之后客户端等待了以后也关闭。所以这就是需要四次挥手才能来关闭连接的原因。</p>
<p>在实际的网络传输过程中，很容易出现拥塞的现象，TCP对于拥塞控制主要有以下四个算法：</p>
<ol>
<li>慢启动</li>
<li>拥塞预防</li>
<li>拥塞发生时，快速重传</li>
<li>快速恢复</li>
</ol>
<h4 id="1-慢启动-1"><a class="header" href="#1-慢启动-1">1. 慢启动</a></h4>
<p>要理解这四个算法的话，首先先要理解拥塞窗口(cwnd)的概念：发送端对从客户端接受确认(ACK)之前可以发送数据的限制。
TCP的拥塞控制主要依赖于这个拥塞窗口来控制，首先三次握手的时候，客户端和服务端会通过ACK分组告知对方自己的接收窗口(rwnd)的大小，然后三次握手ACK消息成功传递以后双方就可以互相发消息了，但是如果在一开始连接刚建立就向网络中发送大量的数据包的话，就很容易导致网络中路由器的缓存空间耗尽，发声拥塞，所以即客户端与服务器之间最大可以传输(未经 ACK 确认的)数据量取 rwnd 和 cwnd 变量中的最小值。而这个cwnd的值会根据算法慢慢指数级增加，同时也设置了一个ssthresh门限值，如果cwnd达到这个值以后会让cwnd增长变得平滑，也就是慢启动。</p>
<h4 id="2-拥塞预防-1"><a class="header" href="#2-拥塞预防-1">2. 拥塞预防</a></h4>
<p>拥塞预防的原理就是加入ssthresh门限值来限制 cwnd的增长，当cwnd超过该值以后，慢启动过程结束，进入拥塞避免阶段。拥塞避免的主要思想是加法增大，也就是cwnd的值不再指数级往上升，开始加法增加。此时当窗口中所有的报文段都被确认时，cwnd的大小加1，cwnd的值就随着RTT开始线性增加，这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。</p>
<h4 id="3-快速重传-1"><a class="header" href="#3-快速重传-1">3. 快速重传</a></h4>
<p>TCP的每一个报文段都有一个定时器，叫做重传定时器，如果重传定时器超时并且没有得到数据确认的话，TCP就会对该报文段进行重传处理，这里TCP也就把网络定义为拥塞的状态，会进行如下操作：</p>
<pre><code>3.1. 把ssthresh降低为cwnd值的一半
3.2. 把cwnd重新设置为1
3.3. 重新进入慢启动过程
</code></pre>
<h4 id="4-快速恢复-1"><a class="header" href="#4-快速恢复-1">4. 快速恢复</a></h4>
<p>快速恢复是当收到3个重复ACK的时候才会触发，进入快速恢复阶段：</p>
<pre><code>4.1 当收到3个重复ACK时，把ssthresh设置为cwnd的一半，把cwnd设置为ssthresh的值加3，然后重传丢失的报文段，加3的原因是因为收到3个重复的ACK，表明有3个“老”的数据包离开了网络。
4.2 再收到重复的ACK时，拥塞窗口增加1。
4.3 当收到新的数据包的ACK时，把cwnd设置为第一步中的ssthresh的值。原因是因为该ACK确认了新的数据，说明从重复ACK时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态。
</code></pre>
<h2 id="udp-1"><a class="header" href="#udp-1">UDP</a></h2>
<p>上面介绍TCP的时候我们已经看出来，TCP是基于连接的协议，建立了可靠的连接以后双方才能互相传递数据。而UDP正好跟TCP相反，UDP是面向非连接的协议，不与对方建立连接，直接把数据包发过去就好了的一种协议，UDP是尽最大努力交付的。
所以UDP的传输速度快，因为不需要什么三次握手这种操作，而且UDP 没有拥塞控制。UDP只适合用于一些只需要传递少量数据，对可靠性要求不是很高的应用场景，比如一些多媒体通信的要求。</p>
<h2 id="tls-1"><a class="header" href="#tls-1">TLS</a></h2>
<p>首先这里我们先来弄清楚一个概念，也就是TLS和SSL的区别，这也是我在看《web性能权威指南》时候一脸懵逼的。
TLS：传输层安全协议，用于两个应用程序之间提供保密性和数据完整性。该协议由两层组成：TLS记录协议和TLS握手协议。
SSL：安全套接字层，位于可靠的面向连接的网络层协议和应用层协议之间的一种协议层。SSL通过互相认证、使用数字签名确保完整性、使用加密确保私密性，以确保客户端和服务端之间的安全通讯。由两层组成：SSL记录协议和SSL握手协议。
两者有什么联系呢？
TLS是以SSL 3.0为基础于1999年作为SSL的新版本推出的，也就是说SSL是TLS的前世，提供更强大的支持。
现在应该弄清楚两者之间的区别以后，我们就可以来看TLS协议的原理了。</p>
<h3 id="tls握手-1"><a class="header" href="#tls握手-1">TLS握手</a></h3>
<p>先来看流程图：
<img src="net/../static/img/net/tls001.png" alt="" /></p>
<ol>
<li>首先服务器生成自己的公钥和私钥，将公钥发送给CA机构</li>
<li>CA机构生成自己的公钥和私钥，并用私钥对服务器发送给自己的公钥签名生CA证书</li>
<li>CA机构把CA证书发送给服务端</li>
<li>浏览器内置了CA根证书的CA公钥</li>
<li>以上都为准备阶段，接下来开始正式连接，客户端向服务端发起三次握手</li>
<li>服务端将CA证书发给客户端，里面包含了服务端生成的公钥，有效期等</li>
<li>客户端根据自己的CA公钥验证CA证书的有效性</li>
<li>客户端生成随机对称密钥</li>
<li>将这个随机对称密钥用服务端给的公钥加密发给服务端</li>
<li>这里如果是银行U盾这种的话，服务器会有一个验证客户端的合法性的步骤，其他基本用不到</li>
<li>然后双方就可以通过这个随机密钥来进行通信了</li>
</ol>
<p>注意这里的随机对称密钥是对称加密，所以运算速度非常快，而服务器公钥只用于加密&quot;对话密钥&quot;本身，这样就减少了加密运算的消耗时间。另外为了优化性能，为了弥补完整的TLS握手所带来的额外的延迟和计算量，TLS提供了会话恢复功能，即在多个连接间共享这个协商后的安全密钥，也就是上面第9部中生成的用公钥加密的随机对称密钥：
在内部服务器会给每个客户端保存一个会话ID和协商后的会话参数就是密钥，对应客户端也会有保存，这样下次连接的时候就可以告诉对方自己有保存上次连接的资料，这样就可以迅速连接，节省一次往返，相当于加了一层缓冲层。</p>
<p>TLS的握手过程基本确保了传输的信息加密过；有身份认证机制，A想发消息给B，A能确保发送到的是B而不是中间被人拦截接受；有校验机制，能保证信息不会被篡改，这三个机制就是TLS出现的意义所在。</p>
<h2 id="http-1x-1"><a class="header" href="#http-1x-1">HTTP 1.x</a></h2>
<p>HTTP 1.1出现的一个重要目标就是为了提升HTTP 1.0的性能。
接下来列举几个比较重要的性能优化点：</p>
<ol>
<li>持久化连接以支持连接复用；</li>
<li>分块传输编码以支持流失响应；</li>
<li>引入HTTP 管道概念做到可以并行处理；</li>
<li>引入更多的缓存控制策略等。</li>
</ol>
<h3 id="持久化连接-1"><a class="header" href="#持久化连接-1">持久化连接</a></h3>
<p>我们知道一个TCP连接创建的时候要经过三次握手才能进行数据传递，而且还可能存在慢启动延迟，所以如果每次去调一个请求如果都需要创建一个TCP连接的话那么显然是很不友好的。所以HTTP 1.1.的时候加入了持久化连接，也就是支持场连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，HTTP1.1中是默认开启keep-alive的。这个持久化连接不会被一直保留，在空闲一段时间后被关闭，节约资源。</p>
<p>但是如果仅仅通过一个持久化连接，然后不断在这个连接上发送一个又一个的请求的话，经过实践效率并不理想，所以HTTP 1.1又加入了向同一个IP地址重复建立多个TCP连接的机制。大家可以用wireshark抓数据包试试，你会发现在几秒钟里面会建立好几个目的端口为80的TCP连接。现在大多数现代浏览器，包括桌面和移动浏览器，都支持每个主机打开 6 个连接。</p>
<h3 id="http管道化-1"><a class="header" href="#http管道化-1">HTTP管道化</a></h3>
<p>HTTP管道化在我的理解其实就是，客户端发送多个http以FIFO队列的形式请求到服务端以后，服务端返回这些请求的响应按照同样的FIFO队列的形式输出到客户端。这里，服务端会严格按照FIFO队列输出，如果服务端并发处理且优先级较高的请求处理时间比较长的话，那么优先级较低且先处理完的请求会被放入服务器的缓冲区，等待优先级较高的请求先回复以后再回复较低的，以FIFO队列形式。
在出现管道化之前，http请求都是顺序请求的，也就是说下一个请求只有在当前请求的响应被完全接受以后才能发送。所以这就有一个问题，http两个请求之间会有很大的延迟。</p>
<p>一般来说，只有幂等的请求才会进行管道化操作，幂等的请求其实就是多次操作都不会改变结果的请求，比如GET和HEAD。所以一般PUT和POST都不会被管道化。</p>
<h2 id="http-20-1"><a class="header" href="#http-20-1">HTTP 2.0</a></h2>
<p>2012年Google提出了SPDY方案，优化了HTTP 1.X的请求延迟、安全性等问题，而HTTP 2.0可以说是在SPDY的基础上设计出来的升级版plus。
HTTP 2.0最大的特点就是在不该动HTTP 语义，HTTP方法、状态码、URI及首部字段等等核心的东西的基础上，突破了HTTP 1.X的性能限制，最大的改变就是HTTP 2.0新加了一个二进制分帧层。</p>
<p><img src="net/../static/img/net/http001.png" alt="" /></p>
<p>从上面的图中我们可以看到，二进制分帧层的位置是在应用层和传输层之间，把HTTP 1.1中的首部信息封装到Headers帧中，把request body封装到了DATA 帧中。HTTP 2.0会把所有的传输信息分割为更小的消息和帧，并对他们采用二进制格式的编码形式。
先来看几个在HTTP 2.0中的新概念：</p>
<ul>
<li>流<br />
已建立的连接上的双向字节流</li>
<li>消息<br />
与逻辑消息对应的完整的一系列数据帧</li>
<li>帧<br />
HTTP 2.0通信的最小单位</li>
</ul>
<p>HTTP 2.0简而言之，就是在一个TCP连接上，建立任意数量的双向字节流，在每条字节流上以消息的形式来传递消息，而消息的是由一个或者多个帧组成的。
这里这个帧是可以乱序传递的，每个帧都有一个帧首部，帧首部上会有一个流标识符，最后会根据这个流标识符来重新组装顺序。
另外为了进一步增加效率，HTTP 2.0有一个首部压缩的机制，HTTP 2.0在客户端和服务端都会用一个“首部表”来跟踪和存储之前发送的键值对，对于相同的数据，就不会再通过每次请求和响应来发送了。
如果首部发生变化了，那么只需要发送变化了的数据放到Headers帧里，新增或者修改的首部帧就会跟踪到“首部表”，然后不断的更新变化。</p>
<h2 id="websocket-1"><a class="header" href="#websocket-1">WebSocket</a></h2>
<p>WebSocket 是HTML5中一种全新的web通信技术，是一种最通用最灵活的一个传输机制，真正实现了浏览器与服务器的全双工实时通信。
WebSocket 资源 URL 采用了自定义模式:ws 表示纯文本通信(如 ws://example. com/socket)，wss 表示使用加密信道通信(TCP+TLS)。WebSocket协议可以算是HTTP协议的一种补充，一种增强，以HTTP协议为基础，跟HTTP协议最大的区别在我理解就是：HTTP协议中只有你发送了一个request，你才会得到一个response，是轮询机制的，也就是说response是被动的，不能主动发起。而WebSocket中服务器则随时可以向客户端传递消息，全双工实时通信。</p>
<h3 id="协议详解-1"><a class="header" href="#协议详解-1">协议详解</a></h3>
<p>上面讲区别的时候讲到WebSocket是基于HTTP协议的，其实说的直白点，WebSocket是借用了HTTP的协议来完成了一部分握手，起到向下兼容现有浏览器的作用。
WebSocket协议有两部分组成：握手和数据传输。</p>
<h3 id="握手-1"><a class="header" href="#握手-1">握手</a></h3>
<p>我们来看一个RFC6455文档中给出的一个客户端握手消息实例：</p>
<pre><code>GET /chat HTTP/1.1
Host: server.example.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==
Sec-WebSocket-Protocol: chat, superchat
Sec-WebSocket-Version: 13
Origin: http://example.com
</code></pre>
<p>这里我们可以看到WebSocket使用HTTP来建立连接，但其中又定义了一系列心的header域：Upgrade: websocket
Connection: Upgrade来告诉服务器，我发起的是WebSocket协议，并通过Sec-WebSocket-Key、Sec-WebSocket-Protocol、Sec-WebSocket-Version三个值来校验以及告诉服务器Draft协议版本。
这之后服务器会返回一个标准的HTTP的Response消息来通知客户端我已经接受请求切换为WebSocket协议了：</p>
<pre><code>HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk=
Sec-WebSocket-Protocol: chat
</code></pre>
<h3 id="数据传输-1"><a class="header" href="#数据传输-1">数据传输</a></h3>
<p>建立了 WebSocket 连接后，客户端就可以随时发送或接收 UTF-8 或二进制消息。 WebSocket 提供的是一条双向通信的信道，也就是说，在同一个 TCP 连接上，可以双向传输数据，不再需要Request消息。WebSocket 通信只涉及消息，应用代码无需担心缓冲、解析、重建接收到的数据。
另外，WebSocket的数据帧是有序的。</p>
<h3 id="心跳机制-1"><a class="header" href="#心跳机制-1">心跳机制</a></h3>
<p>websocket为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的TCP通道保持连接没有断开，所以会有一个心跳包机制：</p>
<ul>
<li>发送方 -&gt; 接受方：ping，对应opcode为ox9</li>
<li>接收方 -&gt; 发送方：pong，对应opcode为0xA</li>
</ul>
<h3 id="经典的性能优化最佳实践-1"><a class="header" href="#经典的性能优化最佳实践-1">经典的性能优化最佳实践</a></h3>
<p>以下内容摘自《web性能权威指南》，我觉得很有参考价值:<br />
无论什么网络，也不管所用网络协议是什么版本，所有应用都应该致力于消除或减 少不必要的网络延迟，将需要传输的数据压缩至最少。这两条标准是经典的性能优 化最佳实践，是其他数十条性能准则的出发点。</p>
<ul>
<li>减少DNS查找<br />
每一次主机名解析都需要一次网络往返，从而增加请求的延迟时间，同时还会阻 塞后续请求。</li>
<li>重用TCP连接<br />
尽可能使用持久连接，以消除 TCP 握手和慢启动延迟</li>
<li>减少HTTP重定向<br />
HTTP 重定向极费时间，特别是不同域名之间的重定向，更加费时;这里面既有 额外的 DNS 查询、TCP 握手，还有其他延迟。最佳的重定向次数为零。</li>
<li>使用CDN(内容分发网络)<br />
把数据放到离用户地理位置更近的地方，可以显著减少每次 TCP 连接的网络延 迟，增大吞吐量。这一条既适用于静态内容，也适用于动态内容</li>
<li>去掉不必要的资源<br />
任何请求都不如没有请求快。</li>
<li>在客户端缓存资源<br />
应该缓存应用资源，从而避免每次请求都发送相同的内容。</li>
<li>传输压缩过的内容<br />
传输前应该压缩应用资源，把要传输的字节减至最少:确保对每种要传输的资源 采用最好的压缩手段。</li>
<li>消除不必要的请求开销<br />
减少请求的 HTTP 首部数据(比如 HTTP cookie)，节省的时间相当于几次往返 的延迟时间。</li>
<li>并行处理请求和响应<br />
请求和响应的排队都会导致延迟，无论是客户端还是服务器端。这一点经常被忽 视，但却会无谓地导致很长延迟。</li>
<li>针对协议版本采取优化措施<br />
HTTP 1.x 支持有限的并行机制，要求打包资源、跨域分散资源，等等。相对而 言，HTTP 2.0 只要建立一个连接就能实现最优性能，同时无需针对 HTTP 1.x 的 那些优化方法。</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="一前言"><a class="header" href="#一前言">一、前言</a></h1>
<h2 id="1-elk简介"><a class="header" href="#1-elk简介">1. ELK简介</a></h2>
<p>ELK是Elasticsearch+Logstash+Kibana的简称</p>
<ul>
<li>
<p>ElasticSearch是一个基于Lucene的分布式全文搜索引擎，提供 RESTful API进行数据读写</p>
</li>
<li>
<p>Logstash是一个收集，处理和转发事件和日志消息的工具</p>
</li>
<li>
<p>Kibana是Elasticsearch的开源数据可视化插件，为查看存储在ElasticSearch提供了友好的Web界面，并提供了条形图，线条和散点图，饼图和地图等分析工具</p>
</li>
</ul>
<p>总的来说，ElasticSearch负责存储数据，Logstash负责收集日志，并将日志格式化后写入ElasticSearch，Kibana提供可视化访问ElasticSearch数据的功能。</p>
<h2 id="2elk工作流"><a class="header" href="#2elk工作流">2、ELK工作流</a></h2>
<p>ELK工作流</p>
<p>应用将日志按照约定的Key写入Redis，Logstash从Redis中读取日志信息写入ElasticSearch集群。Kibana读取ElasticSearch中的日志，并在Web页面中以表格/图表的形式展示。</p>
<h1 id="二准备工作"><a class="header" href="#二准备工作">二、准备工作</a></h1>
<h2 id="1服务器软件环境说明"><a class="header" href="#1服务器软件环境说明">1、服务器&amp;软件环境说明</a></h2>
<ul>
<li>服务器</li>
</ul>
<p>一共准备3台CentOS7 Server</p>
<p>es1	192.168.1.31	部署ElasticSearch主节点</p>
<p>es2	192.168.1.32	部署ElasticSearch从节点</p>
<p>elk	192.168.1.21	部署Logstash + Kibana + Redis</p>
<p>这里为了节省，只部署2台Elasticsearch，并将Logstash + Kibana + Redis部署在了一台机器上。
如果在生产环境部署，可以按照自己的需求调整。</p>
<ul>
<li>软件环境</li>
</ul>
<p>Linux Server	CentOS 7</p>
<p>Elasticsearch	7.0.0</p>
<p>Logstash	7.0.0</p>
<p>Kibana	7.0.0</p>
<p>Redis	4.0</p>
<p>JDK	1.8</p>
<h2 id="2elk环境准备"><a class="header" href="#2elk环境准备">2、ELK环境准备</a></h2>
<p>由于Elasticsearch、Logstash、Kibana均不能以root账号运行。
但是Linux对非root账号可并发操作的文件、线程都有限制。
所以，部署ELK相关的机器都要调整：</p>
<ul>
<li>修改文件限制</li>
</ul>
<pre><code># 修改系统文件
vi /etc/security/limits.conf

#增加的内容

* soft nofile 65536
* hard nofile 65536
* soft nproc 2048
* hard nproc 4096
</code></pre>
<ul>
<li>调整进程数</li>
</ul>
<pre><code>#修改系统文件
vi /etc/security/limits.d/20-nproc.conf
 
#调整成以下配置
*          soft    nproc     4096
root       soft    nproc     unlimited
</code></pre>
<ul>
<li>调整虚拟内存&amp;最大并发连接</li>
</ul>
<pre><code>#修改系统文件
vi /etc/sysctl.conf
 
#增加的内容
vm.max_map_count=655360
fs.file-max=655360
</code></pre>
<p>以上操作重启系统后生效</p>
<ul>
<li>JDK安装</li>
</ul>
<pre><code>rpm -iv jdk.rpm
</code></pre>
<ul>
<li>创建专用用户</li>
</ul>
<pre><code>useradd elk
</code></pre>
<ul>
<li>创建相关目录并赋权</li>
</ul>
<pre><code>#创建应用目录
mkdir /opt/elk
#创建数据目录
mkdir /elk
 
#更改目录拥有者
chown -R elk:elk /opt/elk
chown -R elk:elk /elk
</code></pre>
<ul>
<li>下载包并解压</li>
</ul>
<pre><code>#打开文件夹
cd /home/download
 
#下载
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.0.0.tar.gz
wget https://artifacts.elastic.co/downloads/logstash/logstash-7.0.0.tar.gz
wget https://artifacts.elastic.co/downloads/kibana/kibana-7.0.0.tar.gz
 
#解压
tar -zvxf elasticsearch-7.0.0.tar.gz
tar -zvxf logstash-7.0.0.tar.gz
tar -zvxf kibana-7.0.0.tar.gz
</code></pre>
<h1 id="三elasticsearch-部署"><a class="header" href="#三elasticsearch-部署">三、Elasticsearch 部署</a></h1>
<p>本次一共要部署两个Elasticsearch节点，所有文中没有指定机器的操作都表示每个Elasticsearch机器都要执行该操作</p>
<h2 id="1准备工作"><a class="header" href="#1准备工作">1、准备工作</a></h2>
<ul>
<li>移动Elasticsearch到统一目录</li>
</ul>
<pre><code>#移动目录
mv /home/download/elasticsearch-7.0.0 /opt/elk
#赋权
chown -R elk:elk /opt/elk/elasticsearch-7.0.0
</code></pre>
<ul>
<li>开放端口</li>
</ul>
<pre><code>#增加端口
firewall-cmd --add-port=9200/tcp --permanent
firewall-cmd --add-port=9300/tcp --permanent
 
#重新加载防火墙规则
firewall-cmd --reload
</code></pre>
<p>-切换账号</p>
<pre><code>su - elk
</code></pre>
<ul>
<li>数据&amp;日志目录</li>
</ul>
<pre><code>创建Elasticsearch主目录
mkdir /elk/es
#创建Elasticsearch数据目录
mkdir /elk/es/data
#创建Elasticsearch日志目录
mkdir /elk/es/logs
</code></pre>
<h2 id="2elasticsearch节点配置"><a class="header" href="#2elasticsearch节点配置">2、Elasticsearch节点配置</a></h2>
<ul>
<li>修改配置</li>
</ul>
<pre><code>#打开目录
cd /opt/elk/elasticsearch-7.0.0
 
#修改配置
 
vi config/elasticsearch.yml
</code></pre>
<ul>
<li>主节点配置（192.168.1.31）</li>
</ul>
<pre><code>cluster.name: es 
node.name: es1
path.data: /elk/es/data
path.logs: /elk/es/logs
network.host: 192.168.1.31
http.port: 9200
transport.tcp.port: 9300
node.master: true
node.data: true
discovery.zen.ping.unicast.hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;]
discovery.zen.minimum_master_nodes: 1
</code></pre>
<ul>
<li>从节点配置（192.168.1.32）</li>
</ul>
<pre><code>cluster.name: es 
node.name: es2
path.data: /elk/es/data
path.logs: /elk/es/logs
network.host: 192.168.1.32
http.port: 9200
transport.tcp.port: 9300
node.master: false
node.data: true
discovery.zen.ping.unicast.hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;]
discovery.zen.minimum_master_nodes: 1
</code></pre>
<ul>
<li>配置项说明</li>
</ul>
<pre><code>配置    说明
cluster.name	集群名
node.name	节点名
path.data	数据保存目录
path.logs	日志保存目录
network.host	节点host/ip
http.port	HTTP访问端口
transport.tcp.port	TCP传输端口
node.master	是否允许作为主节点
node.data	是否保存数据
discovery.zen.ping.unicast.hosts	集群中的主节点的初始列表,当节点(主节点或者数据节点)启动时使用这个列表进行探测
discovery.zen.minimum_master_nodes	主节点个数
</code></pre>
<h2 id="3elasticsearch启动健康检查"><a class="header" href="#3elasticsearch启动健康检查">3、Elasticsearch启动&amp;健康检查</a></h2>
<ul>
<li>启动</li>
</ul>
<pre><code>#进入elasticsearch根目录
cd /opt/elk/elasticsearch-7.0.0
#启动
./bin/elasticsearch
</code></pre>
<ul>
<li>查看健康状态</li>
</ul>
<pre><code>curl http://192.168.1.31:9200/_cluster/health
</code></pre>
<p>如果返回status=green表示正常</p>
<pre><code>{
  &quot;cluster_name&quot;: &quot;esc&quot;,
  &quot;status&quot;: &quot;green&quot;,
  &quot;timed_out&quot;: false,
  &quot;number_of_nodes&quot;: 2,
  &quot;number_of_data_nodes&quot;: 2,
  &quot;active_primary_shards&quot;: 0,
  &quot;active_shards&quot;: 0,
  &quot;relocating_shards&quot;: 0,
  &quot;initializing_shards&quot;: 0,
  &quot;unassigned_shards&quot;: 0,
  &quot;delayed_unassigned_shards&quot;: 0,
  &quot;number_of_pending_tasks&quot;: 0,
  &quot;number_of_in_flight_fetch&quot;: 0,
  &quot;task_max_waiting_in_queue_millis&quot;: 0,
  &quot;active_shards_percent_as_number&quot;: 100.0
}
</code></pre>
<h1 id="四logstash-部署"><a class="header" href="#四logstash-部署">四、Logstash 部署</a></h1>
<h2 id="1准备工作-1"><a class="header" href="#1准备工作-1">1、准备工作</a></h2>
<ul>
<li>
<p>部署Redis(略)</p>
</li>
<li>
<p>移动Logstash到统一目录</p>
</li>
</ul>
<pre><code>#移动目录
mv /home/download/logstash-7.0.0 /opt/elk
#赋权
chown -R elk:elk /opt/elk/logstash-7.0.0
</code></pre>
<ul>
<li>切换账号</li>
</ul>
<pre><code>#账号切换到 elk
su - elk
</code></pre>
<ul>
<li>数据&amp;日志目录</li>
</ul>
<pre><code>#创建Logstash主目录
mkdir /elk/logstash
#创建Logstash数据目录
mkdir /elk/logstash/data
#创建Logstash日志目录
mkdir /elk/logstash/logs
</code></pre>
<h2 id="2logstash配置"><a class="header" href="#2logstash配置">2、Logstash配置</a></h2>
<ul>
<li>配置数据&amp;日志目录</li>
</ul>
<pre><code>#打开目录
cd /opt/elk/logstash-7.0.0
#修改配置
vi config/logstash.yml
 
#增加以下内容
path.data: /elk/logstash/data
path.logs: /elk/logstash/logs
</code></pre>
<ul>
<li>配置Redis&amp;Elasticsearch</li>
</ul>
<pre><code>vi config/input-output.conf
 
#配置内容
 
input {
  redis {
    data_type =&gt; &quot;list&quot;
    key =&gt; &quot;logstash&quot;
    host =&gt; &quot;192.168.1.21&quot;
    port =&gt; 6379
    threads =&gt; 5
    codec =&gt; &quot;json&quot;
  }
}
filter {
}
output {
  elasticsearch {
    hosts =&gt; [&quot;192.168.1.31:9200&quot;,&quot;192.168.1.32:9200&quot;]
    index =&gt; &quot;logstash-%{type}-%{+YYYY.MM.dd}&quot;
    document_type =&gt; &quot;%{type}&quot;
  }
  stdout {
  }
}
</code></pre>
<p>该配置就是从redis中读取数据，然后写入指定的elasticsearch。
Redis核心配置项说明：</p>
<pre><code>配置项	说明
data_type =&gt; &quot;list&quot;	数据类型为list
key =&gt; &quot;logstash&quot;	缓存key为：logstash
codec =&gt; &quot;json&quot;	数据格式为：json
</code></pre>
<ul>
<li>启动</li>
</ul>
<pre><code>#进入Logstash根目录
cd /opt/elk/logstash-7.0.0
#测试
./bin/logstash -t -f config/input-output.conf
#启动
./bin/logstash -f config/input-output.conf
</code></pre>
<p>启动成功后，在启动输出的最后一行会看到如下信息：</p>
<pre><code>[INFO ][logstash.pipeline        ] Pipeline started {&quot;pipeline.id&quot;=&gt;&quot;main&quot;}
[INFO ][logstash.agent           ] Pipelines running {:count=&gt;1, :pipelines=&gt;[&quot;main&quot;]}
</code></pre>
<h1 id="五kibana-部署"><a class="header" href="#五kibana-部署">五、Kibana 部署</a></h1>
<h2 id="1准备工作-2"><a class="header" href="#1准备工作-2">1、准备工作</a></h2>
<ul>
<li>移动Kibana到统一目录</li>
</ul>
<pre><code>#移动目录
mv /home/download/kibana-7.0.0 /opt/elk/kibana-7.0.0
#赋权
chown -R elk:elk /usr/elk/kibana-7.0.0
</code></pre>
<ul>
<li>开放端口</li>
</ul>
<pre><code>#增加端口
firewall-cmd --add-port=5601/tcp --permanent
 
#重新加载防火墙规则
firewall-cmd --reload
</code></pre>
<ul>
<li>切换账号</li>
</ul>
<pre><code>#账号切换到 elk
su - elk
</code></pre>
<h2 id="3kibana配置与访问测试"><a class="header" href="#3kibana配置与访问测试">3、Kibana配置与访问测试</a></h2>
<ul>
<li>修改配置</li>
</ul>
<pre><code>#进入kibana-7.0.0根目录
cd /opt/elk/kibana-7.0.0
#修改配置
vi config/kibana.yml
 
#增加以下内容
server.port: 5601
server.host: &quot;192.168.1.21&quot;
elasticsearch.url: &quot;http://192.168.1.31:9200&quot; 
</code></pre>
<ul>
<li>启动</li>
</ul>
<pre><code>#进入kibana-7.0.0根目录
cd /opt/elk/kibana-7.0.0
#启动
./bin/kibana
</code></pre>
<ul>
<li>访问</li>
</ul>
<p>http://192.168.1.21:5601</p>
<h1 id="六测试"><a class="header" href="#六测试">六、测试</a></h1>
<h2 id="1日志写入"><a class="header" href="#1日志写入">1、日志写入</a></h2>
<p>日历写入的话，写入到logstash监听的redis即可。
数据类型之前在/opt/elk/logstash-7.0.0/config/input-uput.conf中有配置</p>
<ul>
<li>Redis命令方式</li>
</ul>
<pre><code>#启动redis客户端
#执行以下命令
lpush logstash '{&quot;host&quot;:&quot;127.0.0.1&quot;,&quot;type&quot;:&quot;logtest&quot;,&quot;message&quot;:&quot;hello&quot;}'
</code></pre>
<ul>
<li>Java代码批量写入（引入Jedis）</li>
</ul>
<pre><code>Jedis jedis = new Jedis(&quot;192.168.1.21&quot;, 6379);
for (int i = 0; i &lt; 1000; i++) {
    jedis.lpush(&quot;logstash&quot;, &quot;{\&quot;host\&quot;:\&quot;127.0.0.1\&quot;,\&quot;type\&quot;:\&quot;logtest\&quot;,\&quot;message\&quot;:\&quot;&quot; + i + &quot;\&quot;}&quot;);
}
</code></pre>
<h2 id="2kibana使用"><a class="header" href="#2kibana使用">2、Kibana使用</a></h2>
<pre><code>http://192.168.1.21:5601/app/kibana#/discover
</code></pre>
<h1 id="other-1"><a class="header" href="#other-1">Other</a></h1>
<h2 id="logstash配置"><a class="header" href="#logstash配置">Logstash配置</a></h2>
<ul>
<li>配置参数</li>
</ul>
<pre><code>file：顾名思义，直接读文件
stdin: 标准输入，调试配置的时候玩玩
syslog: syslog协议的日志格式，比如linux的rsyslog
tcp/udp：使用tcp或udp传输过来的日志
</code></pre>
<pre><code>path: 日志文件或目录的绝对路径，也可以是通配符的。
type: 类型，自定义
start_position: logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行。如果你是要导入原有数据，把这个设定改成 &quot;beginning&quot;，logstash 进程就从头开始读取，类似 less +F 的形式运行。
codec: codec配置，通过它可以更好更方便的与其他有自定义数据格式的运维产品共存，比如 graphite、fluent、netflow、collectd，以及使用 msgpack、json、edn 等通用数据格式的其他产品等。
</code></pre>
<ul>
<li>config.conf</li>
</ul>
<pre><code>input {
    file {
        #指定单一文件
        path =&gt; &quot;/data/es/logstash/files/test.log&quot;
        #指定数组文件
        #path =&gt; [&quot;/data/es/logstash/files/test-1.log&quot;,&quot;/data/es/logstash/files/test-2.log&quot;]
        #指定同级目录模糊匹配
        #path =&gt; &quot;/data/es/logstash/files/test*.log&quot;
        #指定多级目录模糊匹配
        #path =&gt; &quot;/data/es/logstash/files/**/test*.log&quot;

        #当存在多个文件的时候可使用type指定输入输出路径
        type =&gt; &quot;log_index&quot;
        
        #可设置成begining或end，begining表示从头开始读取文件，end表示读取最新数据，可和ignore_older一起使用
        #begining只针对首次启动是否需要读取所有的历史数据，而当文件修改了之后，同样会自动增量更新新数据
        start_position =&gt; &quot;beginning&quot;

        #设置输入规则
        codec =&gt; multiline {
            #利用正则匹配规则，匹配每一行开始的位置，这里匹配每一行开始的位置为数字
            pattern =&gt; &quot;^[0-9]&quot;
     
            #true表示不匹配正则表达式，false为匹配正则表达式，默认false
            #如果不匹配，则会结合what参数，进行合并操作
            negate =&gt; true
            
            #what可设置previous和next，previous则表示将所有不匹配的数据都合并到上一个正则事件
            #而next则相反，将所有的不匹配的数据都合并到下一个正则事件
            what =&gt; &quot;previous&quot;
 
            #表示当多长时间没有新的数据，最后一个正则匹配积累的多行数据都归属为最后一个事件，这里的10表示10秒
            #auto_flush_interval =&gt; 10
       }
    }
    tcp {
        port =&gt; 8888
        mode =&gt; &quot;server&quot;
        ssl_enable =&gt; false
    }
}
filter {
    grok {
        match =&gt; {
            &quot;message&quot; =&gt; &quot;%{IPORHOST:clientip} - - \[%{HTTPDATE:request_time}\] \&quot;(?:%{WORD:method} %{URIPATH:url}(?:%{URIPARAM:params})?(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\&quot; %{NUMBER:status} (?:%{NUMBER:bytes:int}|-) \&quot;%{DATA:referrer}\&quot; \&quot;%{DATA:agent}\&quot;&quot;
        }
    }
    ruby{
        init =&gt; &quot;@kname = ['client','servername','url','status','time','size','upstream','upstreamstatus','upstreamtime','referer','xff','useragent']&quot;
        code =&gt; &quot;
            new_event = LogStash::Event.new(Hash[@kname.zip(event.get('message').split('|'))])
            new_event.remove('@timestamp')
            event.append(new_event)&quot;
    }
}
output {
    #输出控制台
    stdout {
        #codec =&gt; json
    }

    #输出到elasticsearch
    if [type] == &quot;log_index&quot; {
        elasticsearch {
            hosts =&gt; [&quot;192.168.1.31:9200&quot;,&quot;192.168.1.32:9200&quot;]
            
            #以当前的日期作为index和type
            #index =&gt; &quot;log-%{+YYYY.MM.dd}&quot;
            index =&gt; &quot;%{type}-%{+YYYY.MM.dd}&quot;
            document_type =&gt; &quot;%{type}-%{+YYYY.MM.dd}&quot;
            
            #覆盖模板
            #template_overwrite =&gt; true
            #template =&gt; &quot;/elk/es/logstash/template/logstash.json&quot;
        }
    }

    #输出到文件
    if [type] == &quot;log_file&quot; {
        file {
            path =&gt; &quot;/elk/logstash/logs/website-%{+YYYY.MM.dd}.log&quot;
            flush_interval =&gt; 0
        }
    }

    #输出到Redis
    if [type] == &quot;log_redis&quot; {
        redis {
            host =&gt; &quot;192.168.11.5&quot;
            port =&gt; 7890
            db =&gt; 1
            password =&gt; &quot;123456&quot;
            data_type =&gt; &quot;channel&quot;
            key =&gt; &quot;/wefintek/education/website/logs/website-log&quot;
        }
    }
}
</code></pre>
<ul>
<li>补充file-input字段说明</li>
</ul>
<pre><code>codec =&gt; #可选项，默认是plain，可设置其他编码方式；
discover_interval =&gt; #可选项，logstash多久检查一下path下有新文件，默认15s；
exclude =&gt; #可选项，排除path下不想监听的文件；
sincedb_path =&gt; #可选项，记录文件以及文件读取信息位置的数据文件；
sincedb_write_interval =&gt; #可选项，logstash多久写一次sincedb文件，默认15s；
stat_interval =&gt; #可选项，logstash多久检查一次被监听文件的变化，默认1s；
start_position =&gt; #可选项，表示从哪个位置读取文件数据，初次导入为：beginning，最新数据为：end
path =&gt; #必选项，配置文件路径，可定义多个，也可模糊匹配；
tags =&gt; #可选项，在数据处理过程中，由具体的插件来添加或者删除的标记；
type =&gt; #可选项，当有多个file的时候，可用于一对一匹配输入或者输出；
</code></pre>
<ul>
<li>注意事项</li>
</ul>
<ol>
<li>logstash启动之后，进程会一直处于运行状态，若log文件被修改，程序会自动监听，导入新数据；</li>
<li>若需要重新导入数据，则需要删除logstash数据目录(path.data)下 plugins/inputs/file下的文件，所以直接删除该目录即可，之后目录会重新生成；</li>
<li>如果使用了模板覆盖，需要将模板的message字段设置成分词，否则无法有效进行分词全局搜索。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="一前言-1"><a class="header" href="#一前言-1">一、前言</a></h1>
<h2 id="1-elk简介-1"><a class="header" href="#1-elk简介-1">1. ELK简介</a></h2>
<p>ELK是Elasticsearch+Logstash+Kibana的简称</p>
<ul>
<li>
<p>ElasticSearch是一个基于Lucene的分布式全文搜索引擎，提供 RESTful API进行数据读写</p>
</li>
<li>
<p>Logstash是一个收集，处理和转发事件和日志消息的工具</p>
</li>
<li>
<p>Kibana是Elasticsearch的开源数据可视化插件，为查看存储在ElasticSearch提供了友好的Web界面，并提供了条形图，线条和散点图，饼图和地图等分析工具</p>
</li>
</ul>
<p>总的来说，ElasticSearch负责存储数据，Logstash负责收集日志，并将日志格式化后写入ElasticSearch，Kibana提供可视化访问ElasticSearch数据的功能。</p>
<h2 id="2elk工作流-1"><a class="header" href="#2elk工作流-1">2、ELK工作流</a></h2>
<p>ELK工作流</p>
<p>应用将日志按照约定的Key写入Redis，Logstash从Redis中读取日志信息写入ElasticSearch集群。Kibana读取ElasticSearch中的日志，并在Web页面中以表格/图表的形式展示。</p>
<h1 id="二准备工作-1"><a class="header" href="#二准备工作-1">二、准备工作</a></h1>
<h2 id="1服务器软件环境说明-1"><a class="header" href="#1服务器软件环境说明-1">1、服务器&amp;软件环境说明</a></h2>
<ul>
<li>服务器</li>
</ul>
<p>一共准备3台CentOS7 Server</p>
<p>es1	192.168.1.31	部署ElasticSearch主节点</p>
<p>es2	192.168.1.32	部署ElasticSearch从节点</p>
<p>elk	192.168.1.21	部署Logstash + Kibana + Redis</p>
<p>这里为了节省，只部署2台Elasticsearch，并将Logstash + Kibana + Redis部署在了一台机器上。
如果在生产环境部署，可以按照自己的需求调整。</p>
<ul>
<li>软件环境</li>
</ul>
<p>Linux Server	CentOS 7</p>
<p>Elasticsearch	7.0.0</p>
<p>Logstash	7.0.0</p>
<p>Kibana	7.0.0</p>
<p>Redis	4.0</p>
<p>JDK	1.8</p>
<h2 id="2elk环境准备-1"><a class="header" href="#2elk环境准备-1">2、ELK环境准备</a></h2>
<p>由于Elasticsearch、Logstash、Kibana均不能以root账号运行。
但是Linux对非root账号可并发操作的文件、线程都有限制。
所以，部署ELK相关的机器都要调整：</p>
<ul>
<li>修改文件限制</li>
</ul>
<pre><code># 修改系统文件
vi /etc/security/limits.conf

#增加的内容

* soft nofile 65536
* hard nofile 65536
* soft nproc 2048
* hard nproc 4096
</code></pre>
<ul>
<li>调整进程数</li>
</ul>
<pre><code>#修改系统文件
vi /etc/security/limits.d/20-nproc.conf
 
#调整成以下配置
*          soft    nproc     4096
root       soft    nproc     unlimited
</code></pre>
<ul>
<li>调整虚拟内存&amp;最大并发连接</li>
</ul>
<pre><code>#修改系统文件
vi /etc/sysctl.conf
 
#增加的内容
vm.max_map_count=655360
fs.file-max=655360
</code></pre>
<p>以上操作重启系统后生效</p>
<ul>
<li>JDK安装</li>
</ul>
<pre><code>rpm -iv jdk.rpm
</code></pre>
<ul>
<li>创建专用用户</li>
</ul>
<pre><code>useradd elk
</code></pre>
<ul>
<li>创建相关目录并赋权</li>
</ul>
<pre><code>#创建应用目录
mkdir /opt/elk
#创建数据目录
mkdir /elk
 
#更改目录拥有者
chown -R elk:elk /opt/elk
chown -R elk:elk /elk
</code></pre>
<ul>
<li>下载包并解压</li>
</ul>
<pre><code>#打开文件夹
cd /home/download
 
#下载
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.0.0.tar.gz
wget https://artifacts.elastic.co/downloads/logstash/logstash-7.0.0.tar.gz
wget https://artifacts.elastic.co/downloads/kibana/kibana-7.0.0.tar.gz
 
#解压
tar -zvxf elasticsearch-7.0.0.tar.gz
tar -zvxf logstash-7.0.0.tar.gz
tar -zvxf kibana-7.0.0.tar.gz
</code></pre>
<h1 id="三elasticsearch-部署-1"><a class="header" href="#三elasticsearch-部署-1">三、Elasticsearch 部署</a></h1>
<p>本次一共要部署两个Elasticsearch节点，所有文中没有指定机器的操作都表示每个Elasticsearch机器都要执行该操作</p>
<h2 id="1准备工作-3"><a class="header" href="#1准备工作-3">1、准备工作</a></h2>
<ul>
<li>移动Elasticsearch到统一目录</li>
</ul>
<pre><code>#移动目录
mv /home/download/elasticsearch-7.0.0 /opt/elk
#赋权
chown -R elk:elk /opt/elk/elasticsearch-7.0.0
</code></pre>
<ul>
<li>开放端口</li>
</ul>
<pre><code>#增加端口
firewall-cmd --add-port=9200/tcp --permanent
firewall-cmd --add-port=9300/tcp --permanent
 
#重新加载防火墙规则
firewall-cmd --reload
</code></pre>
<p>-切换账号</p>
<pre><code>su - elk
</code></pre>
<ul>
<li>数据&amp;日志目录</li>
</ul>
<pre><code>创建Elasticsearch主目录
mkdir /elk/es
#创建Elasticsearch数据目录
mkdir /elk/es/data
#创建Elasticsearch日志目录
mkdir /elk/es/logs
</code></pre>
<h2 id="2elasticsearch节点配置-1"><a class="header" href="#2elasticsearch节点配置-1">2、Elasticsearch节点配置</a></h2>
<ul>
<li>修改配置</li>
</ul>
<pre><code>#打开目录
cd /opt/elk/elasticsearch-7.0.0
 
#修改配置
 
vi config/elasticsearch.yml
</code></pre>
<ul>
<li>主节点配置（192.168.1.31）</li>
</ul>
<pre><code>cluster.name: es 
node.name: es1
path.data: /elk/es/data
path.logs: /elk/es/logs
network.host: 192.168.1.31
http.port: 9200
transport.tcp.port: 9300
node.master: true
node.data: true
discovery.zen.ping.unicast.hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;]
discovery.zen.minimum_master_nodes: 1
</code></pre>
<ul>
<li>从节点配置（192.168.1.32）</li>
</ul>
<pre><code>cluster.name: es 
node.name: es2
path.data: /elk/es/data
path.logs: /elk/es/logs
network.host: 192.168.1.32
http.port: 9200
transport.tcp.port: 9300
node.master: false
node.data: true
discovery.zen.ping.unicast.hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;]
discovery.zen.minimum_master_nodes: 1
</code></pre>
<ul>
<li>配置项说明</li>
</ul>
<pre><code>配置    说明
cluster.name	集群名
node.name	节点名
path.data	数据保存目录
path.logs	日志保存目录
network.host	节点host/ip
http.port	HTTP访问端口
transport.tcp.port	TCP传输端口
node.master	是否允许作为主节点
node.data	是否保存数据
discovery.zen.ping.unicast.hosts	集群中的主节点的初始列表,当节点(主节点或者数据节点)启动时使用这个列表进行探测
discovery.zen.minimum_master_nodes	主节点个数
</code></pre>
<h2 id="3elasticsearch启动健康检查-1"><a class="header" href="#3elasticsearch启动健康检查-1">3、Elasticsearch启动&amp;健康检查</a></h2>
<ul>
<li>启动</li>
</ul>
<pre><code>#进入elasticsearch根目录
cd /opt/elk/elasticsearch-7.0.0
#启动
./bin/elasticsearch
</code></pre>
<ul>
<li>查看健康状态</li>
</ul>
<pre><code>curl http://192.168.1.31:9200/_cluster/health
</code></pre>
<p>如果返回status=green表示正常</p>
<pre><code>{
  &quot;cluster_name&quot;: &quot;esc&quot;,
  &quot;status&quot;: &quot;green&quot;,
  &quot;timed_out&quot;: false,
  &quot;number_of_nodes&quot;: 2,
  &quot;number_of_data_nodes&quot;: 2,
  &quot;active_primary_shards&quot;: 0,
  &quot;active_shards&quot;: 0,
  &quot;relocating_shards&quot;: 0,
  &quot;initializing_shards&quot;: 0,
  &quot;unassigned_shards&quot;: 0,
  &quot;delayed_unassigned_shards&quot;: 0,
  &quot;number_of_pending_tasks&quot;: 0,
  &quot;number_of_in_flight_fetch&quot;: 0,
  &quot;task_max_waiting_in_queue_millis&quot;: 0,
  &quot;active_shards_percent_as_number&quot;: 100.0
}
</code></pre>
<h1 id="四logstash-部署-1"><a class="header" href="#四logstash-部署-1">四、Logstash 部署</a></h1>
<h2 id="1准备工作-4"><a class="header" href="#1准备工作-4">1、准备工作</a></h2>
<ul>
<li>
<p>部署Redis(略)</p>
</li>
<li>
<p>移动Logstash到统一目录</p>
</li>
</ul>
<pre><code>#移动目录
mv /home/download/logstash-7.0.0 /opt/elk
#赋权
chown -R elk:elk /opt/elk/logstash-7.0.0
</code></pre>
<ul>
<li>切换账号</li>
</ul>
<pre><code>#账号切换到 elk
su - elk
</code></pre>
<ul>
<li>数据&amp;日志目录</li>
</ul>
<pre><code>#创建Logstash主目录
mkdir /elk/logstash
#创建Logstash数据目录
mkdir /elk/logstash/data
#创建Logstash日志目录
mkdir /elk/logstash/logs
</code></pre>
<h2 id="2logstash配置-1"><a class="header" href="#2logstash配置-1">2、Logstash配置</a></h2>
<ul>
<li>配置数据&amp;日志目录</li>
</ul>
<pre><code>#打开目录
cd /opt/elk/logstash-7.0.0
#修改配置
vi config/logstash.yml
 
#增加以下内容
path.data: /elk/logstash/data
path.logs: /elk/logstash/logs
</code></pre>
<ul>
<li>配置Redis&amp;Elasticsearch</li>
</ul>
<pre><code>vi config/input-output.conf
 
#配置内容
 
input {
  redis {
    data_type =&gt; &quot;list&quot;
    key =&gt; &quot;logstash&quot;
    host =&gt; &quot;192.168.1.21&quot;
    port =&gt; 6379
    threads =&gt; 5
    codec =&gt; &quot;json&quot;
  }
}
filter {
}
output {
  elasticsearch {
    hosts =&gt; [&quot;192.168.1.31:9200&quot;,&quot;192.168.1.32:9200&quot;]
    index =&gt; &quot;logstash-%{type}-%{+YYYY.MM.dd}&quot;
    document_type =&gt; &quot;%{type}&quot;
  }
  stdout {
  }
}
</code></pre>
<p>该配置就是从redis中读取数据，然后写入指定的elasticsearch。
Redis核心配置项说明：</p>
<pre><code>配置项	说明
data_type =&gt; &quot;list&quot;	数据类型为list
key =&gt; &quot;logstash&quot;	缓存key为：logstash
codec =&gt; &quot;json&quot;	数据格式为：json
</code></pre>
<ul>
<li>启动</li>
</ul>
<pre><code>#进入Logstash根目录
cd /opt/elk/logstash-7.0.0
#测试
./bin/logstash -t -f config/input-output.conf
#启动
./bin/logstash -f config/input-output.conf
</code></pre>
<p>启动成功后，在启动输出的最后一行会看到如下信息：</p>
<pre><code>[INFO ][logstash.pipeline        ] Pipeline started {&quot;pipeline.id&quot;=&gt;&quot;main&quot;}
[INFO ][logstash.agent           ] Pipelines running {:count=&gt;1, :pipelines=&gt;[&quot;main&quot;]}
</code></pre>
<h1 id="五kibana-部署-1"><a class="header" href="#五kibana-部署-1">五、Kibana 部署</a></h1>
<h2 id="1准备工作-5"><a class="header" href="#1准备工作-5">1、准备工作</a></h2>
<ul>
<li>移动Kibana到统一目录</li>
</ul>
<pre><code>#移动目录
mv /home/download/kibana-7.0.0 /opt/elk/kibana-7.0.0
#赋权
chown -R elk:elk /usr/elk/kibana-7.0.0
</code></pre>
<ul>
<li>开放端口</li>
</ul>
<pre><code>#增加端口
firewall-cmd --add-port=5601/tcp --permanent
 
#重新加载防火墙规则
firewall-cmd --reload
</code></pre>
<ul>
<li>切换账号</li>
</ul>
<pre><code>#账号切换到 elk
su - elk
</code></pre>
<h2 id="3kibana配置与访问测试-1"><a class="header" href="#3kibana配置与访问测试-1">3、Kibana配置与访问测试</a></h2>
<ul>
<li>修改配置</li>
</ul>
<pre><code>#进入kibana-7.0.0根目录
cd /opt/elk/kibana-7.0.0
#修改配置
vi config/kibana.yml
 
#增加以下内容
server.port: 5601
server.host: &quot;192.168.1.21&quot;
elasticsearch.url: &quot;http://192.168.1.31:9200&quot; 
</code></pre>
<ul>
<li>启动</li>
</ul>
<pre><code>#进入kibana-7.0.0根目录
cd /opt/elk/kibana-7.0.0
#启动
./bin/kibana
</code></pre>
<ul>
<li>访问</li>
</ul>
<p>http://192.168.1.21:5601</p>
<h1 id="六测试-1"><a class="header" href="#六测试-1">六、测试</a></h1>
<h2 id="1日志写入-1"><a class="header" href="#1日志写入-1">1、日志写入</a></h2>
<p>日历写入的话，写入到logstash监听的redis即可。
数据类型之前在/opt/elk/logstash-7.0.0/config/input-uput.conf中有配置</p>
<ul>
<li>Redis命令方式</li>
</ul>
<pre><code>#启动redis客户端
#执行以下命令
lpush logstash '{&quot;host&quot;:&quot;127.0.0.1&quot;,&quot;type&quot;:&quot;logtest&quot;,&quot;message&quot;:&quot;hello&quot;}'
</code></pre>
<ul>
<li>Java代码批量写入（引入Jedis）</li>
</ul>
<pre><code>Jedis jedis = new Jedis(&quot;192.168.1.21&quot;, 6379);
for (int i = 0; i &lt; 1000; i++) {
    jedis.lpush(&quot;logstash&quot;, &quot;{\&quot;host\&quot;:\&quot;127.0.0.1\&quot;,\&quot;type\&quot;:\&quot;logtest\&quot;,\&quot;message\&quot;:\&quot;&quot; + i + &quot;\&quot;}&quot;);
}
</code></pre>
<h2 id="2kibana使用-1"><a class="header" href="#2kibana使用-1">2、Kibana使用</a></h2>
<pre><code>http://192.168.1.21:5601/app/kibana#/discover
</code></pre>
<h1 id="other-2"><a class="header" href="#other-2">Other</a></h1>
<h2 id="logstash配置-1"><a class="header" href="#logstash配置-1">Logstash配置</a></h2>
<ul>
<li>配置参数</li>
</ul>
<pre><code>file：顾名思义，直接读文件
stdin: 标准输入，调试配置的时候玩玩
syslog: syslog协议的日志格式，比如linux的rsyslog
tcp/udp：使用tcp或udp传输过来的日志
</code></pre>
<pre><code>path: 日志文件或目录的绝对路径，也可以是通配符的。
type: 类型，自定义
start_position: logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行。如果你是要导入原有数据，把这个设定改成 &quot;beginning&quot;，logstash 进程就从头开始读取，类似 less +F 的形式运行。
codec: codec配置，通过它可以更好更方便的与其他有自定义数据格式的运维产品共存，比如 graphite、fluent、netflow、collectd，以及使用 msgpack、json、edn 等通用数据格式的其他产品等。
</code></pre>
<ul>
<li>config.conf</li>
</ul>
<pre><code>input {
    file {
        #指定单一文件
        path =&gt; &quot;/data/es/logstash/files/test.log&quot;
        #指定数组文件
        #path =&gt; [&quot;/data/es/logstash/files/test-1.log&quot;,&quot;/data/es/logstash/files/test-2.log&quot;]
        #指定同级目录模糊匹配
        #path =&gt; &quot;/data/es/logstash/files/test*.log&quot;
        #指定多级目录模糊匹配
        #path =&gt; &quot;/data/es/logstash/files/**/test*.log&quot;

        #当存在多个文件的时候可使用type指定输入输出路径
        type =&gt; &quot;log_index&quot;
        
        #可设置成begining或end，begining表示从头开始读取文件，end表示读取最新数据，可和ignore_older一起使用
        #begining只针对首次启动是否需要读取所有的历史数据，而当文件修改了之后，同样会自动增量更新新数据
        start_position =&gt; &quot;beginning&quot;

        #设置输入规则
        codec =&gt; multiline {
            #利用正则匹配规则，匹配每一行开始的位置，这里匹配每一行开始的位置为数字
            pattern =&gt; &quot;^[0-9]&quot;
     
            #true表示不匹配正则表达式，false为匹配正则表达式，默认false
            #如果不匹配，则会结合what参数，进行合并操作
            negate =&gt; true
            
            #what可设置previous和next，previous则表示将所有不匹配的数据都合并到上一个正则事件
            #而next则相反，将所有的不匹配的数据都合并到下一个正则事件
            what =&gt; &quot;previous&quot;
 
            #表示当多长时间没有新的数据，最后一个正则匹配积累的多行数据都归属为最后一个事件，这里的10表示10秒
            #auto_flush_interval =&gt; 10
       }
    }
    tcp {
        port =&gt; 8888
        mode =&gt; &quot;server&quot;
        ssl_enable =&gt; false
    }
}
filter {
    grok {
        match =&gt; {
            &quot;message&quot; =&gt; &quot;%{IPORHOST:clientip} - - \[%{HTTPDATE:request_time}\] \&quot;(?:%{WORD:method} %{URIPATH:url}(?:%{URIPARAM:params})?(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\&quot; %{NUMBER:status} (?:%{NUMBER:bytes:int}|-) \&quot;%{DATA:referrer}\&quot; \&quot;%{DATA:agent}\&quot;&quot;
        }
    }
    ruby{
        init =&gt; &quot;@kname = ['client','servername','url','status','time','size','upstream','upstreamstatus','upstreamtime','referer','xff','useragent']&quot;
        code =&gt; &quot;
            new_event = LogStash::Event.new(Hash[@kname.zip(event.get('message').split('|'))])
            new_event.remove('@timestamp')
            event.append(new_event)&quot;
    }
}
output {
    #输出控制台
    stdout {
        #codec =&gt; json
    }

    #输出到elasticsearch
    if [type] == &quot;log_index&quot; {
        elasticsearch {
            hosts =&gt; [&quot;192.168.1.31:9200&quot;,&quot;192.168.1.32:9200&quot;]
            
            #以当前的日期作为index和type
            #index =&gt; &quot;log-%{+YYYY.MM.dd}&quot;
            index =&gt; &quot;%{type}-%{+YYYY.MM.dd}&quot;
            document_type =&gt; &quot;%{type}-%{+YYYY.MM.dd}&quot;
            
            #覆盖模板
            #template_overwrite =&gt; true
            #template =&gt; &quot;/elk/es/logstash/template/logstash.json&quot;
        }
    }

    #输出到文件
    if [type] == &quot;log_file&quot; {
        file {
            path =&gt; &quot;/elk/logstash/logs/website-%{+YYYY.MM.dd}.log&quot;
            flush_interval =&gt; 0
        }
    }

    #输出到Redis
    if [type] == &quot;log_redis&quot; {
        redis {
            host =&gt; &quot;192.168.11.5&quot;
            port =&gt; 7890
            db =&gt; 1
            password =&gt; &quot;123456&quot;
            data_type =&gt; &quot;channel&quot;
            key =&gt; &quot;/wefintek/education/website/logs/website-log&quot;
        }
    }
}
</code></pre>
<ul>
<li>补充file-input字段说明</li>
</ul>
<pre><code>codec =&gt; #可选项，默认是plain，可设置其他编码方式；
discover_interval =&gt; #可选项，logstash多久检查一下path下有新文件，默认15s；
exclude =&gt; #可选项，排除path下不想监听的文件；
sincedb_path =&gt; #可选项，记录文件以及文件读取信息位置的数据文件；
sincedb_write_interval =&gt; #可选项，logstash多久写一次sincedb文件，默认15s；
stat_interval =&gt; #可选项，logstash多久检查一次被监听文件的变化，默认1s；
start_position =&gt; #可选项，表示从哪个位置读取文件数据，初次导入为：beginning，最新数据为：end
path =&gt; #必选项，配置文件路径，可定义多个，也可模糊匹配；
tags =&gt; #可选项，在数据处理过程中，由具体的插件来添加或者删除的标记；
type =&gt; #可选项，当有多个file的时候，可用于一对一匹配输入或者输出；
</code></pre>
<ul>
<li>注意事项</li>
</ul>
<ol>
<li>logstash启动之后，进程会一直处于运行状态，若log文件被修改，程序会自动监听，导入新数据；</li>
<li>若需要重新导入数据，则需要删除logstash数据目录(path.data)下 plugins/inputs/file下的文件，所以直接删除该目录即可，之后目录会重新生成；</li>
<li>如果使用了模板覆盖，需要将模板的message字段设置成分词，否则无法有效进行分词全局搜索。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="一前言-2"><a class="header" href="#一前言-2">一、前言</a></h1>
<h2 id="1-elk简介-2"><a class="header" href="#1-elk简介-2">1. ELK简介</a></h2>
<p>ELK是Elasticsearch+Logstash+Kibana的简称</p>
<ul>
<li>
<p>ElasticSearch是一个基于Lucene的分布式全文搜索引擎，提供 RESTful API进行数据读写</p>
</li>
<li>
<p>Logstash是一个收集，处理和转发事件和日志消息的工具</p>
</li>
<li>
<p>Kibana是Elasticsearch的开源数据可视化插件，为查看存储在ElasticSearch提供了友好的Web界面，并提供了条形图，线条和散点图，饼图和地图等分析工具</p>
</li>
</ul>
<p>总的来说，ElasticSearch负责存储数据，Logstash负责收集日志，并将日志格式化后写入ElasticSearch，Kibana提供可视化访问ElasticSearch数据的功能。</p>
<h2 id="2elk工作流-2"><a class="header" href="#2elk工作流-2">2、ELK工作流</a></h2>
<p>ELK工作流</p>
<p>应用将日志按照约定的Key写入Redis，Logstash从Redis中读取日志信息写入ElasticSearch集群。Kibana读取ElasticSearch中的日志，并在Web页面中以表格/图表的形式展示。</p>
<h1 id="二准备工作-2"><a class="header" href="#二准备工作-2">二、准备工作</a></h1>
<h2 id="1服务器软件环境说明-2"><a class="header" href="#1服务器软件环境说明-2">1、服务器&amp;软件环境说明</a></h2>
<ul>
<li>服务器</li>
</ul>
<p>一共准备3台CentOS7 Server</p>
<p>es1	192.168.1.31	部署ElasticSearch主节点</p>
<p>es2	192.168.1.32	部署ElasticSearch从节点</p>
<p>elk	192.168.1.21	部署Logstash + Kibana + Redis</p>
<p>这里为了节省，只部署2台Elasticsearch，并将Logstash + Kibana + Redis部署在了一台机器上。
如果在生产环境部署，可以按照自己的需求调整。</p>
<ul>
<li>软件环境</li>
</ul>
<p>Linux Server	CentOS 7</p>
<p>Elasticsearch	7.0.0</p>
<p>Logstash	7.0.0</p>
<p>Kibana	7.0.0</p>
<p>Redis	4.0</p>
<p>JDK	1.8</p>
<h2 id="2elk环境准备-2"><a class="header" href="#2elk环境准备-2">2、ELK环境准备</a></h2>
<p>由于Elasticsearch、Logstash、Kibana均不能以root账号运行。
但是Linux对非root账号可并发操作的文件、线程都有限制。
所以，部署ELK相关的机器都要调整：</p>
<ul>
<li>修改文件限制</li>
</ul>
<pre><code># 修改系统文件
vi /etc/security/limits.conf

#增加的内容

* soft nofile 65536
* hard nofile 65536
* soft nproc 2048
* hard nproc 4096
</code></pre>
<ul>
<li>调整进程数</li>
</ul>
<pre><code>#修改系统文件
vi /etc/security/limits.d/20-nproc.conf
 
#调整成以下配置
*          soft    nproc     4096
root       soft    nproc     unlimited
</code></pre>
<ul>
<li>调整虚拟内存&amp;最大并发连接</li>
</ul>
<pre><code>#修改系统文件
vi /etc/sysctl.conf
 
#增加的内容
vm.max_map_count=655360
fs.file-max=655360
</code></pre>
<p>以上操作重启系统后生效</p>
<ul>
<li>JDK安装</li>
</ul>
<pre><code>rpm -iv jdk.rpm
</code></pre>
<ul>
<li>创建专用用户</li>
</ul>
<pre><code>useradd elk
</code></pre>
<ul>
<li>创建相关目录并赋权</li>
</ul>
<pre><code>#创建应用目录
mkdir /opt/elk
#创建数据目录
mkdir /elk
 
#更改目录拥有者
chown -R elk:elk /opt/elk
chown -R elk:elk /elk
</code></pre>
<ul>
<li>下载包并解压</li>
</ul>
<pre><code>#打开文件夹
cd /home/download
 
#下载
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.0.0.tar.gz
wget https://artifacts.elastic.co/downloads/logstash/logstash-7.0.0.tar.gz
wget https://artifacts.elastic.co/downloads/kibana/kibana-7.0.0.tar.gz
 
#解压
tar -zvxf elasticsearch-7.0.0.tar.gz
tar -zvxf logstash-7.0.0.tar.gz
tar -zvxf kibana-7.0.0.tar.gz
</code></pre>
<h1 id="三elasticsearch-部署-2"><a class="header" href="#三elasticsearch-部署-2">三、Elasticsearch 部署</a></h1>
<p>本次一共要部署两个Elasticsearch节点，所有文中没有指定机器的操作都表示每个Elasticsearch机器都要执行该操作</p>
<h2 id="1准备工作-6"><a class="header" href="#1准备工作-6">1、准备工作</a></h2>
<ul>
<li>移动Elasticsearch到统一目录</li>
</ul>
<pre><code>#移动目录
mv /home/download/elasticsearch-7.0.0 /opt/elk
#赋权
chown -R elk:elk /opt/elk/elasticsearch-7.0.0
</code></pre>
<ul>
<li>开放端口</li>
</ul>
<pre><code>#增加端口
firewall-cmd --add-port=9200/tcp --permanent
firewall-cmd --add-port=9300/tcp --permanent
 
#重新加载防火墙规则
firewall-cmd --reload
</code></pre>
<p>-切换账号</p>
<pre><code>su - elk
</code></pre>
<ul>
<li>数据&amp;日志目录</li>
</ul>
<pre><code>创建Elasticsearch主目录
mkdir /elk/es
#创建Elasticsearch数据目录
mkdir /elk/es/data
#创建Elasticsearch日志目录
mkdir /elk/es/logs
</code></pre>
<h2 id="2elasticsearch节点配置-2"><a class="header" href="#2elasticsearch节点配置-2">2、Elasticsearch节点配置</a></h2>
<ul>
<li>修改配置</li>
</ul>
<pre><code>#打开目录
cd /opt/elk/elasticsearch-7.0.0
 
#修改配置
 
vi config/elasticsearch.yml
</code></pre>
<ul>
<li>主节点配置（192.168.1.31）</li>
</ul>
<pre><code>cluster.name: es 
node.name: es1
path.data: /elk/es/data
path.logs: /elk/es/logs
network.host: 192.168.1.31
http.port: 9200
transport.tcp.port: 9300
node.master: true
node.data: true
discovery.zen.ping.unicast.hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;]
discovery.zen.minimum_master_nodes: 1
</code></pre>
<ul>
<li>从节点配置（192.168.1.32）</li>
</ul>
<pre><code>cluster.name: es 
node.name: es2
path.data: /elk/es/data
path.logs: /elk/es/logs
network.host: 192.168.1.32
http.port: 9200
transport.tcp.port: 9300
node.master: false
node.data: true
discovery.zen.ping.unicast.hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;]
discovery.zen.minimum_master_nodes: 1
</code></pre>
<ul>
<li>配置项说明</li>
</ul>
<pre><code>配置    说明
cluster.name	集群名
node.name	节点名
path.data	数据保存目录
path.logs	日志保存目录
network.host	节点host/ip
http.port	HTTP访问端口
transport.tcp.port	TCP传输端口
node.master	是否允许作为主节点
node.data	是否保存数据
discovery.zen.ping.unicast.hosts	集群中的主节点的初始列表,当节点(主节点或者数据节点)启动时使用这个列表进行探测
discovery.zen.minimum_master_nodes	主节点个数
</code></pre>
<h2 id="3elasticsearch启动健康检查-2"><a class="header" href="#3elasticsearch启动健康检查-2">3、Elasticsearch启动&amp;健康检查</a></h2>
<ul>
<li>启动</li>
</ul>
<pre><code>#进入elasticsearch根目录
cd /opt/elk/elasticsearch-7.0.0
#启动
./bin/elasticsearch
</code></pre>
<ul>
<li>查看健康状态</li>
</ul>
<pre><code>curl http://192.168.1.31:9200/_cluster/health
</code></pre>
<p>如果返回status=green表示正常</p>
<pre><code>{
  &quot;cluster_name&quot;: &quot;esc&quot;,
  &quot;status&quot;: &quot;green&quot;,
  &quot;timed_out&quot;: false,
  &quot;number_of_nodes&quot;: 2,
  &quot;number_of_data_nodes&quot;: 2,
  &quot;active_primary_shards&quot;: 0,
  &quot;active_shards&quot;: 0,
  &quot;relocating_shards&quot;: 0,
  &quot;initializing_shards&quot;: 0,
  &quot;unassigned_shards&quot;: 0,
  &quot;delayed_unassigned_shards&quot;: 0,
  &quot;number_of_pending_tasks&quot;: 0,
  &quot;number_of_in_flight_fetch&quot;: 0,
  &quot;task_max_waiting_in_queue_millis&quot;: 0,
  &quot;active_shards_percent_as_number&quot;: 100.0
}
</code></pre>
<h1 id="四logstash-部署-2"><a class="header" href="#四logstash-部署-2">四、Logstash 部署</a></h1>
<h2 id="1准备工作-7"><a class="header" href="#1准备工作-7">1、准备工作</a></h2>
<ul>
<li>
<p>部署Redis(略)</p>
</li>
<li>
<p>移动Logstash到统一目录</p>
</li>
</ul>
<pre><code>#移动目录
mv /home/download/logstash-7.0.0 /opt/elk
#赋权
chown -R elk:elk /opt/elk/logstash-7.0.0
</code></pre>
<ul>
<li>切换账号</li>
</ul>
<pre><code>#账号切换到 elk
su - elk
</code></pre>
<ul>
<li>数据&amp;日志目录</li>
</ul>
<pre><code>#创建Logstash主目录
mkdir /elk/logstash
#创建Logstash数据目录
mkdir /elk/logstash/data
#创建Logstash日志目录
mkdir /elk/logstash/logs
</code></pre>
<h2 id="2logstash配置-2"><a class="header" href="#2logstash配置-2">2、Logstash配置</a></h2>
<ul>
<li>配置数据&amp;日志目录</li>
</ul>
<pre><code>#打开目录
cd /opt/elk/logstash-7.0.0
#修改配置
vi config/logstash.yml
 
#增加以下内容
path.data: /elk/logstash/data
path.logs: /elk/logstash/logs
</code></pre>
<ul>
<li>配置Redis&amp;Elasticsearch</li>
</ul>
<pre><code>vi config/input-output.conf
 
#配置内容
 
input {
  redis {
    data_type =&gt; &quot;list&quot;
    key =&gt; &quot;logstash&quot;
    host =&gt; &quot;192.168.1.21&quot;
    port =&gt; 6379
    threads =&gt; 5
    codec =&gt; &quot;json&quot;
  }
}
filter {
}
output {
  elasticsearch {
    hosts =&gt; [&quot;192.168.1.31:9200&quot;,&quot;192.168.1.32:9200&quot;]
    index =&gt; &quot;logstash-%{type}-%{+YYYY.MM.dd}&quot;
    document_type =&gt; &quot;%{type}&quot;
  }
  stdout {
  }
}
</code></pre>
<p>该配置就是从redis中读取数据，然后写入指定的elasticsearch。
Redis核心配置项说明：</p>
<pre><code>配置项	说明
data_type =&gt; &quot;list&quot;	数据类型为list
key =&gt; &quot;logstash&quot;	缓存key为：logstash
codec =&gt; &quot;json&quot;	数据格式为：json
</code></pre>
<ul>
<li>启动</li>
</ul>
<pre><code>#进入Logstash根目录
cd /opt/elk/logstash-7.0.0
#测试
./bin/logstash -t -f config/input-output.conf
#启动
./bin/logstash -f config/input-output.conf
</code></pre>
<p>启动成功后，在启动输出的最后一行会看到如下信息：</p>
<pre><code>[INFO ][logstash.pipeline        ] Pipeline started {&quot;pipeline.id&quot;=&gt;&quot;main&quot;}
[INFO ][logstash.agent           ] Pipelines running {:count=&gt;1, :pipelines=&gt;[&quot;main&quot;]}
</code></pre>
<h1 id="五kibana-部署-2"><a class="header" href="#五kibana-部署-2">五、Kibana 部署</a></h1>
<h2 id="1准备工作-8"><a class="header" href="#1准备工作-8">1、准备工作</a></h2>
<ul>
<li>移动Kibana到统一目录</li>
</ul>
<pre><code>#移动目录
mv /home/download/kibana-7.0.0 /opt/elk/kibana-7.0.0
#赋权
chown -R elk:elk /usr/elk/kibana-7.0.0
</code></pre>
<ul>
<li>开放端口</li>
</ul>
<pre><code>#增加端口
firewall-cmd --add-port=5601/tcp --permanent
 
#重新加载防火墙规则
firewall-cmd --reload
</code></pre>
<ul>
<li>切换账号</li>
</ul>
<pre><code>#账号切换到 elk
su - elk
</code></pre>
<h2 id="3kibana配置与访问测试-2"><a class="header" href="#3kibana配置与访问测试-2">3、Kibana配置与访问测试</a></h2>
<ul>
<li>修改配置</li>
</ul>
<pre><code>#进入kibana-7.0.0根目录
cd /opt/elk/kibana-7.0.0
#修改配置
vi config/kibana.yml
 
#增加以下内容
server.port: 5601
server.host: &quot;192.168.1.21&quot;
elasticsearch.url: &quot;http://192.168.1.31:9200&quot; 
</code></pre>
<ul>
<li>启动</li>
</ul>
<pre><code>#进入kibana-7.0.0根目录
cd /opt/elk/kibana-7.0.0
#启动
./bin/kibana
</code></pre>
<ul>
<li>访问</li>
</ul>
<p>http://192.168.1.21:5601</p>
<h1 id="六测试-2"><a class="header" href="#六测试-2">六、测试</a></h1>
<h2 id="1日志写入-2"><a class="header" href="#1日志写入-2">1、日志写入</a></h2>
<p>日历写入的话，写入到logstash监听的redis即可。
数据类型之前在/opt/elk/logstash-7.0.0/config/input-uput.conf中有配置</p>
<ul>
<li>Redis命令方式</li>
</ul>
<pre><code>#启动redis客户端
#执行以下命令
lpush logstash '{&quot;host&quot;:&quot;127.0.0.1&quot;,&quot;type&quot;:&quot;logtest&quot;,&quot;message&quot;:&quot;hello&quot;}'
</code></pre>
<ul>
<li>Java代码批量写入（引入Jedis）</li>
</ul>
<pre><code>Jedis jedis = new Jedis(&quot;192.168.1.21&quot;, 6379);
for (int i = 0; i &lt; 1000; i++) {
    jedis.lpush(&quot;logstash&quot;, &quot;{\&quot;host\&quot;:\&quot;127.0.0.1\&quot;,\&quot;type\&quot;:\&quot;logtest\&quot;,\&quot;message\&quot;:\&quot;&quot; + i + &quot;\&quot;}&quot;);
}
</code></pre>
<h2 id="2kibana使用-2"><a class="header" href="#2kibana使用-2">2、Kibana使用</a></h2>
<pre><code>http://192.168.1.21:5601/app/kibana#/discover
</code></pre>
<h1 id="other-3"><a class="header" href="#other-3">Other</a></h1>
<h2 id="logstash配置-2"><a class="header" href="#logstash配置-2">Logstash配置</a></h2>
<ul>
<li>配置参数</li>
</ul>
<pre><code>file：顾名思义，直接读文件
stdin: 标准输入，调试配置的时候玩玩
syslog: syslog协议的日志格式，比如linux的rsyslog
tcp/udp：使用tcp或udp传输过来的日志
</code></pre>
<pre><code>path: 日志文件或目录的绝对路径，也可以是通配符的。
type: 类型，自定义
start_position: logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行。如果你是要导入原有数据，把这个设定改成 &quot;beginning&quot;，logstash 进程就从头开始读取，类似 less +F 的形式运行。
codec: codec配置，通过它可以更好更方便的与其他有自定义数据格式的运维产品共存，比如 graphite、fluent、netflow、collectd，以及使用 msgpack、json、edn 等通用数据格式的其他产品等。
</code></pre>
<ul>
<li>config.conf</li>
</ul>
<pre><code>input {
    file {
        #指定单一文件
        path =&gt; &quot;/data/es/logstash/files/test.log&quot;
        #指定数组文件
        #path =&gt; [&quot;/data/es/logstash/files/test-1.log&quot;,&quot;/data/es/logstash/files/test-2.log&quot;]
        #指定同级目录模糊匹配
        #path =&gt; &quot;/data/es/logstash/files/test*.log&quot;
        #指定多级目录模糊匹配
        #path =&gt; &quot;/data/es/logstash/files/**/test*.log&quot;

        #当存在多个文件的时候可使用type指定输入输出路径
        type =&gt; &quot;log_index&quot;
        
        #可设置成begining或end，begining表示从头开始读取文件，end表示读取最新数据，可和ignore_older一起使用
        #begining只针对首次启动是否需要读取所有的历史数据，而当文件修改了之后，同样会自动增量更新新数据
        start_position =&gt; &quot;beginning&quot;

        #设置输入规则
        codec =&gt; multiline {
            #利用正则匹配规则，匹配每一行开始的位置，这里匹配每一行开始的位置为数字
            pattern =&gt; &quot;^[0-9]&quot;
     
            #true表示不匹配正则表达式，false为匹配正则表达式，默认false
            #如果不匹配，则会结合what参数，进行合并操作
            negate =&gt; true
            
            #what可设置previous和next，previous则表示将所有不匹配的数据都合并到上一个正则事件
            #而next则相反，将所有的不匹配的数据都合并到下一个正则事件
            what =&gt; &quot;previous&quot;
 
            #表示当多长时间没有新的数据，最后一个正则匹配积累的多行数据都归属为最后一个事件，这里的10表示10秒
            #auto_flush_interval =&gt; 10
       }
    }
    tcp {
        port =&gt; 8888
        mode =&gt; &quot;server&quot;
        ssl_enable =&gt; false
    }
}
filter {
    grok {
        match =&gt; {
            &quot;message&quot; =&gt; &quot;%{IPORHOST:clientip} - - \[%{HTTPDATE:request_time}\] \&quot;(?:%{WORD:method} %{URIPATH:url}(?:%{URIPARAM:params})?(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\&quot; %{NUMBER:status} (?:%{NUMBER:bytes:int}|-) \&quot;%{DATA:referrer}\&quot; \&quot;%{DATA:agent}\&quot;&quot;
        }
    }
    ruby{
        init =&gt; &quot;@kname = ['client','servername','url','status','time','size','upstream','upstreamstatus','upstreamtime','referer','xff','useragent']&quot;
        code =&gt; &quot;
            new_event = LogStash::Event.new(Hash[@kname.zip(event.get('message').split('|'))])
            new_event.remove('@timestamp')
            event.append(new_event)&quot;
    }
}
output {
    #输出控制台
    stdout {
        #codec =&gt; json
    }

    #输出到elasticsearch
    if [type] == &quot;log_index&quot; {
        elasticsearch {
            hosts =&gt; [&quot;192.168.1.31:9200&quot;,&quot;192.168.1.32:9200&quot;]
            
            #以当前的日期作为index和type
            #index =&gt; &quot;log-%{+YYYY.MM.dd}&quot;
            index =&gt; &quot;%{type}-%{+YYYY.MM.dd}&quot;
            document_type =&gt; &quot;%{type}-%{+YYYY.MM.dd}&quot;
            
            #覆盖模板
            #template_overwrite =&gt; true
            #template =&gt; &quot;/elk/es/logstash/template/logstash.json&quot;
        }
    }

    #输出到文件
    if [type] == &quot;log_file&quot; {
        file {
            path =&gt; &quot;/elk/logstash/logs/website-%{+YYYY.MM.dd}.log&quot;
            flush_interval =&gt; 0
        }
    }

    #输出到Redis
    if [type] == &quot;log_redis&quot; {
        redis {
            host =&gt; &quot;192.168.11.5&quot;
            port =&gt; 7890
            db =&gt; 1
            password =&gt; &quot;123456&quot;
            data_type =&gt; &quot;channel&quot;
            key =&gt; &quot;/wefintek/education/website/logs/website-log&quot;
        }
    }
}
</code></pre>
<ul>
<li>补充file-input字段说明</li>
</ul>
<pre><code>codec =&gt; #可选项，默认是plain，可设置其他编码方式；
discover_interval =&gt; #可选项，logstash多久检查一下path下有新文件，默认15s；
exclude =&gt; #可选项，排除path下不想监听的文件；
sincedb_path =&gt; #可选项，记录文件以及文件读取信息位置的数据文件；
sincedb_write_interval =&gt; #可选项，logstash多久写一次sincedb文件，默认15s；
stat_interval =&gt; #可选项，logstash多久检查一次被监听文件的变化，默认1s；
start_position =&gt; #可选项，表示从哪个位置读取文件数据，初次导入为：beginning，最新数据为：end
path =&gt; #必选项，配置文件路径，可定义多个，也可模糊匹配；
tags =&gt; #可选项，在数据处理过程中，由具体的插件来添加或者删除的标记；
type =&gt; #可选项，当有多个file的时候，可用于一对一匹配输入或者输出；
</code></pre>
<ul>
<li>注意事项</li>
</ul>
<ol>
<li>logstash启动之后，进程会一直处于运行状态，若log文件被修改，程序会自动监听，导入新数据；</li>
<li>若需要重新导入数据，则需要删除logstash数据目录(path.data)下 plugins/inputs/file下的文件，所以直接删除该目录即可，之后目录会重新生成；</li>
<li>如果使用了模板覆盖，需要将模板的message字段设置成分词，否则无法有效进行分词全局搜索。</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="conda"><a class="header" href="#conda">conda</a></h1>
<h2 id="use-channels"><a class="header" href="#use-channels">use channels</a></h2>
<pre><code>conda install -c https://mirrors.aliyun.com/anaconda/pkgs/free numpy
</code></pre>
<h2 id="add-channels"><a class="header" href="#add-channels">add channels</a></h2>
<pre><code>conda config --add channels https://mirrors.aliyun.com/anaconda/pkgs/free
</code></pre>
<h2 id="clean-cache"><a class="header" href="#clean-cache">clean cache</a></h2>
<pre><code>conda clean --all
</code></pre>
<h2 id="docker-image"><a class="header" href="#docker-image">docker image</a></h2>
<pre><code>FROM irepoing/debian:base

WORKDIR /root

COPY Miniconda.sh Miniconda.sh

RUN bash Miniconda.sh -b -p /opt/miniconda \
    &amp;&amp; /opt/miniconda/bin/conda init \
    &amp;&amp; /opt/miniconda/bin/conda clean --all \
    &amp;&amp; bash &amp;&amp; rm Miniconda.sh

ENV PATH=$PATH:/opt/miniconda/bin
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="conda-1"><a class="header" href="#conda-1">conda</a></h1>
<h2 id="use-channels-1"><a class="header" href="#use-channels-1">use channels</a></h2>
<pre><code>conda install -c https://mirrors.aliyun.com/anaconda/pkgs/free numpy
</code></pre>
<h2 id="add-channels-1"><a class="header" href="#add-channels-1">add channels</a></h2>
<pre><code>conda config --add channels https://mirrors.aliyun.com/anaconda/pkgs/free
</code></pre>
<h2 id="clean-cache-1"><a class="header" href="#clean-cache-1">clean cache</a></h2>
<pre><code>conda clean --all
</code></pre>
<h2 id="docker-image-1"><a class="header" href="#docker-image-1">docker image</a></h2>
<pre><code>FROM irepoing/debian:base

WORKDIR /root

COPY Miniconda.sh Miniconda.sh

RUN bash Miniconda.sh -b -p /opt/miniconda \
    &amp;&amp; /opt/miniconda/bin/conda init \
    &amp;&amp; /opt/miniconda/bin/conda clean --all \
    &amp;&amp; bash &amp;&amp; rm Miniconda.sh

ENV PATH=$PATH:/opt/miniconda/bin
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="definition"><a class="header" href="#definition">Definition</a></h1>
<h2 id="闭包"><a class="header" href="#闭包">闭包</a></h2>
<p>如果一个函数定义在另一个函数的作用域内，并且引用了外层函数的变量，则该函数称为闭包。闭包是Python所支持的一种特性，它让在非global scope定义的函数可以引用其外围空间中的变量，这些外围空间中被引用的变量叫做这个函数的环境变量。环境变量和这个非全局函数一起构成了闭包。</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="包与模块"><a class="header" href="#包与模块">包与模块</a></h3>
<p>在了解import之前，有两个概念必须提一下：</p>
<ul>
<li>包:</li>
</ul>
<p>__init__.py 文件所在目录就是包（package）</p>
<ul>
<li>模块:</li>
</ul>
<p>一个 .py 文件就是一个模块（module）</p>
<p>当然，这只是极简版的概念。实际上包是一种特殊的模块，而任何定义了 __path__ 属性的模块都被当做包。只不过，咱们日常使用中并不需要知道这些。</p>
<h3 id="两种形式的-import"><a class="header" href="#两种形式的-import">两种形式的 import</a></h3>
<ul>
<li>import有两种形式：</li>
</ul>
<p>import ...</p>
<p>from ... import ...</p>
<p>两者有着很细微的区别，先看几行代码。</p>
<pre><code class="language-buildoutcfg">from string import ascii_lowercase
import string
import string.ascii_lowercase
</code></pre>
<p>运行后发现最后一行代码报错：ImportError: No module named ascii_lowercase，意思是：“找不到叫 ascii_lowercase 的模块”。第 1 行和第 3 行的区别只在于有没有 from，翻翻语法定义发现有这样的规则：</p>
<ul>
<li>
<p>import ... 后面只能是包或模块。</p>
</li>
<li>
<p>from ... import ... from后面只能是包或模块，import 后面可以是任何变量。</p>
</li>
</ul>
<p>可以简单的记成：第一个空只能填包或模块，第二个空填啥都行。</p>
<h3 id="import的搜索路径"><a class="header" href="#import的搜索路径">import的搜索路径</a></h3>
<p>提问，下面这几行代码的输出结果是多少？</p>
<pre><code class="language-buildoutcfg"># foo.py
import string
print(string.ascii_lowercase)
</code></pre>
<p>是小写字母吗？那可不一定，如果目录树是这样的：</p>
<pre><code class="language-buildoutcfg">./
├── foo.py
└── string.py
</code></pre>
<p>foo.py 所在目录有叫 string.py 的文件，结果就不确定了。因为你不知道 import string 到底是 import 了 ./string.py 还是标准库的 string。
为了回答这个问题，我们得了解一下 import 是怎么找到模块的，这个过程比较简单，只有两个步骤：</p>
<ol>
<li>搜索「内置模块」（built-in module）</li>
<li>搜索 sys.path 中的路径</li>
</ol>
<p>而 sys.path 在初始化时，又会按照顺序添加以下路径：</p>
<ol>
<li>foo.py 所在目录（如果是软链接，那么是真正的 foo.py 所在目录）或当前目录；</li>
<li>环境变量 PYTHONPATH中列出的目录（类似环境变量 PATH，由用户定义，默认为空）；</li>
<li>site 模块被 import 时添加的路径1（site 会在运行时被自动 import）。</li>
</ol>
<p>import site 所添加的路径一般是 XXX/site-packages（Ubuntu 上是 XXX/dist-packages），比如在我的机器上是 /usr/local/lib/pythonx.x/site-packages。
同时，通过 pip 安装的包也是保存在这个目录下的。如果懒得记 sys.path 的初始化过程，可以简单的认为 import 的查找顺序是：</p>
<ol>
<li>内置模块</li>
<li>.py 文件所在目录</li>
<li>pip 或 easy_install 安装的包</li>
</ol>
<p>回到前面的问题，因为 import string 是通过搜寻 foo.py 文件所在目录，找到 string.py 后 import 的，所以输出取决于 import string.py 时执行的代码。</p>
<h3 id="相对-import-与-绝对-import"><a class="header" href="#相对-import-与-绝对-import">相对 import 与 绝对 import</a></h3>
<h4 id="相对-import"><a class="header" href="#相对-import">相对 import</a></h4>
<p>当项目规模变大，代码复杂度上升的时候，我们通常会把一个一个的 .py 文件组织成一个包，让项目结构更加清晰。这时候 import 又会出现一些问题，比如：一个典型包的目录结构是这样的：</p>
<pre><code class="language-buildoutcfg">string/
├── __init__.py
├── find.py
└── foo.py
</code></pre>
<p>如果 string/foo.py 的代码如下：</p>
<pre><code class="language-buildoutcfg"># string/foo.py
from string import find
print(find)
</code></pre>
<p>那么 python string/foo.py 的运行结果会是下面的哪一个呢？</p>
<ul>
<li>&lt;module 'string.find' from 'string/find.py'&gt;</li>
<li>&lt;function find at 0x123456789&gt;</li>
</ul>
<p>按我们前面讲的各种规则来推导，因为 foo.py 所在目录 string/ 没有 string 模块（即 string.py），所以 import 的是标准库的 string，答案是后者。不过，如果你把 foo 当成 string 包中的模块运行，即 python -m string.foo，会发现运行结果是前者。同样的语句，却有着两种不同的语义，这无疑加重了咱们的心智负担，总不能每次咱们调试包里的模块时，都去检查一下执行的命令是 python string/foo.py 还是 python -m string.foo 吧？</p>
<p>相对 import 就是专为解决「包内导入」（intra-package import）而出现的。它的使用也很简单，from 的后面跟个 . 就行：</p>
<pre><code class="language-buildoutcfg">from .XXX import ...
</code></pre>
<p>比如：</p>
<pre><code class="language-buildoutcfg"># from string/ import find.py
from . import find
# from string/find.py import *
from .find import *
</code></pre>
<p>我们再看个复杂点的例子，有个包的目录结构长这样：</p>
<pre><code class="language-buildoutcfg">one/
├── __init__.py
├── foo.py
└── two/
    ├── __init__.py
    ├── bar.py
    └── three/
        ├── __init__.py
        ├── dull.py
        └── run.py
</code></pre>
<p>foo.py、bar.py、dull.py 中的代码分别是 print(1)、print(2)、print(3)，并且 run.py 的代码如下：</p>
<pre><code class="language-buildoutcfg">from . import dull
from .. import bar
from ... import foo
print('Go, go, go!')
</code></pre>
<p>我们通过 python -m one.two.three.run 运行 run.py，可以看到 run.py 运行结果如下：</p>
<pre><code class="language-buildoutcfg">3
2
1
Go, go, go!
</code></pre>
<p>意思就是，from 后面出现几个 . 就表示往上找第几层的包。也可以将 run.py 改写成下面这样，运行结果是一样的：</p>
<pre><code class="language-buildoutcfg">from .dull import *
from ..bar import *
from ...foo import *
print('Go, go, go!')
</code></pre>
<p>好啦，相对 import 就介绍到这里，回到最初的问题。如果用相对 import，把 string/foo.py 改写成：</p>
<pre><code class="language-buildoutcfg"># string/foo.py
from . import find
print(find)
</code></pre>
<p>那么 python string/foo.py 和 python -m string.foo 的运行结果又是怎样呢？运行一下发现，两者的输出分别是：</p>
<pre><code class="language-buildoutcfg">Traceback (most recent call last):
  File &quot;string/foo.py&quot;, line 1, in &lt;module&gt;
    from . import find
ValueError: Attempted relative import in non-package
</code></pre>
<pre><code class="language-buildoutcfg">&lt;module 'string.find' from 'string/find.py'&gt;
</code></pre>
<p>原因在于 python string/foo.py 把 foo.py 当成一个单独的脚本来运行，认为 foo.py 不属于任何包，所以此时相对 import 就会报错。也就是说，无论命令行是怎么样的，运行时 import 的语义都统一了，不会再出现运行结果不一致的情况。</p>
<h4 id="绝对-import"><a class="header" href="#绝对-import">绝对 import</a></h4>
<p>绝对 import 和相对 import 很好区分，因为从行为上来看，绝对 import 会通过搜索 sys.path 来查找模块；另一方面，除了相对 import 就只剩绝对 import 了嘛 :) 也就是说：</p>
<ol>
<li>所有的 import ... 都是绝对 import</li>
<li>所有的 from XXX import ... 都是绝对 import</li>
</ol>
<p>不过，第 2 点只对 2.x 及其以上的版本（包括 3.x）成立喔！如果是 2.x 以下的版本，得使用：</p>
<pre><code class="language-buildoutcfg">from __future__ import absolute_import
</code></pre>
<h3 id="两者的差异"><a class="header" href="#两者的差异">两者的差异</a></h3>
<p>首先，绝对 import 是 Python 默认的 import 方式，其原因有两点：</p>
<ul>
<li>绝对 import 比相对 import 使用更频繁</li>
<li>绝对 import 能实现相对 import 的所有功能</li>
</ul>
<p>其次，两者搜索模块的方式不一样：</p>
<ul>
<li>对于相对 import，通过查看 __name__ 变量，在「包层级」（package hierarchy）中搜索</li>
<li>对于绝对 import，当不处于包层级中时，搜索 sys.path</li>
</ul>
<p>前面在介绍 sys.path 的初始化的时候，我在有个地方故意模棱两可，即：</p>
<blockquote>
<p>foo.py 所在目录（如果是软链接，那么是真正的 foo.py 所在目录）或 当前目录</p>
</blockquote>
<p>官方文档的原文是：</p>
<blockquote>
<p>the directory containing the input script (or the current directory).</p>
</blockquote>
<p>这是因为当模块处于包层级中的时候，绝对 import 的行为比较蛋疼，官方的说法是：</p>
<blockquote>
<p>The submodules often need to refer to each other. For example, the surround module might use the echo module. In fact, such references are so common that the import statement first looks in the containing package before looking in the standard module search path. Thus, the surround module can simply use import echo or from echo import echofilter. If the imported module is not found in the current package (the package of which the current module is a submodule), the import statement looks for a top-level module with the given name.</p>
</blockquote>
<p>但是在我的测试中发现，其行为可能是下面两者中的任意一种：</p>
<ul>
<li>.py 文件所在目录</li>
<li>当前目录</li>
</ul>
<p>比如，对于目录结构如下的包：</p>
<pre><code class="language-buildoutcfg">father/
├── __init__.py
├── child/
│   ├── __init__.py
│   ├── foo.py
│   └── string.py
└── string/
    └── __init__.py
</code></pre>
<p>其中，foo.py 代码如下：</p>
<pre><code class="language-buildoutcfg">import string
print(string)
</code></pre>
<p>import string 真正导入的模块是：</p>
<pre><code class="language-buildoutcfg">version	python -m child.foo	python child/foo.py
2.x	child/string.py	child/string.py
3.x	string/__init__.py	child/string.py
</code></pre>
<p>如果将 foo.py 的代码改成（你可以 print(sys.path) 看看为什么改成这样）：</p>
<pre><code class="language-buildoutcfg">import sys
sys.path[0] = ''
import string
print(string)
</code></pre>
<p>import 的模块就变成了：</p>
<pre><code class="language-buildoutcfg">version	python -m child.foo	python child/foo.py
2.x	child/string.py	string/__init__.py
3.x	string/__init__.py	string/__init__.py
</code></pre>
<p>为了避免踩到这种坑，咱们可以这样子：</p>
<ul>
<li>避免包或模块重名，避免使用 __main__.py</li>
<li>包内引用尽量使用相对 import</li>
</ul>
<h3 id="import-的大致过程"><a class="header" href="#import-的大致过程">import 的大致过程</a></h3>
<p>import 的实际过程十分复杂，不过其大致过程可以简化为：</p>
<pre><code class="language-buildoutcfg">def import(module_name):
    if module_name in sys.modules:
        return sys.modules[module_name]
    else:
        module_path = find(module_name)

        if module_path:
            module = load(module_path)
            sys.modules[module_name] = module
            return module
        else:
            raise ImportError
</code></pre>
<p>sys.modules 用于缓存，避免重复 import 带来的开销；load 会将模块执行一次，类似于直接运行。</p>
<h3 id="tips"><a class="header" href="#tips">Tips</a></h3>
<ul>
<li>import 会生成 .pyc 文件，.pyc 文件的执行速度不比 .py 快，但是加载速度更快</li>
<li>重复 import 只会执行第一次 import</li>
<li>如果在 ipython 中 import 的模块发生改动，需要通过 reload 函数重新加载</li>
<li>import * 会导入除了以 _ 开头的所有变量，但是如果定义了 __all__，那么会导入 __all__ 中列出的东西</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="jupyter"><a class="header" href="#jupyter">jupyter</a></h1>
<h2 id="install-1"><a class="header" href="#install-1">install</a></h2>
<pre><code>conda install -y -c conda-forge jupyter nb_conda jupyter_contrib_nbextensions
conda clean --all
</code></pre>
<h2 id="jupyter_notebook_configpy"><a class="header" href="#jupyter_notebook_configpy">jupyter_notebook_config.py</a></h2>
<pre><code>c.NotebookApp.ip='*'
c.NotebookApp.password = ''
c.NotebookApp.open_browser = False 
c.NotebookApp.port = 8888
</code></pre>
<h2 id="start-service"><a class="header" href="#start-service">start service</a></h2>
<pre><code>jupyter notebook --allow-root --notebook-dir=/data &gt; /data/jupyter.log 2&gt;&amp;1 &amp;
</code></pre>
<h2 id="build-docker-1"><a class="header" href="#build-docker-1">build docker</a></h2>
<pre><code>FROM irepoing/python:conda
RUN conda install -y -c conda-forge jupyter nb_conda jupyter_contrib_nbextensions \
    &amp;&amp; conda clean --all \
    &amp;&amp; jupyter notebook --generate-config -y

COPY jupyter_notebook_config.py /root/.jupyter/jupyter_notebook_config.py

ENTRYPOINT [&quot;jupyter&quot;, &quot;notebook --allow-root&quot;]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="other-4"><a class="header" href="#other-4">Other</a></h1>
<h2 id="修改centos默认python版本"><a class="header" href="#修改centos默认python版本">修改Centos默认Python版本</a></h2>
<pre><code>#!/usr/bin/python
vi /usr/bin/yum
vi /usr/libexec/urlgrabber-ext-down
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pip"><a class="header" href="#pip">pip</a></h1>
<h2 id="src-install"><a class="header" href="#src-install">src install</a></h2>
<pre><code>python setup.py install
</code></pre>
<h2 id="update-specify-version"><a class="header" href="#update-specify-version">update specify version</a></h2>
<pre><code>pip install --upgrade pip==10.0.0
python -m pip install --upgrade pip==10.0.0
</code></pre>
<h2 id="install-specify-version"><a class="header" href="#install-specify-version">install specify version</a></h2>
<pre><code>pip install &quot;requests==2.5&quot; 
pip install &quot;requests&gt;=2.0&quot; 
pip install &quot;requests&lt;=3.0&quot;
pip install &quot;requests&gt;=2.0,&lt;=3.0&quot;
</code></pre>
<h2 id="temp-index-url"><a class="header" href="#temp-index-url">temp index url</a></h2>
<pre><code>pip install -i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com --no-cache-dir numpy
</code></pre>
<h2 id="get-index-url"><a class="header" href="#get-index-url">get index url</a></h2>
<pre><code>pip config get global.index-url
</code></pre>
<h2 id="set-index-url"><a class="header" href="#set-index-url">set index url</a></h2>
<pre><code>pip config set global.index-url http://mirrors.aliyun.com/pypi/simple
pip config set install.trusted-host mirrors.aliyun.com
</code></pre>
<h2 id="export-install-package"><a class="header" href="#export-install-package">export install package</a></h2>
<pre><code>pip freeze &gt; requirements.txt
pip freeze --all &gt; requirements.txt
</code></pre>
<h2 id="dowload-package-to-dir"><a class="header" href="#dowload-package-to-dir">dowload package to dir</a></h2>
<pre><code>pip download xxx  -d /paks
pip download -r requirements.txt  -d /packs
</code></pre>
<h2 id="install-package-from-dir"><a class="header" href="#install-package-from-dir">install package from dir</a></h2>
<pre><code>pip install -d /packs -r requirements.txt
pip install --no-index --find-links=/packs xxx
pip install --no-index -f /packs -r requirements.txt
</code></pre>
<h2 id="list-expire-package"><a class="header" href="#list-expire-package">list expire package</a></h2>
<pre><code>pip list --outdate
</code></pre>
<h2 id="download-package-and-install-from-lan"><a class="header" href="#download-package-and-install-from-lan">download package and install from lan</a></h2>
<pre><code>pip config set download.trusted-host mirrors.aliyun.com
pip download --trusted-host mirrors.aliyun.com -r requirements.txt -d /packs
pip install --no-index -f file://xxx/packs numpy
</code></pre>
<h2 id="packing-source-wheel"><a class="header" href="#packing-source-wheel">packing source wheel</a></h2>
<pre><code>pip wheel --wheel-dir=/dst /src
</code></pre>
<h2 id="clean-pip-cache"><a class="header" href="#clean-pip-cache">clean pip cache</a></h2>
<pre><code>pip cache purge
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="react"><a class="header" href="#react">react</a></h1>
<h2 id="install-dotenv-cli"><a class="header" href="#install-dotenv-cli">install dotenv-cli</a></h2>
<pre><code>npm install --save dotenv-cli
</code></pre>
<h2 id="react-config-fileenv-or-envxxx"><a class="header" href="#react-config-fileenv-or-envxxx">react config file(.env or .env.xxx)</a></h2>
<pre><code>REACT_APP_XXX = xxx
</code></pre>
<h2 id="react-scripts"><a class="header" href="#react-scripts">react scripts</a></h2>
<pre><code>&quot;scripts&quot;: {
    &quot;eject&quot;: &quot;react-scripts eject&quot;,
    &quot;start&quot;: &quot;react-scripts start&quot;,
    &quot;test&quot;: &quot;react-scripts test&quot;,
    &quot;build&quot;: &quot;react-scripts build&quot;,
    &quot;dev&quot;: &quot;dotenv -e .env.dev react-scripts start&quot;,
    &quot;build-stg&quot;: &quot;dotenv -e .env.stg react-scripts build&quot;,
    &quot;build-prd&quot;: &quot;dotenv -e .env.prd react-scripts build&quot;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="react-1"><a class="header" href="#react-1">react</a></h1>
<h2 id="install-dotenv-cli-1"><a class="header" href="#install-dotenv-cli-1">install dotenv-cli</a></h2>
<pre><code>npm install --save dotenv-cli
</code></pre>
<h2 id="react-config-fileenv-or-envxxx-1"><a class="header" href="#react-config-fileenv-or-envxxx-1">react config file(.env or .env.xxx)</a></h2>
<pre><code>REACT_APP_XXX = xxx
</code></pre>
<h2 id="react-scripts-1"><a class="header" href="#react-scripts-1">react scripts</a></h2>
<pre><code>&quot;scripts&quot;: {
    &quot;eject&quot;: &quot;react-scripts eject&quot;,
    &quot;start&quot;: &quot;react-scripts start&quot;,
    &quot;test&quot;: &quot;react-scripts test&quot;,
    &quot;build&quot;: &quot;react-scripts build&quot;,
    &quot;dev&quot;: &quot;dotenv -e .env.dev react-scripts start&quot;,
    &quot;build-stg&quot;: &quot;dotenv -e .env.stg react-scripts build&quot;,
    &quot;build-prd&quot;: &quot;dotenv -e .env.prd react-scripts build&quot;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-build"><a class="header" href="#rust-build">rust build</a></h1>
<h2 id="link-library-2"><a class="header" href="#link-library-2">link library</a></h2>
<h3 id="gnu"><a class="header" href="#gnu">gnu</a></h3>
<blockquote>
<p>build.rs</p>
</blockquote>
<pre><code>println!(&quot;cargo:rustc-link-search=native=./lib&quot;);
println!(&quot;cargo:rustc-link-lib=dylib=xxx&quot;);
</code></pre>
<blockquote>
<p>.cargo/config.toml</p>
</blockquote>
<pre><code>[build]
rustflags = [&quot;-L./lib&quot;, &quot;-lxxx&quot;]
</code></pre>
<h3 id="msvc"><a class="header" href="#msvc">msvc</a></h3>
<blockquote>
<p>the import library name should be &quot;xxx.lib&quot;<br />
the dynamic library name should be &quot;xxx.dll&quot;</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-build-1"><a class="header" href="#rust-build-1">rust build</a></h1>
<h2 id="link-library-3"><a class="header" href="#link-library-3">link library</a></h2>
<h3 id="gnu-1"><a class="header" href="#gnu-1">gnu</a></h3>
<blockquote>
<p>build.rs</p>
</blockquote>
<pre><code>println!(&quot;cargo:rustc-link-search=native=./lib&quot;);
println!(&quot;cargo:rustc-link-lib=dylib=xxx&quot;);
</code></pre>
<blockquote>
<p>.cargo/config.toml</p>
</blockquote>
<pre><code>[build]
rustflags = [&quot;-L./lib&quot;, &quot;-lxxx&quot;]
</code></pre>
<h3 id="msvc-1"><a class="header" href="#msvc-1">msvc</a></h3>
<blockquote>
<p>the import library name should be &quot;xxx.lib&quot;<br />
the dynamic library name should be &quot;xxx.dll&quot;</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-env"><a class="header" href="#rust-env">rust env</a></h1>
<h2 id="src"><a class="header" href="#src">src</a></h2>
<pre><code>RUSTUP_HOME=~/.rustup
CARGO_HOME=~/.cargo

RUST_HOME=~/.rustup/toolchains/xxx
RUST_SRC_PATH=$RUST_HOME/lib/rustlib/src/rust/library
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="link-2"><a class="header" href="#link-2">link</a></h1>
<h2 id="link-c"><a class="header" href="#link-c">link c</a></h2>
<blockquote>
<p>a. use attribute</p>
</blockquote>
<pre><code>#[link(name=&quot;tool&quot;, kind=&quot;dylib&quot;)]
extern &quot;C&quot; {
    #[link_name=&quot;kkk&quot;]
    fn xxx();
}
</code></pre>
<ul>
<li>kind=&quot;dylib&quot; #default</li>
<li>kind=&quot;static&quot;</li>
<li>kind=&quot;framework&quot;</li>
<li>kind=&quot;raw-dylib&quot;</li>
</ul>
<blockquote>
<p>b. use link-arg (.cargo/config.toml)</p>
</blockquote>
<pre><code>[build]
rustflags = [&quot;-L/path&quot;, &quot;-ltool&quot;] #linux
rustflags = [&quot;-L/path&quot;, &quot;-ltool.dll&quot;] #windows
</code></pre>
<h2 id="build-c"><a class="header" href="#build-c">build c</a></h2>
<pre><code>gcc -shared -o tool.so main.c
gcc -shared -Wl,--out-implib,tool.dll.lib -o tool.dll main.c
</code></pre>
<h2 id="build-cxx"><a class="header" href="#build-cxx">build cxx</a></h2>
<pre><code>extern &quot;C&quot; __declspec(dllexport) void kkk();

g++ -shared -o tool.so main.cxx
g++ -shared -Wl,--out-implib,tool.dll.lib -o tool.dll main.cxx
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pointer"><a class="header" href="#pointer">pointer</a></h1>
<h2 id="rust-has-foure-pointer"><a class="header" href="#rust-has-foure-pointer">rust has foure pointer</a></h2>
<ul>
<li>reference</li>
<li>fat pointer</li>
<li>smart pointer</li>
<li>raw pointer</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rsproxy"><a class="header" href="#rsproxy">rsproxy</a></h1>
<h2 id="step-1"><a class="header" href="#step-1">step 1</a></h2>
<pre><code>export RUSTUP_DIST_SERVER=https://rsproxy.cn
export RUSTUP_UPDATE_ROOT=https://rsproxy.cn/rustup
</code></pre>
<h2 id="step-2"><a class="header" href="#step-2">step 2</a></h2>
<pre><code>curl --proto '=https' --tlsv1.2 -sSf https://rsproxy.cn/rustup-init.sh | sh
</code></pre>
<h2 id="step-3"><a class="header" href="#step-3">step 3</a></h2>
<pre><code>&gt; vi ~/.cargo/config.toml
</code></pre>
<pre><code>[net]
git-fetch-with-cli = true

[cargo-new]
vcs = &quot;none&quot;

[registries.rsproxy]
index = &quot;https://rsproxy.cn/crates.io-index&quot;

[source.rsproxy]
registry = &quot;https://rsproxy.cn/crates.io-index&quot;

[source.rsproxy-sparse]
registry = &quot;sparse+https://rsproxy.cn/index/&quot;

[source.crates-io]
replace-with = &quot;rsproxy-sparse&quot;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rustup"><a class="header" href="#rustup">rustup</a></h1>
<h2 id="install-rustup-online"><a class="header" href="#install-rustup-online">install rustup online</a></h2>
<pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
</code></pre>
<h2 id="install-rustup-offline"><a class="header" href="#install-rustup-offline">install rustup offline</a></h2>
<ul>
<li>visit rustup.rs</li>
<li>download rustup-init</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="triples"><a class="header" href="#triples">triples</a></h1>
<h2 id="target-triples"><a class="header" href="#target-triples">target triples</a></h2>
<blockquote>
<p>x86_64-pc-windows-gnu</p>
</blockquote>
<pre><code>1. Architecture
2. Operating System
3. Runtime Environment
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="证书操作"><a class="header" href="#证书操作">证书操作</a></h1>
<ul>
<li>生成私钥（1024/2048）</li>
</ul>
<pre><code>openssl genrsa -out ca.key 1024
</code></pre>
<ul>
<li>制作解密后的私钥（非必要）</li>
</ul>
<pre><code>openssl rsa -in ca.key -out ca.key
</code></pre>
<ul>
<li>生成根证书（公钥）</li>
</ul>
<pre><code>openssl req -new -x509 -days 3650 -key ca.key -out ca.crt
</code></pre>
<ul>
<li>制作生成网站的证书并用签名认证</li>
</ul>
<p>如果证书已经存在或者想沿用，则可以直接从这一步开始</p>
<ul>
<li>生成证书私钥</li>
</ul>
<pre><code>openssl genrsa -out server.pem 1024
</code></pre>
<ul>
<li>制作解密后的证书私钥</li>
</ul>
<pre><code>openssl rsa -in server.pem -out server.key
</code></pre>
<ul>
<li>生成签名请求</li>
</ul>
<pre><code>openssl req -new -key server.pem -out server.csr
</code></pre>
<p>在 common name 中填入网站域名，如 www.baidu.com 即可生成该站点的证书，同时也可以使用泛域名如 *.baidu.com 来生成所有二级域名可用的网站证书。</p>
<ul>
<li>用证书进行签名</li>
</ul>
<pre><code>openssl ca -policy policy_anything -days 3650 -cert ca.crt -keyfile ca.key -in server.csr -out server.crt
</code></pre>
<ul>
<li>制作过程</li>
</ul>
<p><img src="server/../static/img/pem/pem001.jpg" alt="" /> </p>
<ul>
<li>Nginx配置</li>
</ul>
<p>以下是 Nginx 启用的部分配置，需要设置 ssl_certificate 和 ssl_certificate_key 指定证书和公钥，并且 listen 443，然后重新启动 Nginx，浏览器就可以用 https://yourhost 的方式访问网页了。</p>
<p><img src="server/../static/img/pem/pem002.jpg" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="证书操作-1"><a class="header" href="#证书操作-1">证书操作</a></h1>
<ul>
<li>生成私钥（1024/2048）</li>
</ul>
<pre><code>openssl genrsa -out ca.key 1024
</code></pre>
<ul>
<li>制作解密后的私钥（非必要）</li>
</ul>
<pre><code>openssl rsa -in ca.key -out ca.key
</code></pre>
<ul>
<li>生成根证书（公钥）</li>
</ul>
<pre><code>openssl req -new -x509 -days 3650 -key ca.key -out ca.crt
</code></pre>
<ul>
<li>制作生成网站的证书并用签名认证</li>
</ul>
<p>如果证书已经存在或者想沿用，则可以直接从这一步开始</p>
<ul>
<li>生成证书私钥</li>
</ul>
<pre><code>openssl genrsa -out server.pem 1024
</code></pre>
<ul>
<li>制作解密后的证书私钥</li>
</ul>
<pre><code>openssl rsa -in server.pem -out server.key
</code></pre>
<ul>
<li>生成签名请求</li>
</ul>
<pre><code>openssl req -new -key server.pem -out server.csr
</code></pre>
<p>在 common name 中填入网站域名，如 www.baidu.com 即可生成该站点的证书，同时也可以使用泛域名如 *.baidu.com 来生成所有二级域名可用的网站证书。</p>
<ul>
<li>用证书进行签名</li>
</ul>
<pre><code>openssl ca -policy policy_anything -days 3650 -cert ca.crt -keyfile ca.key -in server.csr -out server.crt
</code></pre>
<ul>
<li>制作过程</li>
</ul>
<p><img src="server/../static/img/pem/pem001.jpg" alt="" /> </p>
<ul>
<li>Nginx配置</li>
</ul>
<p>以下是 Nginx 启用的部分配置，需要设置 ssl_certificate 和 ssl_certificate_key 指定证书和公钥，并且 listen 443，然后重新启动 Nginx，浏览器就可以用 https://yourhost 的方式访问网页了。</p>
<p><img src="server/../static/img/pem/pem002.jpg" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="caddy"><a class="header" href="#caddy">caddy</a></h1>
<h2 id="config-file-caddyfile"><a class="header" href="#config-file-caddyfile">config file (Caddyfile)</a></h2>
<pre><code>:9090 {
    root * /opt/dist
    file_server
    reverse_proxy /api/* 127.0.0.1:8080
}
</code></pre>
<h2 id="vue-dist"><a class="header" href="#vue-dist">vue dist</a></h2>
<h3 id="caddy-1"><a class="header" href="#caddy-1">caddy 1</a></h3>
<pre><code>:9090 {
    root * /opt/dist
    file_server
    rewrite {
        regexp .*
        to {path} /
    }
}

</code></pre>
<h3 id="caddy-2"><a class="header" href="#caddy-2">caddy 2</a></h3>
<pre><code>:9090 {
    root * /opt/dist
    file_server
    encode zstd gzip
    try_files {path} /index.html
    log {
        output file /tmp/caddy_log
        format single_field common_log
    }
}
</code></pre>
<h2 id="reverse-proxy"><a class="header" href="#reverse-proxy">reverse proxy</a></h2>
<h3 id="vue-proxy"><a class="header" href="#vue-proxy">vue proxy</a></h3>
<pre><code>:9090 {
    root * /opt/dist
    reverse_proxy /api/* {
        to http://localhost:8080
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nginx"><a class="header" href="#nginx">nginx</a></h1>
<h2 id="env"><a class="header" href="#env">env</a></h2>
<pre><code>#编译条件
yum -y install make zlib zlib-devel gcc-c++ libtool  openssl openssl-devel
</code></pre>
<h2 id="下面是虚拟主机的配置nginxconf"><a class="header" href="#下面是虚拟主机的配置nginxconf">下面是虚拟主机的配置（nginx.conf）</a></h2>
<pre><code>user www www;
worker_processes 2; #设置值和CPU核心数一致
error_log /usr/local/webserver/nginx/logs/nginx_error.log crit; #日志位置和日志级别
pid /usr/local/webserver/nginx/nginx.pid;
#Specifies the value for maximum file descriptors that can be opened by this process.
worker_rlimit_nofile 65535;
events
    {
        use epoll;
        worker_connections 65535;
    }
http
    {
        include mime.types;
        default_type application/octet-stream;
        log_format main  '$remote_addr - $remote_user [$time_local] &quot;$request&quot; '
        '$status $body_bytes_sent &quot;$http_referer&quot; '
        '&quot;$http_user_agent&quot; $http_x_forwarded_for';

        #charset utf8;

        server_names_hash_bucket_size 128;
        client_header_buffer_size 32k;
        large_client_header_buffers 4 32k;
        client_max_body_size 8m;

        sendfile on;
        tcp_nopush on;
        keepalive_timeout 60;
        tcp_nodelay on;
        fastcgi_connect_timeout 300;
        fastcgi_send_timeout 300;
        fastcgi_read_timeout 300;
        fastcgi_buffer_size 64k;
        fastcgi_buffers 4 64k;
        fastcgi_busy_buffers_size 128k;
        fastcgi_temp_file_write_size 128k;
        gzip on;
        gzip_min_length 1k;
        gzip_buffers 4 16k;
        gzip_http_version 1.0;
        gzip_comp_level 2;
        gzip_types text/plain application/x-javascript text/css application/xml;
        gzip_vary on;

        #limit_zone crawler $binary_remote_addr 10m;
        #下面是server虚拟主机的配置
        server
            {
                listen 80; #监听端口
                server_name localhost; #域名
                index index.html index.htm index.php;
                root /usr/local/webserver/nginx/html; #站点目录
                location ~ .*\.(php|php5)?$
                    {
                        #fastcgi_pass unix:/tmp/php-cgi.sock;
                        fastcgi_pass 127.0.0.1: 9000;
                        fastcgi_index index.php;
                        include fastcgi.conf;
                    }
                location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|ico)$
                    {
                        expires 30d;
                        #access_log off;
                    }
                location ~ .*\.(js|css)?$
                    {
                        expires 15d;
                        #access_log off;
                    }
                access_log off;
            }
    }
</code></pre>
<h2 id="三种代理"><a class="header" href="#三种代理">三种代理</a></h2>
<h3 id="一正向代理forward-proxy"><a class="header" href="#一正向代理forward-proxy">一、正向代理(Forward Proxy)</a></h3>
<p>一般情况下，如果没有特别说明，代理技术默认说的是正向代理技术。
正向代理（forward）是一个位于客户端 【用户A】和原始服务器(origin server)【服务器B】之间的服务器【代理服务器Z】，为了从原始服务器取得内容，用户A向代理服务器Z发送一个请求并指定目标(服务器B)，然后代理服务器Z向服务器B转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理，如下图所示：</p>
<p><img src="server/../static/img/nginx/nginx001.png" alt="" /></p>
<p>从上图看，所谓的正向代理就是代理服务器【Z】替代访问方【用户A】去访问目标服务器【服务器B】。
下面就是正向代理的意义以及场景</p>
<ul>
<li>1、用户访问本来无法访问的服务器B的资源</li>
</ul>
<p><img src="server/../static/img/nginx/nginx002.png" alt="" /></p>
<p>假设最初用户A要访问服务器B需要经过R1和R2路由器这样一个路由节点，如果路由器R1或者路由器R2发生故障，那么就无法访问服务器B了。但是如果用户A让代理服务器Z去代替自己访问服务器B，由于代理服务器Z没有在路由器R1或R2节点中，而是通过其它的路由节点访问服务器B，那么用户A就可以得到服务器B的数据了。
现实中的例子就是“翻墙”。不过自从VPN技术被广泛应用外，“翻墙”不但使用了传统的正向代理技术，有的还使用了VPN技术。例如IP-SECT动态vpn技术等</p>
<ul>
<li>2、加速访问服务器B资源</li>
</ul>
<p>这种说法目前不像以前那么流行了，主要是带宽流量的飞速发展。早期的正向代理中，很多人使用正向代理就是提速。
还是如图2假设用户A到服务器B，经过R1路由器和R2路由器，而R1到R2路由器的链路是一个低带宽链路。而用户A到代理服务器Z，从代理服务器Z到服务器B都是高带宽链路。那么很显然就可以加速访问服务器B了。</p>
<ul>
<li>3、Cache作用</li>
</ul>
<p><img src="server/../static/img/nginx/nginx003.png" alt="" /></p>
<p>Cache（缓存）技术和代理服务技术是紧密联系的（不光是正向代理，反向代理也使用了Cache（缓存）技术。如上图所示，如果在用户A访问服务器B某数据F之前，已经有人通过代理服务器Z访问过服务器B上得数据F，那么代理服务器Z会把数据F保存一段时间，如果有人正好取该数据F，那么代理服务器Z不再访问服务器B，而把缓存的数据F直接发给用户A。这一技术在Cache中术语就叫Cache命中。如果有更多的像用户A的用户来访问代理服务器Z，那么这些用户都可以直接从代理服务器Z中取得数据F，而不用千里迢迢的去服务器B下载数据了。</p>
<ul>
<li>4、客户端访问授权</li>
</ul>
<p>这方面的内容现今使用的还是比较多的，例如一些公司采用ISA Server做为正向代理服务器来授权用户是否有权限访问互联网，如下图所示：</p>
<p><img src="server/../static/img/nginx/nginx004.png" alt="" /></p>
<p>如上图防火墙作为网关，用来过滤外网对其的访问。假设用户A和用户B都设置了代理服务器，用户A允许访问互联网，而用户B不允许访问互联网（这个在代理服务器Z上做限制）这样用户A因为授权，可以通过代理服务器访问到服务器B，而用户B因为没有被代理服务器Z授权，所以访问服务器B时，数据包会被直接丢弃。</p>
<ul>
<li>5、隐藏访问者的行踪</li>
</ul>
<p>如下图所示，我们可以看出服务器B并不知道访问自己的实际是用户A，因为代理服务器Z代替用户A去直接与服务器B进行交互。如果代理服务器Z被用户A完全控制（或不完全控制），会惯以“肉鸡”术语称呼。</p>
<p><img src="server/../static/img/nginx/nginx005.png" alt="" /></p>
<p>总结：
正向代理是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的IP地址，还有代理程序的端口。</p>
<ul>
<li>Nginx正向代理配置示例如下：</li>
</ul>
<pre><code>server{
        resolver 8.8.8.8;
        resolver_timeout 30s; 
        listen 82;
        location / {
                proxy_pass http://$http_host$request_uri;
                proxy_set_header Host $http_host;
                proxy_buffers 256 4k;
                proxy_max_temp_file_size 0;
                proxy_connect_timeout 30;
                proxy_cache_valid 200 302 10m;
                proxy_cache_valid 301 1h;
                proxy_cache_valid any 1m;
        }
}
1、不能有hostname。 
2、必须有resolver, 即dns，即上面的8.8.8.8，超时时间（30秒）可选。 
3、配置正向代理参数，均是由 Nginx 变量组成。
proxy_pass $scheme://$host$request_uri;  
proxy_set_header Host $http_host;  
4、配置缓存大小，关闭磁盘缓存读写减少I/O，以及代理连接超时时间。
proxy_buffers 256 4k;  
proxy_max_temp_file_size 0;  
proxy_connect_timeout 30;  
5、配置代理服务器 Http 状态缓存时间。
proxy_cache_valid 200 302 10m;  
proxy_cache_valid 301 1h;  
proxy_cache_valid any 1m; 
配置好后，重启nginx，以浏览器为例，要使用这个代理服务器，则只需将浏览器代理设置为http://+服务器ip地址+:+82（82是刚刚设置的端口号）即可使用了。
</code></pre>
<h3 id="二反向代理reverse-proxy"><a class="header" href="#二反向代理reverse-proxy">二、反向代理（reverse proxy）</a></h3>
<p>反向代理正好与正向代理相反，对于客户端而言代理服务器就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端。</p>
<p>使用反向代理服务器的作用如下：</p>
<ul>
<li>1、保护和隐藏原始资源服务器</li>
</ul>
<p><img src="server/../static/img/nginx/nginx006.png" alt="" /></p>
<p>用户A始终认为它访问的是原始服务器B而不是代理服务器Z，但实用际上反向代理服务器接受用户A的应答，从原始资源服务器B中取得用户A的需求资源，然后发送给用户A。由于防火墙的作用，只允许代理服务器Z访问原始资源服务器B。尽管在这个虚拟的环境下，防火墙和反向代理的共同作用保护了原始资源服务器B，但用户A并不知情。</p>
<ul>
<li>2、负载均衡</li>
</ul>
<p><img src="server/../static/img/nginx/nginx007.png" alt="" /></p>
<p>当反向代理服务器不止一个的时候，我们甚至可以把它们做成集群，当更多的用户访问资源服务器B的时候，让不同的代理服务器Z（x）去应答不同的用户，然后发送不同用户需要的资源。
当然反向代理服务器像正向代理服务器一样拥有Cache的作用，它可以缓存原始资源服务器B的资源，而不是每次都要向原始资源服务器组请求数据，特别是一些静态的数据，比如图片和文件，如果这些反向代理服务器能够做到和用户X来自同一个网络，那么用户X访问反向代理服务器X，就会得到很高质量的速度。这正是CDN技术的核心。如下图所示：</p>
<p><img src="server/../static/img/nginx/nginx008.png" alt="" /></p>
<p>反向代理结论与正向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。
基本上，网上做正反向代理的程序很多，能做正向代理的软件大部分也可以做反向代理。开源软件中最流行的就是squid，既可以做正向代理，也有很多人用来做反向代理的前端服务器。另外MS ISA也可以用来在Windows平台下做正向代理。反向代理中最主要的实践就是WEB服务，近些年来最火的就是Nginx了。网上有人说Nginx不能做正向代理，其实是不对的。Nginx也可以做正向代理，不过用的人比较少了。</p>
<ul>
<li>Nginx反向代理示例：</li>
</ul>
<pre><code>http {
#    省略了前面一般的配置，直接从负载均衡这里开始
#    设置地址池，后端3台服务器
    upstream http_server_pool {
        server 192.168.1.2:8080 weight=2 max_fails=2 fail_timeout=30s;
        server 192.168.1.3:8080 weight=3 max_fails=2 fail_timeout=30s;
        server 192.168.1.4:8080 weight=4 max_fails=2 fail_timeout=30s;
    }
#    一个虚拟主机，用来反向代理http_server_pool这组服务器
    server {
        listen       80;
#        外网访问的域名        
        server_name  www.test.com; 
        location / {
#           后端服务器返回500 503 404错误，自动请求转发到upstream池中另一台服务器
            proxy_next_upstream error timeout invalid_header http_500 http_503 http_404;
            proxy_pass http://http_server_pool;
            proxy_set_header Host www.test.com;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;
        }
        access_log  logs/www.test.com.access.log  combined;
    }
}
最简单的反向代理演示（在一台服务器上做代理服务器，将http请求转发到另一台IIS服务器上，通过二级域名形式访问。）编辑vim nginx.conf
server {
    listen    80;
    server_name test.zhoumengkang.com;
    location / {
        proxy_pass http://121.199.**.*:80;
    }
}
</code></pre>
<h3 id="三透明代理"><a class="header" href="#三透明代理">三、透明代理</a></h3>
<p>透明代理的意思是客户端根本不需要知道有代理服务器的存在，它改编你的request fields（报文），并会传送真实IP。注意，加密的透明代理则是属于匿名代理，意思是不用设置使用代理了。
透明代理实践的例子就是时下很多公司使用的行为管理软件。如下图所示：</p>
<p><img src="server/../static/img/nginx/nginx009.png" alt="" /></p>
<p>用户A和用户B并不知道行为管理设备充当透明代理行为，当用户A或用户B向服务器A或服务器B提交请求的时候，透明代理设备根据自身策略拦截并修改用户A或B的报文，并作为实际的请求方，向服务器A或B发送请求，当接收信息回传，透明代理再根据自身的设置把允许的报文发回至用户A或B，如上图，如果透明代理设置不允许访问服务器B，那么用户A或者用户B就不会得到服务器B的数据。</p>
<ul>
<li>Nginx透明代理配置示例：</li>
</ul>
<pre><code># cat /etc/nginx/sites-enabled/proxy
       server {
                resolver        8.8.8.8;
                access_log      off;
                listen  [::]:8080;
                location / {
                        proxy_pass      $scheme://$host$request_uri;
                        proxy_set_header Host $http_host;
                        proxy_buffers   256 4k;
                        proxy_max_temp_file_size        0k;
                        }
                }
 
iptables -t nat -A PREROUTING -s 10.8.0.0/24 -p tcp --dport 80 -j DNAT --to 192.168.0.253:8080
RAW Paste Data
# cat /etc/nginx/sites-enabled/proxy
       server {
                resolver        8.8.8.8;
                access_log      off;
                listen  [::]:8080;
                location / {
                        proxy_pass      $scheme://$host$request_uri;
                        proxy_set_header Host $http_host;
                        proxy_buffers   256 4k;
                        proxy_max_temp_file_size        0k;
                        }
                }

iptables -t nat -A PREROUTING -s 10.8.0.0/24 -p tcp --dport 80 -j DNAT --to 192.168.0.253:8080
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="openssl生成签名的步骤"><a class="header" href="#openssl生成签名的步骤">openssl生成签名的步骤：</a></h1>
<p>x509证书一般会用到三类文，key，csr，crt。</p>
<p>key 是openssl格式的私用密钥，通常是rsa算法。</p>
<p>csr 是证书请求文件，用于申请证书。在制作csr文件的时，必须使用自己的私钥来签署申，还可以设定一个密钥。</p>
<p>crt 是CA认证后的证书文件，签署人用自己的key给你签署的凭证。 </p>
<h2 id="1key的生成"><a class="header" href="#1key的生成">1.key的生成 </a></h2>
<pre><code>openssl genrsa -out server.key 1024
</code></pre>
<p>这样就生成了1024位强度、openssl格式的rsa私钥。为了生成这样的密钥，需要一个至少四位的密码。
可以通过以下方法生成没有密码的key:</p>
<pre><code>openssl rsa -in server.key -out server.key
``` 
server.key就是没有密码的版本了


## 2. 生成CA的crt
</code></pre>
<p>openssl req -new -x509 -key server.key -days 3650 -out ca.crt</p>
<pre><code>生成的ca.crt文件是用来签署下面的server.csr文件。 


## 3. csr的生成方法
</code></pre>
<p>openssl req -new -key server.key -out server.csr</p>
<pre><code>需要依次输入国家，地区，组织，email。最重要的是有一个common name，可以写你的名字或者域名。如果为了https申请，这个必须和域名吻合，否则会引发浏览器警报。生成的csr文件交给CA签名后形成服务端自己的证书。 


## 4. crt生成方法

CSR文件必须有CA的签名才可形成证书，可将此文件发送到verisign等地方由它验证，要交一大笔钱，何不自己做CA呢。
</code></pre>
<p>openssl x509 -req -days 3650 -in server.csr -CA ca.crt -CAkey server.key -CAcreateserial -out server.crt</p>
<pre><code>输入key的密钥后，完成证书生成。-CA选项指明用于被签名的csr证书，-CAkey选项指明用于签名的密钥，-CAserial指明序列号文件，而-CAcreateserial指明文件不存在时自动生成。

最后生成了私用密钥server.key和自己认证的SSL证书server.crt

## 5. 证书合并：
</code></pre>
<p>cat server.key server.crt &gt; server.pem</p>
<pre><code></code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ssh-2"><a class="header" href="#ssh-2">ssh</a></h1>
<h2 id="ssh-config-sshconfig"><a class="header" href="#ssh-config-sshconfig">ssh config (~/.ssh/config)</a></h2>
<pre><code>Host alias_name
    HostName target_host
    User username
    Port port_number
    IdentityFile path_to_private_key
</code></pre>
<h2 id="ssh-authorized"><a class="header" href="#ssh-authorized">ssh authorized</a></h2>
<pre><code>local ~/.ssh/id_rsa.pub
remote ~/.ssh/authorized_keys
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ssh-3"><a class="header" href="#ssh-3">ssh</a></h1>
<h2 id="ssh-config-sshconfig-1"><a class="header" href="#ssh-config-sshconfig-1">ssh config (~/.ssh/config)</a></h2>
<pre><code>Host alias_name
    HostName target_host
    User username
    Port port_number
    IdentityFile path_to_private_key
</code></pre>
<h2 id="ssh-authorized-1"><a class="header" href="#ssh-authorized-1">ssh authorized</a></h2>
<pre><code>local ~/.ssh/id_rsa.pub
remote ~/.ssh/authorized_keys
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sys-proxy"><a class="header" href="#sys-proxy">sys proxy</a></h1>
<h2 id="http-proxy"><a class="header" href="#http-proxy">http proxy</a></h2>
<pre><code>export HTTP_PROXY=http://user:password@xxx.com
</code></pre>
<h2 id="https-proxy"><a class="header" href="#https-proxy">https proxy</a></h2>
<pre><code>export HTTPS_PROXY=http://user:password@xxx.com
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sys-proxy-1"><a class="header" href="#sys-proxy-1">sys proxy</a></h1>
<h2 id="http-proxy-1"><a class="header" href="#http-proxy-1">http proxy</a></h2>
<pre><code>export HTTP_PROXY=http://user:password@xxx.com
</code></pre>
<h2 id="https-proxy-1"><a class="header" href="#https-proxy-1">https proxy</a></h2>
<pre><code>export HTTPS_PROXY=http://user:password@xxx.com
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vivim"><a class="header" href="#vivim">vi/vim</a></h1>
<p><img src="vi/../static/img/vi/vi-vim.gif" alt="vi" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vivim-1"><a class="header" href="#vivim-1">vi/vim</a></h1>
<p><img src="vi/../static/img/vi/vi-vim.gif" alt="vi" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vscode-edit"><a class="header" href="#vscode-edit">vscode edit</a></h1>
<h2 id="delete-repeat-lines"><a class="header" href="#delete-repeat-lines">delete repeat lines</a></h2>
<pre><code>replace ^(.*)(\n\1)+$ to $1
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vscode-edit-1"><a class="header" href="#vscode-edit-1">vscode edit</a></h1>
<h2 id="delete-repeat-lines-1"><a class="header" href="#delete-repeat-lines-1">delete repeat lines</a></h2>
<pre><code>replace ^(.*)(\n\1)+$ to $1
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vscode-golang"><a class="header" href="#vscode-golang">vscode golang</a></h1>
<h2 id="go-extension"><a class="header" href="#go-extension">go extension</a></h2>
<pre><code>https://marketplace.visualstudio.com/items?itemName=golang.go
</code></pre>
<h2 id="settingsjson"><a class="header" href="#settingsjson">settings.json</a></h2>
<pre><code>{
    &quot;go.goroot&quot;: &quot;/path/go&quot;,
    &quot;go.gopath&quot;: &quot;/home/c/go&quot;,
    &quot;go.gotoSymbol.includeGoroot&quot;: true,
    &quot;go.toolsManagement.autoUpdate&quot;: true,
}
</code></pre>
<h2 id="go-plugin-goinstallupdate"><a class="header" href="#go-plugin-goinstallupdate">go plugin (go:install/update)</a></h2>
<pre><code>go install github.com/go-delve/delve/cmd/dlv@latest
go install golang.org/x/tools/gopls@latest
go install github.com/josharian/impl@latest
go install github.com/cweill/gotests/gotests@latest
go install github.com/haya14busa/goplay/cmd/goplay@latest
go install github.com/ramya-rao-a/go-outline@latest
go install github.com/fatih/gomodifytags@latest
go install honnef.co/go/tools/cmd/staticcheck@latest
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="java-1"><a class="header" href="#java-1">java</a></h1>
<h2 id="settingsjson-1"><a class="header" href="#settingsjson-1">settings.json</a></h2>
<pre><code>&quot;java.home&quot;: &quot;/path/to/jdk-11&quot;,
&quot;java.configuration.runtimes&quot;: [
  {
    &quot;name&quot;: &quot;JavaSE-8&quot;,
    &quot;path&quot;: &quot;/path/to/jdk-8&quot;,
    &quot;default&quot;: true
  },
  {
    &quot;name&quot;: &quot;JavaSE-11&quot;,
    &quot;path&quot;: &quot;/path/to/jdk-11&quot;,
  },
]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vs-code-keymap"><a class="header" href="#vs-code-keymap">vs code keymap</a></h1>
<h2 id="一主命令框"><a class="header" href="#一主命令框">一、主命令框</a></h2>
<p>F1 或 Ctrl+Shift+P（俗称万能键）  ：打开命令面板。在打开的输入框内，可以输入任何命令,如下图(图片较大，如果查看不清晰，可以在图片上右键 “在新的标签页中打开图片”，查看原图，下同)：</p>
<p><img src="vscode/../static/img/vs/vs1.png" alt="" /></p>
<blockquote>
<p>按一下 Backspace 会进入到 Ctrl+P 模式</p>
</blockquote>
<blockquote>
<p>在 Ctrl+P 下输入 &gt; 可以进入 Ctrl+Shift+P 模式</p>
</blockquote>
<blockquote>
<p>在 Ctrl+P 窗口下还可以直接输入文件名，跳转到该文件</p>
</blockquote>
<blockquote>
<p>在 Ctrl+P 模式下输入 “?” 会弹出下拉菜单，如下图所示：</p>
</blockquote>
<p><img src="vscode/../static/img/vs/vs2.png" alt="" /></p>
<blockquote>
<p>?   列出当前可执行的动作</p>
</blockquote>
<blockquote>
<p>!   显示 Errors或 Warnings，也可以 Ctrl+Shift+M</p>
</blockquote>
<blockquote>
<p>:   跳转到行数，也可以 Ctrl+G 直接进入</p>
</blockquote>
<blockquote>
<p>@    跳转到 symbol（搜索变量或者函数），也可以 Ctrl+Shift+O 直接进入</p>
</blockquote>
<blockquote>
<p>@    根据分类跳转 symbol，查找属性或函数，也可以 Ctrl+Shift+O 后输入&quot; : &quot;进入</p>
</blockquote>
<blockquote>
<p>#   根据名字查找 symbol，也可以 Ctrl+T</p>
</blockquote>
<h2 id="二常用快捷键"><a class="header" href="#二常用快捷键">二、常用快捷键</a></h2>
<h3 id="1编辑器与窗口管理"><a class="header" href="#1编辑器与窗口管理">1、编辑器与窗口管理</a></h3>
<pre><code>新建文件:   Ctrl+N

文件之间切换:   Ctrl+Tab

打开一个新的VS Code编辑器:    Ctrl+Shift+N

关闭当前窗口:   Ctrl+W

关闭当前的VS Code编辑器:   Ctrl+Shift+W

切出一个新的编辑器窗口（最多3个):   Ctrl+\

切换左中右3个编辑器窗口的快捷键:   Ctrl+1  Ctrl+2  Ctrl+3
</code></pre>
<h3 id="2代码编辑"><a class="header" href="#2代码编辑">2、代码编辑</a></h3>
<p>(1) 格式调整</p>
<pre><code>
代码行向左或向右缩进:   Ctrl+[ 、 Ctrl+]

复制或剪切当前行/当前选中内容:   Ctrl+C 、 Ctrl+V

代码格式化:   Shift+Alt+F

向上或向下移动一行:   Alt+Up 或 Alt+Down

向上或向下复制一行:   Shift+Alt+Up 或 Shift+Alt+Down

在当前行下方插入一行:   Ctrl+Enter

在当前行上方插入一行:   Ctrl+Shift+Enter
</code></pre>
<p>(2) 光标相关</p>
<pre><code>移动到行首:   Home

移动到行尾:   End

移动到文件结尾:   Ctrl+End

移动到文件开头:   Ctrl+Home

移动到定义处:   F12

查看定义处缩略图(只看一眼而不跳转过去):    Alt+F12

选择从光标到行尾的内容:   Shift+End

选择从光标到行首的内容： Shift+Home

删除光标右侧的所有内容(当前行):   Ctrl+Delete

扩展/缩小选取范围： Shift+Alt+Right 和 Shift+Alt+Left

多行编辑(列编辑):   Alt+Shift+鼠标左键 或 Ctrl+Alt+Down/Up

同时选中所有匹配编辑(与当前行或选定内容匹配):   Ctrl+Shift+L

下一个匹配的也被选中:   Ctrl+D

回退上一个光标操作:   Ctrl+U

撤销上一步操作: Ctrl+Z

手动保存:   Ctrl+S
</code></pre>
<p>(3) 重构代码</p>
<pre><code>找到所有的引用:   Shift+F12

同时修改本文件中所有匹配的:   Ctrl+F2

跳转到下一个 Error 或 Warning:   当有多个错误时可以按 F8 逐个跳转
</code></pre>
<p>(4) 查找替换</p>
<pre><code>查找:   Ctrl+F

查找替换:   Ctrl+H
</code></pre>
<p>(5) 显示相关</p>
<pre><code>
全屏显示(再次按则恢复):   F11

放大或缩小(以编辑器左上角为基准):   Ctrl +/-

侧边栏显示或隐藏： Ctrl+B

显示资源管理器(光标切到侧边栏中才有效):   Ctrl+Shift+E

显示搜索(光标切到侧边栏中才有效):   Ctrl+Shift+F

显示(光标切到侧边栏中才有效):   Git Ctrl+Shift+G

显示 Debug:    Ctrl+Shift+D

显示 Output:    Ctrl+Shift+U
</code></pre>
<p>(6) 其他设置</p>
<pre><code>自动保存：File -&gt; AutoSave(中文界面下“文件”-&gt;“自动保存”) 或者 Ctrl+Shift+P，输入 auto
</code></pre>
<h2 id="三修改默认快捷键"><a class="header" href="#三修改默认快捷键">三、修改默认快捷键</a></h2>
<p>打开默认键盘快捷方式设置：File -&gt; Preferences -&gt; Keyboard Shortcuts( 中文界面时：“文件”-&gt;&quot;首选项&quot;-&gt;&quot;键盘快捷方式&quot;)，或者：Alt+F -&gt; p -&gt; k -&gt; Enter，进入后如下图一所示。</p>
<p>修改快捷键绑定方法一：直接在对应命令那一行点击，出现笔状图标，点击进入修改，如下图一所示：</p>
<p><img src="vscode/../static/img/vs/vs3.png" alt="" /></p>
<p>修改快捷键绑定方法二：点击搜索栏下侧的“ keybindings.json ”，进入编辑界面，如下图所示：</p>
<p><img src="vscode/../static/img/vs/vs4.png" alt="" /></p>
<p>编写对应规则有一定的方法，如下所示：</p>
<pre><code>// 将键绑定放入此文件中以覆盖默认值
[{
    &quot;key&quot;: &quot;f8&quot;,
    &quot;command&quot;: &quot;workbench.action.tasks.runTask&quot;,
    &quot;args&quot;: &quot;build&quot;,
    &quot;when&quot;: &quot;editorTextFocus&quot;
}
]

key    表示绑定的键

command    表示执行的命令

args    命令的参数，这里我们是build编译任务

when    快捷键在何时生效，这里指的是编辑区

保存完，你尝试按下F8，任务便顺利运行了。
</code></pre>
<p>自己的&quot; keybindings.json &quot;文件参考如下(谨慎使用)：</p>
<pre><code>// Place your key bindings in this file to overwrite the defaults
[
    // ctrl+space 被切换输入法快捷键占用
    {
        &quot;key&quot;: &quot;ctrl+alt+space&quot;,
        &quot;command&quot;: &quot;editor.action.triggerSuggest&quot;,
        &quot;when&quot;: &quot;editorTextFocus&quot;
    },
    // ctrl+d 删除一行
    {
        &quot;key&quot;: &quot;ctrl+d&quot;,
        &quot;command&quot;: &quot;editor.action.deleteLines&quot;,
        &quot;when&quot;: &quot;editorTextFocus&quot;
    },
    // 与删除一行的快捷键互换
    {
        &quot;key&quot;: &quot;ctrl+shift+k&quot;,
        &quot;command&quot;: &quot;editor.action.addSelectionToNextFindMatch&quot;,
        &quot;when&quot;: &quot;editorFocus&quot;
    },
    // ctrl+shift+/多行注释
    {
        &quot;key&quot;:&quot;ctrl+shift+/&quot;,
        &quot;command&quot;: &quot;editor.action.blockComment&quot;,
        &quot;when&quot;: &quot;editorTextFocus&quot;
    },
    // 定制与 sublime 相同的大小写转换快捷键
    editor.action.transformToLowercase
    editor.action.transformToUppercase
    {
        &quot;key&quot;: &quot;ctrl+k ctrl+u&quot;,
        &quot;command&quot;: &quot;editor.action.transformToUppercase&quot;
        &quot;when&quot;: &quot;editorTextFocus&quot;
    },
    {
        &quot;key&quot;: &quot;ctrl+k ctrl+l&quot;,
        &quot;command&quot;: &quot;editor.action.transformToLowercase&quot;
        &quot;when&quot;: &quot;editorTextFocus&quot;
    }
]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="maven-2"><a class="header" href="#maven-2">maven</a></h1>
<h2 id="settingsjson-2"><a class="header" href="#settingsjson-2">settings.json</a></h2>
<pre><code>&quot;maven.executable.path&quot;: &quot;/path/maven/bin/mvn&quot;,
&quot;maven.settingsFile&quot;: &quot;/path/maven/conf/settings.xml&quot;,
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="svn"><a class="header" href="#svn">svn</a></h1>
<h2 id="1-svn-ignore"><a class="header" href="#1-svn-ignore">1. svn ignore</a></h2>
<h3 id="11-settingsjson"><a class="header" href="#11-settingsjson">1.1 settings.json</a></h3>
<pre><code>&quot;svn.sourceControl.ignore&quot;: [
        &quot;.vscode&quot;,
        &quot;**/target&quot;,
        &quot;**/log&quot;,
    ]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vue"><a class="header" href="#vue">vue</a></h1>
<h2 id="srcmainjs"><a class="header" href="#srcmainjs">src/main.js</a></h2>
<pre><code>import Vue from 'vue'
import app from '@/app.vue'
import store from '@/store'
import router from '@/router'

Vue.config.productionTip = false

new Vue({
    store,
    router,
    render: h =&gt; h(app),
}).$mount('#app')
</code></pre>
<h2 id="srcappvue"><a class="header" href="#srcappvue">src/app.vue</a></h2>
<pre><code>&lt;template&gt;
    &lt;div id=&quot;app&quot;&gt;
        &lt;router-view&gt;&lt;/router-view&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
    export default {
        name: 'app'
    }
&lt;/script&gt;

&lt;style&gt;

&lt;/style&gt;
</code></pre>
<h2 id="srcstoreindexjs"><a class="header" href="#srcstoreindexjs">src/store/index.js</a></h2>
<pre><code>import Vue from 'vue'
import Vuex from 'vuex'

Vue.use(Vuex)

export default new Vuex.Store({
    state: {},
    actions: {},
    modules: {},
    mutations: {},
})
</code></pre>
<h2 id="srcrouterindexjs"><a class="header" href="#srcrouterindexjs">src/router/index.js</a></h2>
<pre><code>import Vue from 'vue'
import Router from 'vue-router'

Vue.use(Router)

const RouterPush = Router.prototype.push
Router.prototype.push = function push(to) {
    return RouterPush.call(this, to).catch(err =&gt; err)
}

const routes = [
    {
        path: '/',
        name: 'index',
        component: () =&gt; import('@/views/index'),
        meta: {title: '首页'},
    },
    {
        path: '/login',
        name: 'login',
        component: () =&gt; import('@/views/login'),
        meta: {title: '登录'},
    },
]

const router = new Router({
    mode: 'hash', //hash, history
    routes: routes,
})

router.beforeEach((to, from, next) =&gt; {
    if (to.meta.title) {
        document.title = to.meta.title
    }

    let token = sessionStorage.getItem('token')

    if (token) {
        if (to.path == '/login') {
            next({path: '/'})
        } else {
            next()
        }
    } else {
        if (to.path == '/login') {
            next()
        } else {
            next({path: '/login'})
        }
    }
})

export default router

</code></pre>
<h2 id="vueconfigjs"><a class="header" href="#vueconfigjs">vue.config.js</a></h2>
<pre><code>'use strict'
const path = require('path')
const port = process.env.port || 8080
const resolve = dir =&gt; {
    return path.join(__dirname, dir)
}

module.exports = {
    publicPath: '/',
    outputDir: 'dist',
    assetsDir: '',
    indexPath: 'index.html',
    filenameHashing: true,
    lintOnSave: 'default',
    runtimeCompiler: false,
    transpileDependencies: [],
    productionSourceMap: true,
    integrity: false,
    configureWebpack: {},
    chainWebpack: config =&gt; {
        config.resolve.alias
            .set('@', resolve('src'))
            .set('style', resolve('src/style'))
            .set('assets', resolve('src/assets'))
            .set('components', resolve('src/components'))

        config.module
            .rule('svg')
            .exclude.add(resolve('src/static/icons/svg'))
            .end()

        config.module
            .rule('icons')
            .test(/\.svg$/)
            .include.add(resolve('src/static/icons/svg'))
            .end()
            .use('svg-sprite-loader')
            .loader('svg-sprite-loader')
            .options({symbolId: 'icon-[name]'})
            .end()
    },
    devServer: {
        port: port,
        open: false,
        proxy: {
            '/api': {
                target: 'http://localhost:9090',
                secure: false,
                changeOrigin: true,
                pathRewrite: {
                    '^/api': '',
                }
            }
        },
    },
    parallel: require('os').cpus().length &gt; 1,
    pwa: {},
    pluginOptions: {
        electronBuilder: {
            nodeIntegration: true
        }
    },
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vue-1"><a class="header" href="#vue-1">vue</a></h1>
<h2 id="srcmainjs-1"><a class="header" href="#srcmainjs-1">src/main.js</a></h2>
<pre><code>import Vue from 'vue'
import app from '@/app.vue'
import store from '@/store'
import router from '@/router'

Vue.config.productionTip = false

new Vue({
    store,
    router,
    render: h =&gt; h(app),
}).$mount('#app')
</code></pre>
<h2 id="srcappvue-1"><a class="header" href="#srcappvue-1">src/app.vue</a></h2>
<pre><code>&lt;template&gt;
    &lt;div id=&quot;app&quot;&gt;
        &lt;router-view&gt;&lt;/router-view&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
    export default {
        name: 'app'
    }
&lt;/script&gt;

&lt;style&gt;

&lt;/style&gt;
</code></pre>
<h2 id="srcstoreindexjs-1"><a class="header" href="#srcstoreindexjs-1">src/store/index.js</a></h2>
<pre><code>import Vue from 'vue'
import Vuex from 'vuex'

Vue.use(Vuex)

export default new Vuex.Store({
    state: {},
    actions: {},
    modules: {},
    mutations: {},
})
</code></pre>
<h2 id="srcrouterindexjs-1"><a class="header" href="#srcrouterindexjs-1">src/router/index.js</a></h2>
<pre><code>import Vue from 'vue'
import Router from 'vue-router'

Vue.use(Router)

const RouterPush = Router.prototype.push
Router.prototype.push = function push(to) {
    return RouterPush.call(this, to).catch(err =&gt; err)
}

const routes = [
    {
        path: '/',
        name: 'index',
        component: () =&gt; import('@/views/index'),
        meta: {title: '首页'},
    },
    {
        path: '/login',
        name: 'login',
        component: () =&gt; import('@/views/login'),
        meta: {title: '登录'},
    },
]

const router = new Router({
    mode: 'hash', //hash, history
    routes: routes,
})

router.beforeEach((to, from, next) =&gt; {
    if (to.meta.title) {
        document.title = to.meta.title
    }

    let token = sessionStorage.getItem('token')

    if (token) {
        if (to.path == '/login') {
            next({path: '/'})
        } else {
            next()
        }
    } else {
        if (to.path == '/login') {
            next()
        } else {
            next({path: '/login'})
        }
    }
})

export default router

</code></pre>
<h2 id="vueconfigjs-1"><a class="header" href="#vueconfigjs-1">vue.config.js</a></h2>
<pre><code>'use strict'
const path = require('path')
const port = process.env.port || 8080
const resolve = dir =&gt; {
    return path.join(__dirname, dir)
}

module.exports = {
    publicPath: '/',
    outputDir: 'dist',
    assetsDir: '',
    indexPath: 'index.html',
    filenameHashing: true,
    lintOnSave: 'default',
    runtimeCompiler: false,
    transpileDependencies: [],
    productionSourceMap: true,
    integrity: false,
    configureWebpack: {},
    chainWebpack: config =&gt; {
        config.resolve.alias
            .set('@', resolve('src'))
            .set('style', resolve('src/style'))
            .set('assets', resolve('src/assets'))
            .set('components', resolve('src/components'))

        config.module
            .rule('svg')
            .exclude.add(resolve('src/static/icons/svg'))
            .end()

        config.module
            .rule('icons')
            .test(/\.svg$/)
            .include.add(resolve('src/static/icons/svg'))
            .end()
            .use('svg-sprite-loader')
            .loader('svg-sprite-loader')
            .options({symbolId: 'icon-[name]'})
            .end()
    },
    devServer: {
        port: port,
        open: false,
        proxy: {
            '/api': {
                target: 'http://localhost:9090',
                secure: false,
                changeOrigin: true,
                pathRewrite: {
                    '^/api': '',
                }
            }
        },
    },
    parallel: require('os').cpus().length &gt; 1,
    pwa: {},
    pluginOptions: {
        electronBuilder: {
            nodeIntegration: true
        }
    },
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deploy-2"><a class="header" href="#deploy-2">deploy</a></h1>
<h2 id="caddy-1"><a class="header" href="#caddy-1">caddy</a></h2>
<h3 id="caddy-file"><a class="header" href="#caddy-file">caddy file</a></h3>
<pre><code>:8080 {
    root * /opt/dist/{$RUN_ENV}
    file_server
    encode zstd gzip
    reverse_proxy /api/* {
        to {$SER_URL}
    }
}
</code></pre>
<h3 id="docker-file"><a class="header" href="#docker-file">docker file</a></h3>
<pre><code>FROM docker.io/itesting/alpine:caddy
COPY dist /code/dist
COPY Caddyfile /code/Caddyfile
ENTRYPOINT [&quot;caddy&quot;, &quot;run&quot;, &quot;--config&quot;, &quot;/code/Caddyfile&quot;]
</code></pre>
<pre><code>FROM docker.io/itesting/npm:caddy
COPY . /code
WORKDIR /code
RUN npm install
RUN npm run build -- --dest=&quot;dist/stg&quot; --mode=&quot;stg&quot;
RUN npm run build -- --dest=&quot;dist/prd&quot; --mode=&quot;prd&quot;
ENTRYPOINT [&quot;caddy&quot;, &quot;run&quot;, &quot;--config&quot;, &quot;/code/Caddyfile&quot;]
</code></pre>
<h3 id="build-docker-2"><a class="header" href="#build-docker-2">build docker</a></h3>
<pre><code>docker build -t vue-demo .
</code></pre>
<h3 id="run-docker"><a class="header" href="#run-docker">run docker</a></h3>
<pre><code>docker run -d -e RUN_ENV=stg -e SER_URL=http://example:8080 -p 8080:8080 vue-demo
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="svg"><a class="header" href="#svg">svg</a></h1>
<h2 id="vueconfigjs-2"><a class="header" href="#vueconfigjs-2">vue.config.js</a></h2>
<pre><code>const resolve = dir =&gt; {
    return path.join(__dirname, dir)
}

module.exports = {
    chainWebpack: config =&gt; {
            config.module
                .rule('svg')
                .exclude.add(resolve('src/static/icons/svg'))
                .end()
    
            config.module
                .rule('icons')
                .test(/\.svg$/)
                .include.add(resolve('src/static/icons/svg'))
                .end()
                .use('svg-sprite-loader')
                .loader('svg-sprite-loader')
                .options({symbolId: 'icon-[name]'})
                .end()
    },
}
</code></pre>
<h2 id="srccomponentssvgindexjs"><a class="header" href="#srccomponentssvgindexjs">src/components/svg/index.js</a></h2>
<pre><code>import Vue from 'vue'
import SvgIcon from '@/components/svg/SvgIcon'

Vue.component('svg-icon', SvgIcon)

const requireAll = ctx =&gt; ctx.keys().map(ctx)
requireAll(require.context('@/static/icons/svg', false, /\.svg$/))
</code></pre>
<h2 id="srccomponentssvgsvgiconvue"><a class="header" href="#srccomponentssvgsvgiconvue">src/components/svg/SvgIcon.vue</a></h2>
<pre><code>&lt;template&gt;
    &lt;svg :class=&quot;svgClass&quot; aria-hidden=&quot;true&quot; v-on=&quot;$listeners&quot;&gt;
        &lt;use :xlink:href=&quot;iconName&quot;&gt;&lt;/use&gt;
    &lt;/svg&gt;
&lt;/template&gt;

&lt;script&gt;
    export default {
        name: &quot;SvgIcon&quot;,
        props: {
            iconClass: {
                type: String,
                required: true,
            },
            className: {
                type: String,
                default: '',
            }
        },
        computed: {
            iconName() {
                return `#icon-${this.iconClass}`
            },
            svgClass() {
                if (this.className) {
                    return 'svg-icon' + this.className
                } else {
                    return 'svg-icon'
                }
            },
            styleExternalIcon() {
                return {
                    mask: `url(${this.iconClass}) no-repeat 50% 50%`,
                    '-webkit-mask': `url(${this.iconClass}) no-repeat 50% 50%`
                }
            },
        }
    }
&lt;/script&gt;

&lt;style scoped&gt;
    .svg-icon {
        width: 1em;
        height: 1em;
        vertical-align: -0.15em;
        fill: currentColor;
        overflow: hidden;
    }

    .svg-external-icon {
        background-color: currentColor;
        mask-size: cover !important;
        display: inline-block;
    }
&lt;/style&gt;
</code></pre>
<h2 id="srcmainjs-2"><a class="header" href="#srcmainjs-2">src/main.js</a></h2>
<pre><code>import '@/components/svg'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="windows"><a class="header" href="#windows">windows</a></h1>
<h2 id="skip-network"><a class="header" href="#skip-network">skip network</a></h2>
<pre><code>[Shift + F10]
oobe\bypassnro
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="windows-1"><a class="header" href="#windows-1">windows</a></h1>
<h2 id="skip-network-1"><a class="header" href="#skip-network-1">skip network</a></h2>
<pre><code>[Shift + F10]
oobe\bypassnro
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="msi"><a class="header" href="#msi">msi</a></h1>
<h2 id="install-2"><a class="header" href="#install-2">install</a></h2>
<pre><code>msiexec /q /i xxx.msi
</code></pre>
<h2 id="uninstall"><a class="header" href="#uninstall">uninstall</a></h2>
<pre><code>msiexec /q /x xxx.msi
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="md文档使用手册"><a class="header" href="#md文档使用手册">MD文档使用手册</a></h1>
<h2 id="一标题"><a class="header" href="#一标题">一、标题</a></h2>
<h1 id="一级标题"><a class="header" href="#一级标题">一级标题</a></h1>
<h2 id="二级标题"><a class="header" href="#二级标题">二级标题</a></h2>
<h3 id="三级标题"><a class="header" href="#三级标题">三级标题</a></h3>
<h4 id="四级标题"><a class="header" href="#四级标题">四级标题</a></h4>
<h5 id="五级标题"><a class="header" href="#五级标题">五级标题</a></h5>
<h6 id="六级标题"><a class="header" href="#六级标题">六级标题</a></h6>
<p>前面带#号，后面带文字，分别表示h1-h6,上图可以看出，只到h6，而且h1下面会有一条横线，注意，#号后面有空格</p>
<h1 id="一级标题-1"><a class="header" href="#一级标题-1">一级标题</a></h1>
<h2 id="二级标题-1"><a class="header" href="#二级标题-1">二级标题</a></h2>
<p>这种方式好像只能表示一级和二级标题，而且=和-的数量没有限制，只要大于一个就行</p>
<h1 id="一级标题-2"><a class="header" href="#一级标题-2">一级标题</a></h1>
<h2 id="二级标题-2"><a class="header" href="#二级标题-2">二级标题</a></h2>
<p>这里的标题支持h1-h6，为了减少篇幅，我就偷个懒，只写前面二个，这个比较好理解，相当于标签闭合，注意，标题与#号要有空格</p>
<h2 id="二列表"><a class="header" href="#二列表">二、列表</a></h2>
<p>无序列表</p>
<ul>
<li>1</li>
<li>2</li>
<li>3</li>
</ul>
<ul>
<li>4</li>
<li>5</li>
<li>6</li>
</ul>
<ul>
<li>7</li>
<li>8</li>
<li>9</li>
</ul>
<p>可以看到，无序列表可以用* ， + ， - 来创建，用在线编辑器看，实际上是转换成了ul&gt;li ，所以使用哪个都可以，推荐使用*吧</p>
<p>有序列表</p>
<ol>
<li>
<p>1</p>
</li>
<li>
<p>2</p>
</li>
<li>
<p>3</p>
</li>
<li>
<p>1</p>
</li>
<li>
<p>1</p>
</li>
<li>
<p>1</p>
</li>
<li>
<p>1</p>
</li>
<li>
<p>1</p>
</li>
</ol>
<h2 id="三区块引用"><a class="header" href="#三区块引用">三、区块引用</a></h2>
<ul>
<li>
<p>团结就是力量</p>
<blockquote>
<p>这是谁说的，我也不知道了...</p>
</blockquote>
<blockquote>
<p>我觉得这是毛主席说的！</p>
</blockquote>
<blockquote>
<blockquote>
<p>谁说的这是毛主席说的？</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>楼上给力，连毛主席的面子都不给！</p>
</blockquote>
</blockquote>
</blockquote>
</li>
</ul>
<h2 id="四分割线"><a class="header" href="#四分割线">四、分割线</a></h2>
<hr />
<hr />
<hr />
<p>分割线可以由* - _（星号，减号，底线）这3个符号的至少3个符号表示，注意至少要3个，且不需要连续，有空格也可以</p>
<h2 id="五链接"><a class="header" href="#五链接">五、链接</a></h2>
<h3 id="行内式"><a class="header" href="#行内式">行内式</a></h3>
<p><a href="http://www.baidu.com">百度一下</a>，你就知道了！</p>
<p><a href="http://www.baidu.com" title="这里还可以加标题哦">百度一下</a>，你就知道了！</p>
<h3 id="参数式"><a class="header" href="#参数式">参数式</a></h3>
<p>有什么不懂，你就<a href="http://www.baidu.com" title="百度首页">name</a>一下</p>
<p>有什么不懂，你就<a href="http://www.baidu.com" title="百度首页">百度</a>一下</p>
<h2 id="六图片"><a class="header" href="#六图片">六、图片</a></h2>
<p><img src="https://www.baidu.com/img/baidu_jgylogo3.gif" alt="百度" /></p>
<p>这里有一张图片<img src="https://www.baidu.com/img/baidu_jgylogo3.gif" alt="img" title="说明" /></p>
<p>用法跟链接的基本一样，唯一的不同就是，图片前面要写一个！（这是必须的）</p>
<h2 id="七代码框"><a class="header" href="#七代码框">七、代码框</a></h2>
<h3 id="单行代码用-反单引号"><a class="header" href="#单行代码用-反单引号">单行代码用<code> </code>(反单引号)</a></h3>
<p><code>fmt.Println(&quot;hello world&quot;)</code></p>
<h3 id="多行代码-三个反单引号"><a class="header" href="#多行代码-三个反单引号">多行代码<code> </code>（三个反单引号）</a></h3>
<pre><code class="language-buildoutcfg">func main() {
	tools.Task()
}
</code></pre>
<p>多行用三个反引号，如果要写注释，可以在反引号后面写。</p>
<h2 id="八强调"><a class="header" href="#八强调">八、强调</a></h2>
<p>这是一个<em>强调</em></p>
<p>这是一个<strong>加粗</strong></p>
<p>一个星号或者是一个下划线包起来，会转换为<em>强调</em>，如果是2个，会转换为<strong>加粗</strong></p>
<h2 id="九删除线"><a class="header" href="#九删除线">九、删除线(~~)</a></h2>
<p><del>删除线</del></p>
<h2 id="十转义"><a class="header" href="#十转义">十、转义</a></h2>
<p>\</p>
<p>/</p>
<p>*</p>
<p>+</p>
<p>以此类推</p>
<h2 id="表格"><a class="header" href="#表格">表格</a></h2>
<div class="table-wrapper"><table><thead><tr><th>表头</th><th>表头</th></tr></thead><tbody>
<tr><td>内容</td><td>内容</td></tr>
</tbody></table>
</div>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="theme/pagetoc.js"></script>

        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </body>
</html>
